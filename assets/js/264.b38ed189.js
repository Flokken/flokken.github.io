(window.webpackJsonp=window.webpackJsonp||[]).push([[264],{594:function(e,a,r){"use strict";r.r(a);var v=r(4),t=Object(v.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("blockquote",[a("p",[e._v("极客时间:")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://time.geekbang.org/column/article/423595",target:"_blank",rel:"noopener noreferrer"}},[e._v("MapReduce：源起Unix的设计思想"),a("OutboundLink")],1)]),e._v(" "),a("p",[a("a",{attrs:{href:"https://time.geekbang.org/column/article/423598",target:"_blank",rel:"noopener noreferrer"}},[e._v("MapReduce：不怕失败的计算框架"),a("OutboundLink")],1)])]),e._v(" "),a("h2",{attrs:{id:"引言"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#引言"}},[e._v("#")]),e._v(" 引言")]),e._v(" "),a("p",[e._v("前面学习了GFS。本质上，GFS 是对上千台服务器、上万块硬盘的硬件做了一个封装，让 GFS 的使用者可以把 GFS 当成一块硬盘来使用。通过 GFS 客户端，无论你是要读还是写海量的数据，你都不需要去操心这些数据最终要存储到哪一台服务器或者哪一块硬盘上。你也不需要担心哪一台服务器的网线可能松了，哪一块硬盘可能坏了，这些问题都由 GFS 这个“分布式系统”去考虑解决了。")]),e._v(" "),a("p",[e._v("不过，GFS 仅仅是解决了数据存储和读写的问题。要知道，只是把数据读出来和写回去，只能做做数据备份，这可解决不了什么具体、有意义的问题。所幸，在 GFS 这个分布式文件系统之上，谷歌又在 2004 年发表了 MapReduce 的论文，**也就是一个分布式计算的框架。**那么，我们今天就一起来看看，MapReduce 到底是要解决什么样的问题。而要解决这些问题的系统，又应该要怎么设计。")]),e._v(" "),a("p",[e._v("当你仔细了解 MapReduce 的框架之后，你会发现 MapReduce 的设计哲学和 Unix 是一样的，叫做“Do one thing, and do it well”，也就是每个模块只做一件事情，但是把这件事情彻底做好。在学完这两讲之后，你不仅应该了解什么是 MapReduce，MapReduce 是怎么设计的。更重要的是理解如何对系统进行抽象并做出合理的设计。"),a("strong",[e._v("在未来你自己进行系统设计的时候，为各个模块划分好职责和边界，把“Do one thing, and do it well”落到实处。")])]),e._v(" "),a("h2",{attrs:{id:"分布式系统的首要目标-开发人员不懂分布式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分布式系统的首要目标-开发人员不懂分布式"}},[e._v("#")]),e._v(" 分布式系统的首要目标：开发人员不懂分布式")]),e._v(" "),a("p",[e._v("分布式系统的第一特性是什么？")]),e._v(" "),a("p",[e._v("有些人可能选择**“性能”（Performance）**，分布式系统本来就是因为单机性能不够了，那么把性能视作重要的因素是理所当然的。")]),e._v(" "),a("p",[e._v("有些人可能会选择**“可伸缩性”（Scalability）**，只要增加更多的硬件节点，就能处理更大规模的数据，更快地处理原来的数据，那么我们就可以“性能不够，机器来凑")]),e._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/5b0ae6a58b185edeefeaa01496196a92.jpg",alt:"img"}}),e._v(" "),a("p",[e._v("这些都没有错，但是"),a("strong",[e._v("易用性")]),e._v("也很重要。更具体一点，就是我们希望来使用这个分布式数据处理系统的人，最好意识不到“分布式”的存在。")]),e._v(" "),a("blockquote",[a("p",[e._v("MapReduce就是为了让没有分布式系统知识和经验的人，一样可以快速简便地去利用 MapReduce 处理海量的数据。")])]),e._v(" "),a("p",[e._v("这篇论文，基本上可以看作是三个部分：")]),e._v(" "),a("ul",[a("li",[e._v("MapReduce 的计算模型和应用场景；")]),e._v(" "),a("li",[e._v("MapReduce 实际是如何实现的，使得开发者无需关心分布式的存在；")]),e._v(" "),a("li",[e._v("如何逐步迭代优化 MapReduce 的性能。")])]),e._v(" "),a("h2",{attrs:{id:"mapreduce-一个分布式的-bash"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce-一个分布式的-bash"}},[e._v("#")]),e._v(" MapReduce：一个分布式的 Bash")]),e._v(" "),a("p",[e._v("我们回头看 2004 年发布的 MapReduce，是简单到可以说是简陋的。这也是为什么后续不断有各种各样的新系统出现，比如 Spark、Storm、Dremel 等。但是，尽管简单，MapReduce 的设计其实非常干净利落，它从一开始就是奔着让开发者对“分布式”无感而去的。")]),e._v(" "),a("p",[e._v("我们先看第一点： "),a("strong",[e._v("MapReduce 的计算模型和应用场景是什么，然后我们再和 Unix 下的管道做一个对比，看一看为什么说 MapReduce 继承了 Unix 的设计思想。")])]),e._v(" "),a("p",[e._v("不过在直接看论文之前，我想请你先自己想一想，"),a("strong",[e._v("要针对存放在上千个节点的 GFS 上的数据，进行数据处理，你会怎么做？你会有哪些计算方式的需求呢？")])]),e._v(" "),a("p",[e._v("最直接的方式就是在很多台机器上，同时来做运算，"),a("strong",[e._v("也就是进行并行计算，这样可以利用我们有上千个节点的优势。")])]),e._v(" "),a("p",[e._v("而需要的计算方式，抽象来说，无非是三种情况。")]),e._v(" "),a("ul",[a("li",[e._v("第一种，是对所有的数据，我们都只需要单条数据就能完成处理。比如，我们有很多网页的内容，我们要从里面提取出来每一个网页的标题。这样的计算可以完全并行化。")]),e._v(" "),a("li",[e._v("第二种，是需要汇总多条数据才能完成计算。比如，要统计日志里面某个 URL 被访问了多少次，只需要简单累加就可以了。或者我们需要更复杂一些的操作，比如统计某个 URL 下面的唯一用户数。而对于这里的第二种情况，我们就需要将所有相同 URL 的数据，搬运到同一个计算节点上进行处理。不过，在搬运之后，不同的 URL 还是可以放到不同的节点进行处理的。")]),e._v(" "),a("li",[e._v("第三种，自然是一、二两种情况的组合了。比如，我们先从网页数据里面，提取出网页的 URL 和标题，然后根据标题里面的关键字，统计特定关键字出现在多少个不同的 URL 里面，这就需要同时采用一二这两种情况的操作。")])]),e._v(" "),a("p",[e._v("当然，我们可以有更复杂的数据操作，但是这些动作也都可以抽象成前面的两个动作的组合。因为无非，"),a("strong",[e._v("我们要处理的数据要么是完全独立的，要么需要多条数据之间的依赖。")])]),e._v(" "),a("p",[a("strong",[e._v("实际上，前面的第一种动作，就是 MapReduce 里面的 Map；第二种动作，就是 MapReduce 里面的 Reduce；而搬运的过程，就是 Shuffle(混洗)。")])]),e._v(" "),a("h3",{attrs:{id:"mapreduce编程模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce编程模型"}},[e._v("#")]),e._v(" MapReduce编程模型")]),e._v(" "),a("p",[e._v("根据上面的思考，其实就是MapReduce的编程模型。对于利用MapReduce框架进行数据处理的开发者来说，只需要实现一个Map函数，一个Reduce函数。")]),e._v(" "),a("p",[e._v("**Map函数，就是一个映射函数，**他会接受一个key-value对，然后把这个key-value对转换成0到多个新的key-value对并输出出去。")]),e._v(" "),a("p",[a("code",[e._v("map(k1,v1) -> list(k2,v2)")])]),e._v(" "),a("p",[a("strong",[e._v("Reduce 函数，则是一个化简函数")]),e._v("，它接受一个 Key，以及这个 Key 下的一组 Value，然后化简成一组新的值 Value 输出出去。")]),e._v(" "),a("p",[a("code",[e._v("reduce(k2,list(v2)) -> list(v3)")])]),e._v(" "),a("p",[e._v("而在 Map 函数和 Reduce 函数之外，"),a("strong",[e._v("开发者还需要指定一下输入输出文件的路径。输入路径上的文件内容，会变成一个个键值对给到 Map 函数")]),e._v("。而 Map 函数会运行开发者写好的映射逻辑，"),a("strong",[e._v("把数据作为新的一组键值对输出出去。")])]),e._v(" "),a("p",[e._v("Map 函数的输出结果，会被整个 MapReduce 程序接手，进行一个叫做混洗的操作。")]),e._v(" "),a("p",[a("strong",[e._v("混洗(Shuffle)会把 Map 函数输出的所有相同的 Key 的 Value 整合到一个列表中，给到 Reduce 函数。并且给到 Reduce 函数的 Key，在每个 Reduce 里，都是按照 Key 排好序的。")])]),e._v(" "),a("blockquote",[a("p",[e._v("这里提一下排序，排好序并不是 MapReduce 框架本身的核心需求，而是为了技术上实现方便。因为我们要把相同 Key 的数据放到一起处理，而通过一个 HashMap 把所有的数据放在内存里又不一定放得下。")]),e._v(" "),a("p",[a("strong",[e._v("那么利用硬盘进行外部排序（也就是本地磁盘中进行排序）是一个最简单的，没有内存大小依赖的对数据根据 Key 进行分组的解决办法。")])])]),e._v(" "),a("p",[e._v("最后，在拿到混洗完成，分好组的数据之后，Reduce 函数就会运行你写好的化简逻辑，最终输出结果。")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231031111920757.png",alt:"image-20231031111920757"}})]),e._v(" "),a("blockquote",[a("p",[e._v("MapReduce是一个典型的模版方法模式（Template Method Pattern），因为 MapReduce 框架已经设定好了整个数据处理的流程，"),a("strong",[e._v("你只需要实现 Map 和 Reduce 这两个接口函数，就能完成海量的数据处理程序。")])])]),e._v(" "),a("h3",{attrs:{id:"应用场景"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#应用场景"}},[e._v("#")]),e._v(" 应用场景")]),e._v(" "),a("p",[e._v("在论文中就列举了很多应用场景，这里举例：")]),e._v(" "),a("ul",[a("li",[e._v("分布式 grep；")]),e._v(" "),a("li",[e._v("统计 URL 的访问频次；")]),e._v(" "),a("li",[e._v("反转网页 - 链接图；")]),e._v(" "),a("li",[e._v("分域名的词向量；")]),e._v(" "),a("li",[e._v("生成倒排索引；")]),e._v(" "),a("li",[e._v("分布式排序。")])]),e._v(" "),a("p",[e._v("下面，我们就主要来关注一下前两个场景的用途，看看最简单的两个场景是如何通过 MapReduce 来实现的**。然后，我们可以把其中的第二个场景和 Unix 下的 Bash 脚本对应起来，来理解为什么说 MapReduce 的设计思想，就是来自于 Unix 下的 Bash 和管道。**")]),e._v(" "),a("h4",{attrs:{id:"分布式-grep"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分布式-grep"}},[e._v("#")]),e._v(" 分布式 grep")]),e._v(" "),a("p",[e._v("在日常使用 Linux 的过程中，相信你没少用过 grep 这个命令。早年间，在出现各种线上故障的时候，我常常会通过 grep 来检索各种应用和 Web 服务器的错误日志，去排查线上问题，如下所示：")]),e._v(" "),a("p",[a("code",[e._v('grep "error" access.log > /tmp/error.log.1')])]),e._v(" "),a("p",[e._v("在单台 Linux 服务器上，我们当然可以用一个 grep 命令。那么如果有很多台服务器，我们怎么才能知道在哪台机器上会有我们需要的错误日志呢？")]),e._v(" "),a("p",[e._v("**最简单的办法，当然就是在每台服务器上，都执行一遍相同的 grep 命令就好了。这个动作就是所谓的“分布式 grep”，**在整个 MapReduce 框架下，它其实就是一个只有 Map，没有 Reduce 的任务。")]),e._v(" "),a("p",[e._v("对于谷歌这个全球最大搜索引擎来说，"),a("strong",[e._v("这是完美地用来做网页预处理的方案")]),e._v("。通过网络爬虫抓取到的网页内容，你都可以直接存到 GFS 上，这样你就可以撰写一个 Map 函数，从 HTML 的网页中，提取网页里的标题、正文，以及链接。然后你可以再去撰写一个 Map 函数，对标题和正文进行关键词提取。")]),e._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/5aa81492a07af4898aa72038886d916c.jpg",alt:"img"}}),e._v(" "),a("p",[e._v("“分布式 grep”就是一个分布式抽取数据的抽象，无论是像 grep 一样通过一个正则表达式来提取内容，还是用复杂的算法和策略从输入中提取内容，都可以看成是一种“分布式 grep”。"),a("strong",[e._v("而在 MapReduce 这个框架下，你只需要撰写一个 Map 函数，并不需要关心数据存储在具体哪台机器上，也不需要关心哪台机器的硬件或者网络出了问题。")])]),e._v(" "),a("h4",{attrs:{id:"统计-url-的访问频次"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#统计-url-的访问频次"}},[e._v("#")]),e._v(" 统计 URL 的访问频次")]),e._v(" "),a("p",[e._v("这里，我们先以极客时间的专栏用户访问日志作为例子，来看看 MapReduce 可以怎么来统计访问频次。下面放了一个表格，我们把它叫做 url_visit_logs 。在这个表格里面有三个字段，分别是：")]),e._v(" "),a("ul",[a("li",[e._v("URL，记录用户具体是看专栏里的哪一篇文章；")]),e._v(" "),a("li",[e._v("USER_ID，记录具体是哪一个用户访问；")]),e._v(" "),a("li",[e._v("VISIT_TIME，记录用户访问的具体时间。")])]),e._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/2f4970c91bb78c137dceb953185f282d.jpg",alt:"img"}}),e._v(" "),a("p",[e._v("如果只是极客时间的网页，我们可以把这张表里面的数据放在数据库里面，通过一句 SQL 就可以完成了：")]),e._v(" "),a("p",[a("code",[e._v("SELECT URL, COUNT(*) FROM url_visit_logs GROUP BY URL ORDER BY URL")])]),e._v(" "),a("p",[e._v("但是如果考虑全网的数据网页访问日志，那么是一个非常庞大的数据量，可以把这些日志以文件的方式放在GFS上，然后用MapReduce来做数据统计。")]),e._v(" "),a("p",[e._v("具体流程如下：")]),e._v(" "),a("p",[e._v("输入数据是这样的：")]),e._v(" "),a("ul",[a("li",[e._v("Key 就是单条日志记录在文件中的行号；")]),e._v(" "),a("li",[e._v("Value 就是对应单条记录的字符串，不同字段之间以 Tab 分割。")])]),e._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/947abe5c03ff7ab69717286yyef8012c.jpg",alt:"img"}}),e._v(" "),a("p",[e._v("Map 函数只需要通过一个 split 或者类似的函数，对 Value 进行分割，拿到 URL，然后输出一个 List 的 key-value 对。在当前的场景下，这个 List 只有一个 key-value 对：")]),e._v(" "),a("blockquote",[a("p",[e._v("value也可以是1，因为这里出现一次url就代表有一次这个url的访问，这里记1感觉更合理")])]),e._v(" "),a("ul",[a("li",[e._v("输出的 Key 就是 URL；")]),e._v(" "),a("li",[e._v("输出的 Value 为空字符串。")])]),e._v(" "),a("p",[e._v("对于Reduce来说，MapReduce 框架会把所有相同 URL 的 Map 的输出记录，都混洗给到同一个 Reduce 函数里。Reduce拿到的输入数据是：")]),e._v(" "),a("ul",[a("li",[e._v("Key 就是 URL；")]),e._v(" "),a("li",[e._v("一个 List 的 Value，里面的每一项都是空字符串。")])]),e._v(" "),a("p",[e._v("Reduce 函数的逻辑也非常简单，就是把 list 里面的所有 Value 计个数，然后和前面的 Key 拼装到一起，并输出出去。Reduce 函数输出的 list 里，也只有这一个元素。")]),e._v(" "),a("blockquote",[a("p",[e._v("4个空，所以计数是4")])]),e._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/cb83f5289acbc0335a4f800b6a8ece61.jpg",alt:"img"}}),e._v(" "),a("p",[a("strong",[e._v("类比SQL执行这个过程：")])]),e._v(" "),a("ul",[a("li",[e._v("其中的 Map 过程，类似于 SELECT 关键字，从输入数据中提取出需要使用的 Key 和 Value 字段。")]),e._v(" "),a("li",[e._v("MapReduce 框架完成的混洗过程，类似于 SQL 中的 GROUP BY 关键字，根据相同的 Key，把 Map 中选择的数据混洗到一起。")]),e._v(" "),a("li",[e._v("最后的 Reduce 过程，就是先对混洗后数据中的 Value，执行了 COUNT 这个函数，然后再将 Key 和 COUNT 执行的结果拼装到一起，输出为最后的结果。")])]),e._v(" "),a("p",[a("strong",[e._v("类比Bash")])]),e._v(" "),a("p",[e._v("Hive 的 HQL 就是通过一个个 MapReduce 程序来实现的。而前面的整个 MapReduce 的过程，其实用一段 Bash 代码也可以实现。")]),e._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[e._v("cat")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token variable"}},[e._v("$input")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("|")]),e._v(" \n   "),a("span",{pre:!0,attrs:{class:"token function"}},[e._v("awk")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v("'{print $1}'")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("|")]),e._v("\n   "),a("span",{pre:!0,attrs:{class:"token function"}},[e._v("sort")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("|")]),e._v("\n   "),a("span",{pre:!0,attrs:{class:"token function"}},[e._v("uniq")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[e._v("-c")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token variable"}},[e._v("$output")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br")])]),a("p",[e._v("在这段代码中")]),e._v(" "),a("ul",[a("li",[e._v("cat 相当于我们 MapReduce 框架从 HDFS 读取数据；")]),e._v(" "),a("li",[e._v("awk 的脚本，是我们实现的 Map 函数；")]),e._v(" "),a("li",[e._v("sort 相当于 MapReduce 的混洗，只是这个混洗是在本机上执行的；")]),e._v(" "),a("li",[e._v("而最后的 uniq -c 则是实现了 Reduce 函数，在排好序的数据下，完成了同一 URL 的去重计数的工作。")])]),e._v(" "),a("p",[e._v("对比MapReduce框架，bash的操作可以这么理解：")]),e._v(" "),a("ul",[a("li",[e._v("读写 HDFS 文件的内容，对应着 cat 命令和标准输出；")]),e._v(" "),a("li",[e._v("对于数据进行混洗，对应着 sort 命令；")]),e._v(" "),a("li",[e._v("整个框架，不同阶段之间的数据传输，用的就是标准的输入输出管道。")])]),e._v(" "),a("blockquote",[a("p",[e._v("所以对于开发者而言，只需要实现Map和Reduce函数即可，其他都不用担心。而对于实现 MapReduce 的底层框架代码，也可以映射到读取、外部排序、输出，以及通过网络进行跨机器的数据传输就好了。在这个设计框架下，每一个组件都只需要完成自己的工作，整个框架就能很容易地串联起来了。")])]),e._v(" "),a("h3",{attrs:{id:"小结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[e._v("#")]),e._v(" 小结")]),e._v(" "),a("p",[e._v("作为一个框架，MapReduce 设计的一个重要思想，就是让使用者意识不到“分布式”这件事情本身的存在。从设计模式的角度，MapReduce 框架用了一个经典的设计模式，就是模版方法模式。而从设计思想的角度，MapReduce 的整个流程，类似于 Unix 下一个个命令通过管道把数据处理流程串接起来。")]),e._v(" "),a("p",[e._v("MapReduce 的数据处理设计很直观，并不难理解。Map 帮助我们解决了并行在很多台机器上处理互相之间没有依赖关系的数据；而 Reduce 则用来处理互相之间有依赖关系的数据，我们可以通过 MapReduce 框架自带的 Shuffle 功能，通过排序来根据设定好的 Key 进行分组，把相同 Key 的数据放到同一个节点上，供 Reduce 处理。")]),e._v(" "),a("p",[e._v("而作为 MapReduce 框架的使用者，你只需要实现 Map 和 Reduce 两个函数，并且指定输入输出路径，MapReduce 框架就会帮助你完成整个数据处理过程，不需要你去关心整个分布式集群的存在。另外，不仅仅是 MapReduce 的用户，只需要考虑“单一职责”，实现自己的 Map 和 Reduce 函数就好了。即使作为 MapReduce 的框架实现，也能够把数据读取、数据输出、网络传输、数据混洗等模块单独拆出来，实现起来也很容易。")]),e._v(" "),a("p",[e._v("Map 和 Reduce 这两个函数虽然非常简单，但是对于输入输出的格式，以及内部具体的逻辑代码没有任何限制，是完全灵活的，足以完成从日志分析、网页处理、数据统计，乃至于搜索引擎的索引生成工作。")]),e._v(" "),a("h2",{attrs:{id:"mapreduce-框架的三个挑战"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce-框架的三个挑战"}},[e._v("#")]),e._v(" MapReduce 框架的三个挑战")]),e._v(" "),a("blockquote",[a("p",[e._v("要想学习如何搭建和改进分布式系统，了解 MapReduce 的底层原理必不可少。今天，我们就一起来看看 MapReduce 的框架干了什么。MapReduce 这个“保姆”，为什么可以让你不需要处理复杂的分布式架构的问题。")])]),e._v(" "),a("p",[e._v("要想让写 Map 和 Reduce 函数的人不需要关心“分布式”的存在，那么 MapReduce 框架本身就需要解决好三个很重要的问题：")]),e._v(" "),a("ul",[a("li",[e._v("第一个，自然是如何做好各个服务器节点之间的“协同”，以及解决出现各种软硬件问题后的“容错”这两部分的设计。")]),e._v(" "),a("li",[e._v("第二个，是上一讲我们没怎么关心的性能问题。和我们在 GFS 论文里面讲过的一样，MapReduce 框架一样非常容易遇到网络性能瓶颈。尽量充分利用 MapReduce 集群的计算能力，并让整个集群的性能可以随硬件的增加接近于线性增长，可以说是非常大的一个挑战。")]),e._v(" "),a("li",[e._v("最后一个，还是要回到易用性。Map 函数和 Reduce 函数最终还是运行在多个不同的机器上的，并且在 Map 和 Reduce 函数中还会遇到各种千奇百怪的数据。当我们的程序在遭遇到奇怪的数据出错的时候，我们需要有办法来进行 debug。")])]),e._v(" "),a("p",[e._v("谷歌在论文里面，也通过第三部分的“MapReduce 的实现”，以及第四部分的“MapReduce 的完善”，很好地回答了怎么解决这三个问题。")]),e._v(" "),a("h3",{attrs:{id:"mapreduce-的协同"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce-的协同"}},[e._v("#")]),e._v(" MapReduce 的协同")]),e._v(" "),a("p",[e._v("一个 MapReduce 的集群，通常就是之前的分布式存储系统 GFS 的集群。在这个集群里，本身会有一个调度系统（Scheduler）。当我们要运行一个 MapReduce 任务的时候，其实就是把整个 MapReduce 的任务提交给这个调度系统，让这个调度系统来分配和安排 Map 函数和 Reduce 函数，以及后面会提到的 master 在不同的硬件上运行。")]),e._v(" "),a("p",[e._v("在 MapReduce 任务提交了之后，整个 MapReduce 任务就会按照这样的顺序来执行。")]),e._v(" "),a("p",[a("strong",[e._v("第一步")]),e._v("，你写好的 MapReduce 程序，已经指定了输入路径。所以 MapReduce 会先找到 GFS 上的对应路径，然后把对应路径下的所有数据进行分片（Split）。每个分片的大小通常是 64MB，这个尺寸也是 GFS 里面一个块（Block）的大小。接着，MapReduce 会在整个集群上，启动很多个 MapReduce 程序的复刻（fork）进程。")]),e._v(" "),a("p",[e._v("**第二步，**在这些进程中，有一个和其他不同的特殊进程，就是一个 master 进程，剩下的都是 worker 进程。然后，我们会有 M 个 map 的任务（Task）以及 R 个 reduce 的任务，分配给这些 worker 进程去进行处理。这里的 master 进程，是负责找到空闲的（idle）worker 进程，然后再把 map 任务或者 reduce 任务，分配给 worker 进程去处理。")]),e._v(" "),a("blockquote",[a("p",[e._v("并不是每一个 map 和 reduce 任务，都会单独建立一个新的 worker 进程来执行。而是 master 进程会把 map 和 reduce 任务分配给有限的 worker，因"),a("strong",[e._v("为一个 worker 通常可以顺序地执行多个 map 和 reduce 的任务")])])]),e._v(" "),a("p",[a("strong",[e._v("第三步")]),e._v("，被分配到 map 任务的 worker 会读取某一个分片，分片里的数据就像上一讲所说的，变成一个个 key-value 对喂给了 map 任务，然后等 Map 函数计算完后，会生成的新的 key-value 对缓冲在内存里。")]),e._v(" "),a("p",[a("strong",[e._v("第四步")]),e._v("，这些缓冲了的 key-value 对，会定期地写到 map 任务所在机器的本地硬盘上。并且按照一个分区函数（partitioning function），把输出的数据分成 R 个不同的区域。而这些本地文件的位置，会被 worker 传回给到 master 节点，再由 master 节点将这些地址转发给 reduce 任务所在的 worker 那里。")]),e._v(" "),a("p",[a("strong",[e._v("第五步")]),e._v("，运行 reduce 任务的 worker，在收到 master 的通知之后，会通过 RPC（远程过程调用）来从 map 任务所在机器的本地磁盘上，抓取数据。当 reduce 任务的 worker 获取到所有的中间文件之后，它就会将中间文件根据 Key 进行排序。这样，所有相同 Key 的 Value 的数据会被放到一起，也就是完成了我们上一讲所说的混洗（Shuffle）的过程。")]),e._v(" "),a("p",[e._v("**第六步，**reduce 会对排序后的数据执行实际的 Reduce 函数，并把 reduce 的结果输出到当前这个 reduce 分片的最终输出文件里。")]),e._v(" "),a("p",[a("strong",[e._v("第七步")]),e._v("，当所有的 map 任务和 reduce 任务执行完成之后，master 会唤醒启动 MapReduce 任务的用户程序，然后回到用户程序里，往下执行 MapReduce 任务提交之后的代码逻辑。")]),e._v(" "),a("p",[e._v("整个 MapReduce 的执行过程，**还是一个典型的 Master-Slave 的分布式系统。**map 和 reduce 所在的 worker 之间并不会直接通信，它们都只和 master 通信。另外，像是 map 的输出数据在哪里这样的信息，也是告诉 master，让 master 转达给 reduce 所在的 worker。"),a("strong",[e._v("reduce 从 map 里获取数据，也是直接拿到数据所在的地址去抓取，而不是让 reduce 通过 RPC，调用 map 所在的 worker 去获取数据。")])]),e._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/fe9a03016b995b0c0581ce23d2b4c98d.jpg",alt:"img"}}),e._v(" "),a("h3",{attrs:{id:"mapreduce-的容错-fault-tolerance"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce-的容错-fault-tolerance"}},[e._v("#")]),e._v(" MapReduce 的容错（Fault Tolerance）")]),e._v(" "),a("p",[e._v("MapReduce 的容错机制非常简单，可以简单地用两个关键词来描述，就是"),a("strong",[e._v("重新运行和写 Checkpoints。")])]),e._v(" "),a("p",[e._v("对于 worker 节点的失效，MapReduce 框架解决问题的方式非常简单。就是换一台服务器重新运行这个 worker 节点被分配到的所有任务。master 节点会定时地去 ping 每一个 worker 节点，一旦 worker 节点没有响应，我们就会认为这个节点失效了。")]),e._v(" "),a("p",[a("strong",[e._v("于是，我们会重新在另一台服务器上，启动一个 worker 进程，并且在新的 worker 进程所在的节点上，重新运行所有失效节点上被分配到的任务")]),e._v("。而无论失效节点上，之前的 map 和 reduce 任务是否执行成功，这些任务都会重新运行。因为在节点 ping 不通的情况下，我们很难保障它的本地硬盘还能正常访问。")]),e._v(" "),a("blockquote",[a("p",[e._v("这个情况遇到过：简单来说是一个reduce占用内存很大的任务，在一个内存较小的服务器上失败了。然后这个任务又被重新分配到另一个服务器的新worker上。")]),e._v(" "),a("p",[e._v("那时用的是Hadoop，不过Hadoop就是MapReduce的开源实现")])]),e._v(" "),a("h4",{attrs:{id:"worker-节点的失效-worker-failure"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#worker-节点的失效-worker-failure"}},[e._v("#")]),e._v(" worker 节点的失效（Worker Failure）")]),e._v(" "),a("p",[e._v("对于 worker 节点的失效，MapReduce 框架解决问题的方式非常简单。就是换一台服务器重新运行这个 worker 节点被分配到的所有任务。master 节点会定时地去 ping 每一个 worker 节点，一旦 worker 节点没有响应，我们就会认为这个节点失效了。")]),e._v(" "),a("p",[e._v("于是，我们会重新在另一台服务器上，启动一个 worker 进程，并且在新的 worker 进程所在的节点上，重新运行所有失效节点上被分配到的任务。而无论失效节点上，之前的 map 和 reduce 任务是否执行成功，这些任务都会重新运行。因为在节点 ping 不通的情况下，我们很难保障它的本地硬盘还能正常访问。")]),e._v(" "),a("h4",{attrs:{id:"master-节点的失效-master-failure"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#master-节点的失效-master-failure"}},[e._v("#")]),e._v(" master 节点的失效（Master Failure）")]),e._v(" "),a("p",[e._v("对于 master 节点的失效，事实上谷歌已经告诉了我们，他们就任由 master 节点失败了，也就是整个 MapReduce 任务失败了。那么，对于开发者来说，解决这个问题的办法也很简单，就是再次提交一下任务去重试。")]),e._v(" "),a("p",[e._v("因为 master 进程在整个任务中只有一个，它会失效的可能性很小。"),a("strong",[e._v("而 MapReduce 的任务也是一个用户离线数据处理的任务，并不是一个实时在线的服务，失败重来通常也没有什么影响，只是晚一点拿到数据结果罢了。")])]),e._v(" "),a("p",[e._v("论文并没有实现对于 master 的失效自动恢复机制，但他们也给出了一个很简单的解决方案，"),a("strong",[e._v("那就是让 master 定时把它里面存放的信息，作为一个个的 Checkpoint 写入到硬盘中去。")])]),e._v(" "),a("p",[e._v("我们可以把这个 Checkpoint 直接写到 GFS 里，然后让调度系统监控 master。这样一旦 master 失效，"),a("strong",[e._v("我们就可以启动一个新的 master，来读取 Checkpoints 数据，然后就可以恢复任务的继续执行了，而不需要重新运行整个任务。")])]),e._v(" "),a("h4",{attrs:{id:"对错误数据视而不见"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#对错误数据视而不见"}},[e._v("#")]),e._v(" 对错误数据视而不见")]),e._v(" "),a("p",[e._v("worker 和 master 的节点失效，以及对应的恢复机制，通常都是来自于硬件问题。但是在海量数据处理的情况下，比如在 TB 乃至 PB 级别的数据下，我们还会经常遇到“脏数据”的问题。")]),e._v(" "),a("p",[e._v("这些数据，可能是日志采集的时候就出错了，也可能是一个非常罕见的边界情况（edge-case），我们的 Map 和 Reduce 函数正好处理不了。甚至有可能，只是简单的硬盘硬件的问题带来的错误数据。")]),e._v(" "),a("blockquote",[a("p",[e._v("那么，对于这些异常数据，我们固然可以不断 debug，一一修正。但是这么做，大多数时候都是划不来的，你很可能为了一条数据记录，"),a("strong",[e._v("由于 Map 函数处理不了，你就要重新扫描几 TB 的数据。")])]),e._v(" "),a("p",[e._v("这个情况应该也遇到过，就是数据中的某条数据处理出错，但是因为数据量很大，所以忽视这个出错的也没啥问题。")])]),e._v(" "),a("p",[e._v("以，"),a("strong",[e._v("MapReduce 不仅为节点故障提供了容错机制，对于这些极少数的数据异常带来的问题，也提供了一个容错机制。MapReduce 会记录 Map 或者 Reduce 函数，运行出错的具体数据的行号，如果同样行号的数据执行重试还是出错")]),e._v("，它就会跳过这一行的数据。如果这样的数据行数在总体数据中的比例很小，那么整个 MapReduce 程序会忽视这些错误，仍然执行完成。毕竟，一个 URL 被访问了 1 万次还是 9999 次，对于搜素引擎的排序结果不会有什么影响。")]),e._v(" "),a("h3",{attrs:{id:"mapreduce-的性能优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce-的性能优化"}},[e._v("#")]),e._v(" MapReduce 的性能优化")]),e._v(" "),a("p",[e._v("其实 MapReduce 的集群就是 GFS 的集群。所以 MapReduce 集群里的硬件配置，和 GFS 的硬件配置差不多，最容易遇到的性能瓶颈，也是 100MB 或者 1GB 的网络带宽（因为那时候是2004年，不过今天看来也不过时）。")]),e._v(" "),a("h4",{attrs:{id:"把程序搬到数据那儿去"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#把程序搬到数据那儿去"}},[e._v("#")]),e._v(" 把程序搬到数据那儿去")]),e._v(" "),a("p",[e._v("既然网络带宽是瓶颈，"),a("strong",[e._v("那么优化的办法自然就是尽可能减少需要通过网络传输的数据。")])]),e._v(" "),a("p",[e._v("在 MapReduce 这个框架下，就是在分配 map 任务的时候，根据需要读取的数据在哪里进行分配。通过前面 GFS 论文的学习，我们可以知道，GFS 是知道每一个 Block 的数据是在哪台服务器上的。而 MapReduce，会找到同样服务器上的 worker，来分配对应的 map 任务。如果那台服务器上没有，那么它就会找离这台服务器最近的、有 worker 的服务器，来分配对应的任务。你可以参考下面给出的示意图：")]),e._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/23b33f40bf6d1c8a3eaf8f5d8d5254e4.jpg",alt:"img"}}),e._v(" "),a("p",[e._v("除此之外，由于 MapReduce 程序的代码往往很小，可能只有几百 KB 或者几 MB，但是每个 map 需要读取的一个分片的数据是 64MB 大小。这样，我们通过把要执行的 MapReduce 程序，复制到数据所在的服务器上，就不用多花那 10 倍乃至 100 倍的网络传输量了。")]),e._v(" "),a("h4",{attrs:{id:"通过-combiner-减少网络数据传输"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#通过-combiner-减少网络数据传输"}},[e._v("#")]),e._v(" 通过 Combiner 减少网络数据传输")]),e._v(" "),a("p",[e._v("除了 Map 函数需要读取输入的分片数据之外，Reduce 所在的 worker 去抓取中间数据，一样也需要通过网络。"),a("strong",[e._v("那么要在这里减少网络传输，最简单的办法，就是尽可能让中间数据的数据量小一些。")])]),e._v(" "),a("p",[a("strong",[e._v("MapReduce 允许开发者自己定义一个 Combiner 函数")]),e._v("。这个 Combiner 函数，会对在同一个服务器上所有 map 输出的结果运行一次，然后进行数据合并。")]),e._v(" "),a("p",[e._v("以之前提到的统计域名访问次数为例：")]),e._v(" "),a("p",[e._v("而对于用户会高频访问的网站，在 map 输出的中间结果里就会有很多条记录，比如用户访问了 baidu.com、douyin.com 这样的域名就会有大量的记录。这些记录的 Key 就是对应的 baidu.com、douyin.com 的域名，而 value 都是 1。")]),e._v(" "),a("p",[e._v("既然只是对访问次数计数，我们自然就可以通过一个 Combiner，"),a("strong",[e._v("把 1 万条相同域名的访问记录做个化简。把它们变成 Key 还是域名，Value 就是有多少次访问的数值这样的记录就好了。而这样一化简，reduce 所在的 worker 需要抓取的数据，就从 1 万条变成了 1 条。")])]),e._v(" "),a("p",[a("strong",[e._v("实际上，不仅是同一个 Map 函数的输出可以合并，同一台服务器上多个 Map 的输出，我们都可以合并，反正利用的是本地的资源。")])]),e._v(" "),a("p",[e._v("提升了多少效率？以域名的访问次数为例，它的数据分布一定有很强的头部效应，少量 20% 的域名可能占了 80% 的访问记录，**这样一合并，我们要传输的数据至少可以减少 60%。**这样通过一个中间Combiner，我们传输的数据一下子少了很多，大大缓解了网络传输压力。")]),e._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/3e849249397c9558a87e6c11e76c3059.jpg",alt:"img"}}),e._v(" "),a("h3",{attrs:{id:"mapreduce-的-debug-信息"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce-的-debug-信息"}},[e._v("#")]),e._v(" MapReduce 的 debug 信息")]),e._v(" "),a("p",[e._v("我们来看一下MapReduce对开发者的易用性。")]),e._v(" "),a("p",[e._v("map 和 reduce 的任务都是在分布式集群上运行的，这个就给我们对程序 debug 带来了很大的挑战。无论是通过 debugger 做单步调试，还是打印出日志来看程序执行的情况，都不太可行。所以，MapReduce 也为开发者贴心地提供了三个办法来解决这一点。")]),e._v(" "),a("ul",[a("li",[e._v("第一个，"),a("strong",[e._v("是提供一个单机运行的 MapReduce 的库")]),e._v("，这个库在接收到 MapReduce 任务之后，会在本地执行完成 map 和 reduce 的任务。这样，你就可以通过拿一点小数据，在本地调试你的 MapReduce 任务了，无论是 debugger 还是打日志，都行得通。")]),e._v(" "),a("li",[e._v("第二个，"),a("strong",[e._v("是在 master 里面内嵌了一个 HTTP 服务器，然后把 master 的各种状态展示出来给开发者看到")]),e._v("。这样一来，你就可以看到有多少个任务执行完了，有多少任务还在执行过程中，它处理了多少输入数据，有多少中间数据，有多少输出的结果数据，以及任务完成的百分比等等。同样的，里面还有每一个任务的日志信息。另外通过这个 HTTP 服务器，"),a("strong",[e._v("你还可以看到具体是哪一个 worker 里的任务失败了，对应的错误日志是什么。")])]),e._v(" "),a("li",[e._v("后一个，"),a("strong",[e._v("是 MapReduce 框架里提供了一个计数器（counter）的机制")]),e._v("。作为开发者，你可以自己定义几个计数器，然后在 Map 和 Reduce 的函数里去调用这个计数器进行自增。所有 map 和 reduce 的计数器都会汇总到 master 节点上，通过上面的 HTTP 服务器里展现出来。")])]),e._v(" "),a("h3",{attrs:{id:"小结-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结-2"}},[e._v("#")]),e._v(" 小结")]),e._v(" "),a("p",[e._v("和 GFS 一样，MapReduce 的实现是比较简单的，"),a("strong",[e._v("就是一个典型的单 master 多 worker 组成的主从架构。在分布式系统容错上，"),a("strong",[e._v("MapReduce 也采取")]),e._v("了简单的重新运行、再来一次的方案")]),e._v("。对于 master 这个单点可能出现的故障，谷歌在最早的实现里，根本就没有考虑失效恢复，"),a("strong",[e._v("而是选择了任由 master 失败，让开发人员重新提交任务重试的办法。")])]),e._v(" "),a("blockquote",[a("p",[e._v("为了省带宽做了诸多优化")])]),e._v(" "),a("p",[e._v("还有一点也和 GFS 一样，MapReduce 论文发表时的硬件，用的往往是 100MB 或者 1GB 的网络带宽。所以 MapReduce 框架对于这一点，就做了不少性能优化动作。通过尽量让各个 worker 从本地硬盘读取数据，以及通过 Combiner 合并本地 Map 输出的数据，来尽可能减少数据在网络上的传输。")]),e._v(" "),a("p",[a("strong",[e._v("MapReduce 里还有备用任务（Backup Tasks）、自定义的 Partitioner 等更多的细节。")])]),e._v(" "),a("p",[a("strong",[e._v("MapReduce的遗憾：")])]),e._v(" "),a("ul",[a("li",[e._v("没有完全达到让用户感受不到这是分布式系统")]),e._v(" "),a("li",[e._v("性能仍然不够理想，这体现在两个方面，"),a("strong",[e._v("一个是每个任务都有比较大的 overhead，都需要预先把程序复制到各个 worker 节点，然后启动进程；另一个是所有的中间数据都要读写多次硬盘。map 的输出结果要写到硬盘上，reduce 抓取数据排序合并之后，也要先写到本地硬盘上再进行读取，所以快不起来。")])])]),e._v(" "),a("h2",{attrs:{id:"拓展阅读"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#拓展阅读"}},[e._v("#")]),e._v(" 拓展阅读")]),e._v(" "),a("blockquote",[a("p",[e._v("1.MapReduce 是一个典型的模版方法模式，你可以去读一读《[设计模式][https://book.douban.com/subject/1052241/]》这本书的 5.10 小节。事实上，在整个大数据领域中，我们处处可以看到各种不同设计模式的身影。")]),e._v(" "),a("p",[e._v("2.对于分布式系统，我们总是希望增加机器就能够带来同比例的性能提升，但是这一点其实很难做到。Storm 的作者南森·马茨（Nathan Marz）在 2010 年就发表过一个很有意思的博文，告诉大家为什么优化 MapReduce 任务 30% 的运行时间，就会减少 80% 任务实际消耗的时间。")]),e._v(" "),a("p",[e._v("[这篇文章][http://nathanmarz.com/blog/the-mathematics-behind-hadoop-based-systems.html]应该更加有助于你理解为什么我们说 MapReduce 的遗憾与缺陷中提到的额外开销（overhead）问题。我把这篇文章的链接放在这里，推荐你去阅读学习一下。")])]),e._v(" "),a("h2",{attrs:{id:"q-a"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#q-a"}},[e._v("#")]),e._v(" Q&A:")]),e._v(" "),a("p",[e._v("1.在前面的 URL 访问频次的应用场景中，我们只是简单地做了单个 URL 的访问频次统计。如果我们想提出两个新需求，一个是不再按照 URL 统计访问频次，而是按照域名统计，第二个是统计结果要按访问的人数多少从高到底排序，我们应该怎么做呢？这个逻辑我们也能通过 Bash 来实现吗？")]),e._v(" "),a("p",[e._v("2.在用 MapReduce 处理数据的时候，因为数据不平衡，可能会使得 MapReduce 的任务运行得很慢。MapReduce 论文里面给出的解决方法，是通过开发人员自己去实现一个分区函数。不过，一旦需要开发人员自己思考如何分片，其实已经让我们要意识到这个“分布式”本身的存在了。那么，如果让你在 MapReduce 框架层面解决好这一个问题，你觉得有什么好办法吗？")])])}),[],!1,null,null,null);a.default=t.exports}}]);