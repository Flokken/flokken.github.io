(window.webpackJsonp=window.webpackJsonp||[]).push([[262],{591:function(t,a,v){"use strict";v.r(a);var _=v(4),r=Object(_.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("blockquote",[a("p",[a("a",{attrs:{href:"https://time.geekbang.org/column/article/420448",target:"_blank",rel:"noopener noreferrer"}},[t._v("建立你的大数据知识网络"),a("OutboundLink")],1)])]),t._v(" "),a("img",{staticStyle:{zoom:"100%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/928e1c25e9b4332d9d897b40de8a972d.jpg"}}),t._v(" "),a("center",[t._v(" 大数据思维导图")]),t._v(" "),a("h2",{attrs:{id:"分布式系统"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分布式系统"}},[t._v("#")]),t._v(" 分布式系统")]),t._v(" "),a("p",[t._v("所有的大数据系统都是分布式系统。我们需要大数据系统，就是因为普通的单机已经无法满足我们期望的性能了。那么"),a("strong",[t._v("作为一个分布式的数据系统，它就需要满足三个特性，也就是可靠性、可扩展性和可维护性。")])]),t._v(" "),a("p",[t._v("作为一个数据系统，我们需要可靠性。如果只记录一份数据，那么当硬件故障的时候就会遇到丢数据的问题，所以我们需要对数据做复制。而数据复制之后，以哪一份数据为准，"),a("strong",[t._v("又给我们带来了主从架构、多主架构以及无主架构的选择")]),t._v("。")]),t._v(" "),a("p",[t._v("然后，在最常见的主从架构里，我们根据复制过程，"),a("strong",[t._v("可以有同步复制和异步复制之分")]),t._v("。同步复制的节点可以作为高可用切换的 Backup Master，而异步复制的节点只适合作为只读的 Shadow Master。")]),t._v(" "),a("p",[t._v("第二个重要的特性是"),a("strong",[t._v("可扩展性")]),t._v("。在“大数据”的场景下，单个节点存不下所有数据，于是就有了数据分区。常见的分区方式有两种，第一种是通过"),a("strong",[t._v("区间进行分片")]),t._v("，典型的代表就是 Bigtable，第二种是通过哈希进行分区，在大型分布式系统中常用的是"),a("strong",[t._v("一致性 Hash，典型的代表是 Cassandra")]),t._v("。")]),t._v(" "),a("p",[t._v("最后一点就是整个系统"),a("strong",[t._v("的可维护性")]),t._v("。我们需要考虑容错，在硬件出现故障的时候系统仍然能够运作。我们还需要考虑恢复，也就是当系统出现故障的时候，仍能快速恢复到可以使用的状态。而为了确保我们不会因为部分网络的中断导致作出错误的判断，我们就需要利用共识算法，来确保系统中能够对哪个节点正在正常服务作出判断。"),a("strong",[t._v("这也就引出了 CAP 这个所谓的“不可能三角”。")])]),t._v(" "),a("blockquote",[a("p",[t._v("一致性（Consistency），可用性(Availability)，分区容错性（Partition Tolerance）")])]),t._v(" "),a("p",[t._v("而分布式系统的核心问题就是 CAP 这个不可能三角，"),a("strong",[t._v("我们需要在一致性、可用性和分区容错性之间做权衡和选择。因此，我们选择的主从架构、复制策略、分片策略，以及容错和恢复方案，都是根据我们实际的应用场景下对于 CAP 进行的权衡和选择。")])]),t._v(" "),a("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/1783016bc1c272074ede6e592a567767.jpg"}}),t._v(" "),a("h2",{attrs:{id:"单节点存储引擎"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#单节点存储引擎"}},[t._v("#")]),t._v(" 单节点存储引擎")]),t._v(" "),a("p",[t._v("第一个是"),a("strong",[t._v("事务")]),t._v("。在写入数据的时候，我们需要保障写入的数据是原子的、完整的。在传统的数据库领域，我们有 ACID 这样的事务特性，也就是原子性（Atomic）、一致性（Consistency）、隔离性（Isolation）以及持久性（Durability）。而在大数据领域，很多时候因为分布式的存在，我们常常会退化到一个叫做 BASE 的模型。BASE 代表着基本可用（Basically Available）、软状态（Soft State）以及最终一致性（Eventually Consistent）。")]),t._v(" "),a("blockquote",[a("p",[t._v("ACID模型，BASE模型")])]),t._v(" "),a("p",[t._v("不过无论是 ACID 还是 BASE，"),a("strong",[t._v("在单机上，我们都会使用预写日志（WAL）、快照（Snapshot）和检查点（Checkpoints）以及写时复制（Copy-on-Write）这些技术，来保障数据在单个节点的写入是原子的")]),t._v("。而只要写入的数据记录是在单个分片上，我们就可以保障数据写入的事务性，所以我们很容易可以做到单行事务，或者是进一步的实体组（Entity Group）层面的事务。")]),t._v(" "),a("p",[t._v("第二个是底层的数据是如何写入和存储的。这个既要考虑到计算机硬件的特性，**比如数据的顺序读写比随机读写快，在内存上读写比硬盘上快；**也要考虑到我们在算法和数据结构中的时空复杂度，比如 Hash 表的时间复杂度是 O(1)，B+ 树的时间复杂度是 O(logN)。")]),t._v(" "),a("p",[t._v("这样，通过结合硬件性能、数据结构和算法特性，我们会看到分布式数据库最常使用的，其实是"),a("strong",[t._v("基于 LSM 树（Log-Structured Merge Tree）的 MemTable+SSTable 的解决方案。")])]),t._v(" "),a("p",[t._v("第三个则是**数据的序列化问题。**出于存储空间和兼容性的考虑，我们会选用 Thrift 这样的二进制序列化方案。而为了在分析数据的时候尽量减少硬盘吞吐量，我们则要研究 Parquet 或者 ORCFile 这样的列存储格式。然后，为了在 CPU、网络和硬盘的使用上取得平衡，我们又会选择 Snappy 或者 LZO 这样的快速压缩算法。")]),t._v(" "),a("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/ca5d48c1579869015f9d5c5788204c17.jpg"}}),t._v(" "),a("h2",{attrs:{id:"计算引擎"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#计算引擎"}},[t._v("#")]),t._v(" 计算引擎")]),t._v(" "),a("p",[t._v("这个维度实际上也是大数据领域本身进化和迭代最快的一部分。为什么会这么说呢？让我们来一起捋一下大数据处理引擎的进化过程：")]),t._v(" "),a("ul",[a("li",[t._v("我们先有了最原始粗糙的 MapReduce 来进行批数据处理，然后围绕它不断迭代出了让"),a("strong",[t._v("数据处理更快的 Spark 和让数据处理更容易的各种 DSL（比如 Sawzall/Pig 和 Hive）。")])]),t._v(" "),a("li",[t._v("然后我们围绕着**实时数据处理，**有了“最少一次”的 S4/Storm，并把它和批处理综合到一起，产生了著名的 Lambda 架构。")]),t._v(" "),a("li",[t._v("紧接着有了**“以批为流”**，通过 Mini-Batch 来进行实时数据处理的 Spark Streaming，以及“流批一体”，能够做到“正好一次”的 Kafka 和 Kappa 结构。")]),t._v(" "),a("li",[t._v("最后，还是 Google 一锤定音，"),a("strong",[t._v("给出了统一的 Dataflow 模型，并伴随着有了 Apache Flink 和 Apache Beam 这两个开源项目。")])])]),t._v(" "),a("p",[t._v("分布式问题，往往脱胎于少量经典论文的算法证明；单节点的存储引擎，也是一个自计算机诞生起就被反复研究的问题，这两者其实往往是经典论文的再现。但是在上千个服务器上的计算引擎应该怎么做，则是一个巨大的工程实践问题，我们没有太多可以借鉴的经验。这也是为什么计算引擎的迭代和变化是最大的。")]),t._v(" "),a("p",[t._v("随着 Dataflow 论文的发表，我们可以看到整个大数据的处理引擎，逐渐收敛成了一个统一的模型，大数据领域发展也算有了一个里程碑。")]),t._v(" "),a("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/c8b0d26697cd31216358055e5c68a9bd.jpg"}}),t._v(" "),a("h2",{attrs:{id:"调度系统和综合应用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#调度系统和综合应用"}},[t._v("#")]),t._v(" 调度系统和综合应用")]),t._v(" "),a("p",[t._v("总结来说，**分布式系统、存储引擎和计算引擎就共同构成了大数据的核心技术。**更进一步，随着多种分布式系统的混排，又产生了 Kubernetes 这样的资源管理和调度系统。而所有的这些技术之间，都不是各自独立，而是相互关联的。")]),t._v(" "),a("h2",{attrs:{id:"大数据技术是计算机科学中很多科目的综合应用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#大数据技术是计算机科学中很多科目的综合应用"}},[t._v("#")]),t._v(" 大数据技术是计算机科学中很多科目的综合应用")]),t._v(" "),a("p",[t._v("我们可以看到在单节点上的存储引擎，就是要综合考虑组成原理、算法和数据结构以及数据库原理相关的知识。而序列化和压缩，前者是组成原理里的二进制编码问题，后者则脱胎于算法和数据结构中的赫夫曼树和赫夫曼编码。")]),t._v(" "),a("p",[t._v("另外，最终选择什么算法做压缩，又要回到组成原理中，对于 CPU、网络以及硬盘的硬件性能进行平衡和考量。而针对分布式事务，我们一方面需要理解单机下的"),a("strong",[t._v("数据库事务，另一方面需要理解分布式环境下的 CAP 不可能三角")]),t._v("。只有这样，我们才能对于 Paxos 以及 Raft 这些共识算法有深入的理解。")]),t._v(" "),a("p",[t._v("而当我们要优化海量数据的分析效率，需要修改的反而是单节点存储引擎，"),a("strong",[t._v("因为只有通过列式存储，我们才能优化海量数据分析中的瓶颈：读取硬盘数据的 IO。")])]),t._v(" "),a("p",[t._v("因此，从我的认知来看，"),a("strong",[t._v("大数据系统的知识点不是一棵树，而是一张网")]),t._v("。当你学明白了整个大数据系统的知识点和原理之后，自然就有了深厚的计算机科学和工程的功底。它能给你一种，“天下虽大，何处去不得”的信心。")]),t._v(" "),a("h2",{attrs:{id:"如何精读论文"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何精读论文"}},[t._v("#")]),t._v(" 如何精读论文？")]),t._v(" "),a("p",[t._v("面对这些相对分散和全面的知识点，是学习大数据论文的第一层挑战。而论文本身往往也很精炼，则是学习过程中的第二层挑战。")]),t._v(" "),a("h4",{attrs:{id:"从第一性原理出发-尝试自己去设计系统和解决问题。"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#从第一性原理出发-尝试自己去设计系统和解决问题。"}},[t._v("#")]),t._v(" 从第一性原理出发，尝试自己去设计系统和解决问题。")]),t._v(" "),a("p",[t._v("在读论文之前，先尝试自己去思考和解决对应的问题，有助于你更深刻地理解问题和解决方案的重点。")]),t._v(" "),a("p",[t._v("比如，在学习 Megastore 的论文之前，你可以问一问自己下面这两个问题：")]),t._v(" "),a("ul",[a("li",[t._v("如果要在 Bigtable 上为数据表加上 Schema，我该怎么做？")]),t._v(" "),a("li",[t._v("如果我希望能够在 Bigtable 上，支持跨行事务，可以从哪里起步？")])]),t._v(" "),a("p",[t._v("带着你对问题的思考和方案去读论文，你的收获一定比囫囵吞枣地读一遍要多得多。")]),t._v(" "),a("h3",{attrs:{id:"多做交叉阅读和扩展阅读。"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#多做交叉阅读和扩展阅读。"}},[t._v("#")]),t._v(" 多做交叉阅读和扩展阅读。")]),t._v(" "),a("p",[t._v("根据你需要深入了解的知识点，你可能要回顾之前已经解读过的论文，也可能需要去阅读一些开源项目的代码，或者是一些计算机经典书籍中相关的章节，帮你彻底理解对应的问题。")]),t._v(" "),a("p",[t._v("比如，学习 Bigtable 论文的时候，论文里只告诉你底层的数据存储是 SSTable。而通过学习 LSM 树，或者是去读一下 LevelDB 的源码，你不仅可以理解 SSTable 的底层实现。还能帮助你深入理解针对硬件性能去设计数据结构，乃至系统中特定的组件。当然，我在课程的讲解中，也会给你推荐一系列的扩展阅读资料，帮助你找到更多的学习线索。")]),t._v(" "),a("h2",{attrs:{id:"目标-泛读和精读、理论和实践的结合。"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#目标-泛读和精读、理论和实践的结合。"}},[t._v("#")]),t._v(" 目标，泛读和精读、理论和实践的结合。")]),t._v(" "),a("p",[t._v("大数据的论文，是一个一个“点”，但是每一个点深挖下去，都可以串联到大量的理论和工程知识。大数据的论文，是一个一个“点”，但是每一个点深挖下去，都可以串联到大量的理论和工程知识。而如果通过阅读论文追求学得“多”，其实意义并不大。最合适的学习方法，我认为是有针对性地针对自己的目标，来学习这个课程。")]),t._v(" "),a("p",[t._v("**如果你的工作就是开发和维护大数据系统中的某个项目，**比如 HBase、Flink，那么你就精读对应的论文，泛读其他的相关论文，并对于你所关心的项目源码进行深入挖掘。搞清楚每一个设计背后选择的根本原因，搞清楚它为什么这么设计。")]),t._v(" "),a("p",[a("strong",[t._v("如果你原先是做后端应用开发，想要学习大数据知识，转向大数据领域的开发")]),t._v("。那么，搞清楚每篇论文和每个系统的应用场景，尝试通过 Google Cloud 或者其他的云系统，多尝试用一用这些大数据系统，会更有帮助。")]),t._v(" "),a("p",[a("strong",[t._v("如果你就是想要提升自己的理论知识和架构能力，那么我建议你放慢节奏。搞清楚论文里每一个关键设计点的原理")]),t._v("，尽量多阅读我给到的推荐阅读材料。甚至你不妨可以动手试一试，去实现其中的一些算法和组件，这是最有效的办法。")]),t._v(" "),a("p",[t._v("归根到底，**学习的成效不是表面知识知道得多，而是要真的掌握和理解这些知识。**AngelList 的创始人纳瓦尔·拉威康（Naval Ravikant）说过：")]),t._v(" "),a("center",[t._v(" 知识是一座摩天大楼。你可以在记忆的脆弱基础上走捷径，或者在理解的钢架上慢慢建立。")]),t._v(" "),a("blockquote",[a("p",[t._v("推荐")]),t._v(" "),a("p",[t._v("DDIA")]),t._v(" "),a("p",[t._v("分布式应用场景https://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf")])])],1)}),[],!1,null,null,null);a.default=r.exports}}]);