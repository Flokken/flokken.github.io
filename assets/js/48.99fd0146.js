(window.webpackJsonp=window.webpackJsonp||[]).push([[48],{377:function(s,t,a){"use strict";a.r(t);var n=a(4),r=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h2",{attrs:{id:"什么是自然语言处理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#什么是自然语言处理"}},[s._v("#")]),s._v(" 什么是自然语言处理？")]),s._v(" "),t("p",[s._v("所谓自然语言处理（Natural  Language   Processmg， NLP）。顾名思义就是处理自然语言的科学简单地说：它是一种能够让计算机理解人类语言的 技术。换言之，自然语言处理的"),t("strong",[s._v("目标就是让计算机理解人说的话,进而完成对我们有帮助的事情。")])]),s._v(" "),t("h3",{attrs:{id:"单词含义"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#单词含义"}},[s._v("#")]),s._v(" 单词含义")]),s._v(" "),t("p",[s._v("我们的语言由单词构成，而语言的含义就是由单词的含义构成的，换句话说，单词是含义的最小单位。因此，为了让计算机理解自然语言，最重要的事可以说是理解单词含义。")]),s._v(" "),t("p",[s._v("要让计算机理解单词含义，那当然需要将其表现成他理解的形式，一般由三种单词表现方法")]),s._v(" "),t("ul",[t("li",[s._v("基于同义词词典的方法")]),s._v(" "),t("li",[s._v("基于计数的方法")]),s._v(" "),t("li",[s._v("基于推理的方法")])]),s._v(" "),t("h3",{attrs:{id:"基于同义词词典的方法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基于同义词词典的方法"}},[s._v("#")]),s._v(" 基于同义词词典的方法")]),s._v(" "),t("p",[s._v("在同义词词 典中，具有相同含义的单词（同义词）或含义类似的单词（近义词）被归 类到同一个组")]),s._v(" "),t("p",[s._v("比如’使用同义词词典’我们可以知道car的同义司有 automobile、motorcar等")]),s._v(" "),t("p",[t("img",{attrs:{src:"C:/Users/86180/AppData/Roaming/Typora/typora-user-images/image-20230404160720664.png",alt:"image-20230404160720664"}})]),s._v(" "),t("p",[s._v("另外,在自然语言处理中用到的同义词词典有时会"),t("strong",[s._v("定义单词之间的粒度更细的关系")]),s._v(",比如“上位-下位”关系、“整体—部分”关系。举个例子, 如图2-2所示,我们利用图结构定义了各个单词之间的关系")]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230404161017008.png"}}),s._v(" "),t("p",[s._v("在图2-2中，单词motorvehicle（机动车）是单词car的上位概念，car的下位概念有SUV，compact和hatch-back等更加具体的车种")]),s._v(" "),t("p",[s._v("像这样通过对所有单词创建近义词集合,并用图表示各个单词的关 系,可以定义单词之间的联系，利用这个单词网络，可以教会计算机单 词之间的相关性。")]),s._v(" "),t("h4",{attrs:{id:"worldnet"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#worldnet"}},[s._v("#")]),s._v(" WorldNet")]),s._v(" "),t("p",[s._v("在自然语言处理领域,最著名的同义词词典是WordNet，WordNet 是普林斯顿大学于1985年开始开发的同义词词典。")]),s._v(" "),t("p",[s._v("使用WordNet’可以获得单词的近义词,或者利用单词网络，使用单词网络，可以计算单词之间的相似度。")]),s._v(" "),t("p",[s._v("python中的"),t("strong",[s._v("NLTK库")]),s._v("便源自于这个东西。")]),s._v(" "),t("blockquote",[t("p",[s._v("我们实际使用WordNet来计算单词的相似度， 具体来说，就是基于—个人工定义的单词网络，来计算单词之间的 相似度，如果能（正确计算单词之间的相似度，那么我们就踏出了理解单词含义的第一步。")])]),s._v(" "),t("p",[t("strong",[s._v("同义词词典的问题")])]),s._v(" "),t("ul",[t("li",[s._v("难以顺应时代变化")]),s._v(" "),t("li",[s._v("人力成本高")]),s._v(" "),t("li",[s._v("无法表示单词的微妙差异")])]),s._v(" "),t("p",[s._v("为了避免这些问题，介绍基于计数的方法和利用神经网络的基于推理的方法这两种方法可以从"),t("strong",[s._v("海量的文本数据中自动提取单词含义")]),s._v("，将我们从人工关联单词的辛苦劳动中解放出来。")]),s._v(" "),t("h3",{attrs:{id:"基于计数的方法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基于计数的方法"}},[s._v("#")]),s._v(" 基于计数的方法")]),s._v(" "),t("p",[s._v("从介绍基于计数的方法开始,我们将使用语料库（corpus）。简而言之，语料库就是大量的文本数据。不过,语料库并不是胡乱收集数据般收集 的都是用于自然语言处理研究和应用的文本数据。")]),s._v(" "),t("p",[s._v("语料库中包含了大量的关于自然语言的实践知识，"),t("strong",[s._v("文章的写作方法，单词的选择方法和单词含义等")]),s._v("。基于计数的方法的目标就是 从这些富有实践知识的语料库中, 自动且高效地提取本质")]),s._v(" "),t("blockquote",[t("p",[s._v("自然语言处理领域中使用的语料库有时会给文本数据添加额外的信息，比如,可以给文本数据的各个单词标记词性，在这种情况 下，为了方便计算机处理，语料库通常会被结构化（比如采用 树结构等数据形式）")])]),s._v(" "),t("h4",{attrs:{id:"基于python的语料库的预处理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基于python的语料库的预处理"}},[s._v("#")]),s._v(" 基于python的语料库的预处理")]),s._v(" "),t("p",[s._v("自然语言处理领域存在各种各样的语料库，有名的语料库有 Wjkipedia和GoogleNews等。")]),s._v(" "),t("p",[s._v("现在，我们对一个非常小的语料库（一个文本）进行**预处理。**这里的预处理指的是，"),t("strong",[s._v("将文本分割为单词（分词），并将分割后的单词列表转换为单词ID列表。")])]),s._v(" "),t("p",[s._v("如下：")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" text "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'you say goodbye and i say hello.'")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" text "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" text.replace"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.'")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("' .'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" text\n"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'you say goodbye and i say hello .'")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" text.split"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'you'")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'say'")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'goodbye'")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'and'")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'i'")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'say'")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'hello'")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("p",[s._v("将空格作为分隔符,通过split,切分句子。考虑到句子结尾处的句号''. ''   ,我们先在句号前插人一个空格（即 用' .'替换'.'）,再进行分词")]),s._v(" "),t("blockquote",[t("p",[s._v("通过导入正则表达式的re模块使用re.split('(\\W+)?',text)也可以进行分词")])]),s._v(" "),t("p",[s._v("现在，已经可以将原始文章当成单词列表使用了，但是直接以文本的形式操作单词,总感觉有些不方便。"),t("strong",[s._v("因 此我们进一步给单词标上ID以便使用单词ID列表")]),s._v("。为此,我们使用 Python的字典来创建单词ID和单词的对应表。把这个过程写成函数就是")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("preprocess")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    text "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("lower"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    text "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("replace"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("' .'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    words "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("split"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("' '")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    \n    word_to_id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    id_to_word"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" word "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" words"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" word "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            new_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" new_id\n            id_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("new_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" word\n    corpus "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("w"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" w "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" words"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("id_to_word\n\n\n\ntext "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'you say goodbye and i say hello.'")]),s._v("\nprocess"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("##")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'you'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'say'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'goodbye'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'and'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'i'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'hello'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'you'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'say'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'goodbye'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'and'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'i'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'hello'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br")])]),t("p",[s._v("这样，我们完成了单词列表转换成单词id列表，并且把其再转换为np数组。")]),s._v(" "),t("p",[t("strong",[s._v("注意，word_to_id是单词到id的字典，id_to_word是id到单词的字典，corpus是单词id的列表，会经常使用")])]),s._v(" "),t("h4",{attrs:{id:"分布式假设"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分布式假设"}},[s._v("#")]),s._v(" 分布式假设")]),s._v(" "),t("p",[t("strong",[s._v("单词的分布式表示")]),s._v("：")]),s._v(" "),t("p",[s._v("我们知道，使用RGB可以表示颜色，"),t("strong",[s._v("并且这种基于三原色的表示方式很紧凑")]),s._v("，也更容易让人联想他的颜色。比如即便不知道“深诽”是什么样的颜色,但如果知道它的（R，G，B）＝（201,23,30）,就至少可以知道它是红色系的颜色。此外，"),t("strong",[s._v("颜色之间的 关联性（是否是相似的颜色）也更容易通过向量表示来判断和量化")]),s._v("，单词可以这样干吗？")]),s._v(" "),t("p",[s._v("可否在单词领域构建紧凑合理的向量表示呢?我们关注能准确把握"),t("strong",[s._v("单词含义的向量表示")]),s._v("。在自然语言处理领域，"),t("strong",[s._v("这称为分布式表示")])]),s._v(" "),t("blockquote",[t("p",[s._v("单词的分布式表示将单词表示为固定长度的向量。这种向量 的特征在于它是用"),t("strong",[s._v("密集向量")]),s._v("表示的。"),t("strong",[s._v("密集向量的意思是，向量的 各个元素（大多数）是由非 0 实数表示的")]),s._v("。例如，三维分布式表 示是 [0.21,-0.45,0.83]。如何构建这样的单词的分布式表示是 我们接下来的一个重要课题")])]),s._v(" "),t("p",[t("strong",[s._v("分布式假设：")])]),s._v(" "),t("p",[s._v("在自然语言处理的历史中，用向量表示单词的研究有很多。如果仔细 看一下这些研究，"),t("strong",[s._v("就会发现几乎所有的重要方法都基于一个简单的想 法，这个想法就是“某个单词的含义由它周围的单词形成”，"),t("strong",[s._v("称为")]),s._v("分布式假设")]),s._v("（distributional hypothesis）。许多用向量表示单词的 近期研究也基于该假设")]),s._v(" "),t("p",[s._v("分布式假设所表达的理念非常简单。"),t("strong",[s._v("单词本身没有含义，单词含义由 它所在的上下文（语境）形成。")])]),s._v(" "),t("p",[s._v("比如“I drink beer.”“We drink wine.”，drink 的 附近常有饮料出现。")]),s._v(" "),t("p",[s._v("从现在开始，我们会经常使用“上下文”一词。"),t("strong",[s._v("本章说的上下文是指 某个单词（关注词）周围的单词")]),s._v("。在图 2-3 的例子中，左侧和右侧的 2 个单词就是上下文。")]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230404172307038.png"}}),s._v(" "),t("p",[s._v("这里，我们将上下文的大小（即周围的单词有多少个）称为"),t("strong",[s._v("窗口大小（windowsize）")])]),s._v(" "),t("blockquote",[t("p",[s._v("窗口大小为 1，上下文包含左右各 1 个单词；窗口大小为 2，上下文包含左右各 2 个单词，以此类推。")]),s._v(" "),t("p",[s._v("根据具体情况，也可以仅将左边的单词或者右边的单词作为 上下文。此外，也可以使用考虑了句子分隔符的上下文")])]),s._v(" "),t("h4",{attrs:{id:"共现矩阵"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#共现矩阵"}},[s._v("#")]),s._v(" 共现矩阵")]),s._v(" "),t("p",[t("strong",[s._v("如何根据分布式来假设来用向量来表示单词呢？")])]),s._v(" "),t("p",[s._v("最直截了当的实现方法是对周围单词的数量进行计数。具体来说，在关注某个单词的情况下，"),t("strong",[s._v("对它的周围出现了多少次什么单词进行计数，然后再 汇总。这里，我们将这种做法称为“基于计数的方法”")])]),s._v(" "),t("p",[s._v("这里我们仍然用之前的那个语料库并进行预处理")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("text "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'you say goodbye and i say hello.'")]),s._v("\nprocess"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("##")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#cropus")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'you'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'say'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'goodbye'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'and'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'i'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'hello'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#word_to_id")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'you'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'say'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'goodbye'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'and'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'i'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'hello'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#id_to_word")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("p",[s._v("显然词汇总数为 7 个（注意，"),t("strong",[s._v("这里指的是词汇的种类，")]),s._v("）。下面，我们计算每个单词 的上下文所包含的单词的频数。在这个例子中，我们将窗口大小设为 1，从单词 ID 为 0 的 you 开始。")]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230404174117130.png"}}),s._v(" "),t("p",[s._v("从上面我们可以看到，可以用向量 [0, 1, 0, 0, 0, 0, 0] 表示(基于上下文)单词 you。")]),s._v(" "),t("p",[s._v("对say也可以由同样处理")]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230404174433914.png"}}),s._v(" "),t("p",[s._v("单词 say 可以表示为向量 [1, 0, 1, 0, 1, 1, 0]。")]),s._v(" "),t("p",[s._v("对所有单词做同样处理，得到")]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230404174617109.png"}}),s._v(" "),t("p",[s._v("是汇总了所有单词的共现单词的表格。这个表格的各行对应相 应单词的向量。因为图 2-7 的表格呈矩阵状，"),t("strong",[s._v("所以称为共现矩阵")]),s._v(" （co-occurence matrix）。")]),s._v(" "),t("h5",{attrs:{id:"显然的性质"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#显然的性质"}},[s._v("#")]),s._v(" "),t("strong",[s._v("显然的性质")])]),s._v(" "),t("p",[s._v("首先这里我发现，这里的次数指的是在"),t("strong",[s._v("限定窗口下，滑完所有单词所得到的次数")]),s._v("（不是一个单词在整个文本中出现的次数），这一点很重要。")]),s._v(" "),t("p",[s._v("因为我们是通过统计上下的方式来统计计算向量的，进而由向量得到列表，那么肯定的，共现矩阵的一维，正好表现了在限定的窗口大小下，两个单词一起出现的次数。这样的话，")]),s._v(" "),t("ul",[t("li",[s._v("如果把横轴看成x轴，纵轴看成y轴，（x,y）就是两个单词一起出现的次数，")]),s._v(" "),t("li",[s._v("并且，每一行是一个单词的向量，每一列是在上面的计数方法下，该单词出现的次数")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#共现矩阵的一行显然就是一个向量")]),s._v("\nC "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("int32"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 单词ID为0的向量")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# [0 1 0 0 0 0 0]")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br")])]),t("p",[s._v("现在，我们使用函数实现这个过程（其中参数 corpus 是单词 ID 列表，参数 vocab_size 是词汇个数，window_size 是窗口大小）")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("create_co_matrix")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" vocab_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" window_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    corpus_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    co_matrix "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zeros"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("vocab_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" vocab_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("dtype"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("int32"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#思路就是把对应id的哪行，那个单词的左右窗口都加上1")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" idx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("enumerate")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#numerate返回下标和索引")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" window_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            left_idx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" idx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" i\n            right_idx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" idx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" i\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" left_idx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                left_word_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("left_idx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n                co_matrix"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("word_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" left_word_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" right_idx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" corpus_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                right_word_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("right_idx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n                co_matrix"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("word_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" right_word_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" co_matrix\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br")])]),t("h4",{attrs:{id:"向量相似度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#向量相似度"}},[s._v("#")]),s._v(" 向量相似度")]),s._v(" "),t("p",[s._v("测量向量间的相似度有很多方法，其中具有代表性的方法有向量内积 或欧式距离等。虽然除此之外还有很多方法，但是在测量单词的向量 表示的相似度方面，"),t("strong",[s._v("余弦相似度（cosine similarity）是很常用 的。")])]),s._v(" "),t("p",[s._v("设有"),t("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[t("mjx-math",{staticClass:"MJX-TEX"},[t("mjx-msub",[t("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"1"}})],1)],1)],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"["}})],1),t("mjx-msub",[t("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"1"}})],1)],1)],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-msub",{attrs:{space:"2"}},[t("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"2"}})],1)],1)],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-msub",{attrs:{space:"2"}},[t("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"3"}})],1)],1)],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"22EF"}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"."}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"]"}})],1)],1)],1),s._v(","),t("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[t("mjx-math",{staticClass:"MJX-TEX"},[t("mjx-msub",[t("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"1"}})],1)],1)],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"["}})],1),t("mjx-msub",[t("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"1"}})],1)],1)],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-msub",{attrs:{space:"2"}},[t("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"2"}})],1)],1)],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-msub",{attrs:{space:"2"}},[t("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"3"}})],1)],1)],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"]"}})],1)],1)],1),s._v("两个向量")],1),s._v(" "),t("p",[s._v("分子是向量内积，分母是各个向量的范数。"),t("strong",[s._v("范数表示 向量的大小，这里计算的是 L2 范数")]),s._v("（"),t("strong",[s._v("即向量各个元素的平方和的平 方根")]),s._v("）。式 (2.1) 的要点是先对向量进行正规化，再求它们的内积。")]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230404205058118.png"}}),s._v(" "),t("p",[s._v("余弦相似度直观地表示了“"),t("strong",[s._v("两个向量在多大程度上指向同一 方向")]),s._v("”。")]),s._v(" "),t("blockquote",[t("p",[s._v("两个向量完全指向相同的方向时，余弦相似度为 1；完 全指向相反的方向时，余弦相似度为 -1。")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("cos_similarity")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    nx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sqrt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# x的正规化")]),s._v("\n    ny "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" y "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sqrt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("y"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# y的正规化")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("nx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ny"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("注意这个代码有问题，那就是当零向量（元素全部为 0 的向量）被赋值给 参数时，"),t("strong",[s._v("会出现“除数为 0”（zero division）的错误")]),s._v("。")]),s._v(" "),t("blockquote",[t("p",[s._v("有除法的时候，一定要考虑除数有没有零的情况，通用办法是给除数加上一个微小值")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("cos_similarity")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("eps"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1e-8")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    nx "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sqrt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("eps"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# x的正规化")]),s._v("\n    ny "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" y "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sqrt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("y"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("eps"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# y的正规化")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("nx"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ny"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("这里我们用了 1e-8 作为微小值，在这么小的值的情况下， 根据浮点数的舍入误差，这个微小值会被其他值“吸收”掉。在 上面的实现中，因为这个微小值会被向量的范数“吸收”掉，所 以在绝大多数情况下，加上 eps 不会对最终的计算结果造成影 响。而当向量的范数为 0 时，这个微小值可以防止“除数为 0” 的错误")]),s._v(" "),t("p",[s._v("我们这里求一下，you和i的相似程度（单词ID列表，也叫单词向量的相似程度）")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("\ntext "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'You say goodbye and I say hello.'")]),s._v("\ncorpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id_to_word "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" preprocess"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nvocab_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nC "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" create_co_matrix"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" vocab_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nc0 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'you'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# you的单词向量")]),s._v("\nc1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'i'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# i的单词向量")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("cos_similarity"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c0"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" c1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#0.7071067758832467")]),s._v("\n\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br")])]),t("h4",{attrs:{id:"相似单词排序"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#相似单词排序"}},[s._v("#")]),s._v(" 相似单词排序")]),s._v(" "),t("p",[s._v("实现余弦函数可以，利用他实现排序函数,"),t("strong",[s._v("当某个单词被作为查询词时，将与这个查询词相似的单词按 降序显示出来")]),s._v("。这里将这个函数称为 "),t("strong",[s._v("most_similar")]),s._v("(query, word_to_id, id_to_word, word_matrix, top=5)")]),s._v(" "),t("img",{staticStyle:{zoom:"60%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230404210711661.png"}}),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("most_similar")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("query"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("id_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("word_matrix"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("top"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#取出查询")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" query "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'%s is not found'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" query"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v("\n    \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'\\n[query] '")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("query"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    query_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("query"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n    query_vec "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" word_matrix"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("query_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#计算余弦相似度")]),s._v("\n    vocab_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    similarity "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zeros"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("vocab_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("vocab_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        similarity"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cos_similarity"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("word_matrix"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("query_vec"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#基于余弦相似度，按降序输出")]),s._v("\n    count "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" similarity"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("argsort"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#argsort是numpy的一个排序函数，因为他按升序排列，要求降序，所以前面哪里乘以-1")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" id_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v("query"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("continue")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'%s: %s'")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("similarity"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        \n        count"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" count"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v("top"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br")])]),t("p",[s._v("这个 argsort() 方法可以"),t("strong",[s._v("按升序对 NumPy 数组的元素进行排")]),s._v("序（"),t("strong",[s._v("不过，返回值是数组的索引")]),s._v("）。下面是 一个例子。")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("argsort"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\narray"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("这里利用上面文本进行一个查询，you")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("text "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'You say goodbye and I say hello.'")]),s._v("\ncorpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id_to_word "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" preprocess"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nvocab_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nC "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" create_co_matrix"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" vocab_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nmost_similar"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'you'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" top"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("query"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" you\ngoodbye"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.7071067758832467")]),s._v("\ni"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.7071067758832467")]),s._v("\nhello"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.7071067758832467")]),s._v("\nsay"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("and")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br")])]),t("p",[s._v("这个结果只按降序显示了 you 这个查询词的前 5 个相似单词，各个 单词旁边的值是余弦相似度。观察上面的结果可知，和 you 最接近的 单词有 3 个，分别是 goodbye、i（= I）和 hello。因为 i 和 you 都是人称代词，所以二者相似可以理解。"),t("strong",[s._v("但是，goodbye 和 hello 的 余弦相似度也很高，这和我们的感觉存在很大的差异")]),s._v("。"),t("strong",[s._v("一个可能的原因是，这里的语料库太小了。后面我们会用更大的语料库进行相同的 实验。")])]),s._v(" "),t("h3",{attrs:{id:"基于计数的方法的改进"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基于计数的方法的改进"}},[s._v("#")]),s._v(" 基于计数的方法的改进")]),s._v(" "),t("h4",{attrs:{id:"点互信息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#点互信息"}},[s._v("#")]),s._v(" 点互信息")]),s._v(" "),t("p",[s._v("共现矩阵使用原始的出现次数来表示单词向量，"),t("strong",[s._v("他并没有很好的性质")]),s._v("。")]),s._v(" "),t("p",[s._v("举例：")]),s._v(" "),t("p",[s._v("我们来考虑某个语料库中 the 和 car 共现的情况。在这种情 况下，我们会看到很多“...the car...”这样的短语。因此，它们的 共现次数将会很大。另外，car 和 drive 也明显有很强的相关性。但 是，如果只看单词的出现次数，那么与 drive 相比，t"),t("strong",[s._v("he 和 car 的 相关性更强。这意味着，仅仅因为 the 是个常用词，它就被认为与 car 有很强的相关性。")])]),s._v(" "),t("p",[s._v("为了解决这一问题，可以使用"),t("strong",[s._v("点互信息")]),s._v("（Pointwise Mutual Information，PMI）这一指标")]),s._v(" "),t("p",[s._v("对于随机变量"),t("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[t("mjx-math",{staticClass:"MJX-TEX"},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"y"}})],1)],1)],1),s._v(",其定义如下：")],1),s._v(" "),t("p",[t("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[t("mjx-math",{staticClass:"MJX-TEX"},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"M"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"I"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"l"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"o"}})],1),t("mjx-msub",[t("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[t("mjx-c",{attrs:{c:"g"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"2"}})],1)],1)],1),t("mjx-mfrac",[t("mjx-frac",[t("mjx-num",[t("mjx-nstrut"),t("mjx-mrow",{attrs:{size:"s"}},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1)],1)],1),t("mjx-dbox",[t("mjx-dtable",[t("mjx-line"),t("mjx-row",[t("mjx-den",[t("mjx-dstrut"),t("mjx-mrow",{attrs:{size:"s"}},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1),s._v(" "),t("p",[s._v("注意，由于当单词（x,y）一起出现次数为0时，PMI（x,y）=log0=无穷，为了解决这个问题")]),s._v(" "),t("p",[s._v("，"),t("strong",[s._v("实践上我们会使用下述正的点互信息")]),s._v("（Positive PMI， PPMI）。")]),s._v(" "),t("p",[t("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[t("mjx-math",{staticClass:"MJX-TEX"},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"M"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"I"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"m"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"a"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mn",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"0"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"M"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"I"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),s._v(" "),t("p",[s._v("其中P(x)，P(y)表示他们各自发生的概率，P(x,y)表示他们一起发生的概率。"),t("strong",[s._v("PMI 的值越高，表明相关性越强")])]),s._v(" "),t("p",[s._v("使用共现矩阵（其元素表示单词共现的次数）来重写PMI")]),s._v(" "),t("p",[s._v("将共现矩阵表示为 C(x,y)，将单词 x和 y的共现次数表示为C(x,y) ，将单词x 和y 的出现次数分别表示为C(x),C(y) ， 将语料库的单词数量记为N ，则有：")]),s._v(" "),t("p",[t("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[t("mjx-math",{staticClass:"MJX-TEX"},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"M"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"I"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"l"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"o"}})],1),t("mjx-msub",[t("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[t("mjx-c",{attrs:{c:"g"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"2"}})],1)],1)],1),t("mjx-mfrac",[t("mjx-frac",[t("mjx-num",[t("mjx-nstrut"),t("mjx-mrow",{attrs:{size:"s"}},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1)],1)],1),t("mjx-dbox",[t("mjx-dtable",[t("mjx-line"),t("mjx-row",[t("mjx-den",[t("mjx-dstrut"),t("mjx-mrow",{attrs:{size:"s"}},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1)],1)],1)],1)],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"l"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"o"}})],1),t("mjx-msub",[t("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[t("mjx-c",{attrs:{c:"g"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"2"}})],1)],1)],1),t("mjx-mfrac",[t("mjx-frac",[t("mjx-num",[t("mjx-nstrut"),t("mjx-mfrac",{attrs:{size:"s"}},[t("mjx-frac",[t("mjx-num",[t("mjx-nstrut"),t("mjx-mrow",{attrs:{size:"s"}},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1)],1)],1),t("mjx-dbox",[t("mjx-dtable",[t("mjx-line"),t("mjx-row",[t("mjx-den",[t("mjx-dstrut"),t("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"N"}})],1)],1)],1)],1)],1)],1)],1)],1),t("mjx-dbox",[t("mjx-dtable",[t("mjx-line"),t("mjx-row",[t("mjx-den",[t("mjx-dstrut"),t("mjx-mfrac",{attrs:{size:"s"}},[t("mjx-frac",[t("mjx-num",[t("mjx-nstrut"),t("mjx-mrow",{attrs:{size:"s"}},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1)],1)],1),t("mjx-dbox",[t("mjx-dtable",[t("mjx-line"),t("mjx-row",[t("mjx-den",[t("mjx-dstrut"),t("mjx-mrow",{attrs:{size:"s"}},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"N"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"2217"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"N"}})],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"l"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"o"}})],1),t("mjx-msub",[t("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[t("mjx-c",{attrs:{c:"g"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"2"}})],1)],1)],1),t("mjx-mfrac",[t("mjx-frac",[t("mjx-num",[t("mjx-nstrut"),t("mjx-mrow",{attrs:{size:"s"}},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"N"}})],1)],1)],1),t("mjx-dbox",[t("mjx-dtable",[t("mjx-line"),t("mjx-row",[t("mjx-den",[t("mjx-dstrut"),t("mjx-mrow",{attrs:{size:"s"}},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1),s._v(" "),t("blockquote",[t("p",[s._v("注意这里的次数，是在上面那种分布式表现下的次数，不是比如一句话里这个单词出现了几次这种")])]),s._v(" "),t("p",[s._v("下面我们来具体地算一下。 这里假设语料库的单词数量（N ）为 10 000，the 出现 100 次，car 出现 20 次，drive 出现 10 次，the 和 car 共现 10 次，car 和 drive 共现 5 次。这时，如果从共现次数的角度来看，则与 drive 相比，the 和 car 的相关性更强。而如果从 PMI 的角度来看，结果 是怎样的呢？我们来计算一下。")]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230404224200831.png"}}),s._v(" "),t("p",[s._v("在使用 PMI 的情况下，与 the 相比，drive 和 car 具有 更强的相关性。")]),s._v(" "),t("p",[s._v("实现代码")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#PPMI")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("ppmi")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" verbose"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" eps"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1e-8")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    M "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zeros_like"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dtype"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("float32"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    N "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    S "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" axis"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    total "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n    cnt "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" j "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            pmi "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("log2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" j"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" N "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("S"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("j"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("S"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" eps"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            M"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" j"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("max")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" pmi"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" verbose"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                cnt "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" cnt "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("total"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'%.1f%% done'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("cnt"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("total"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" M\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br")])]),t("blockquote",[t("p",[s._v("这里我不理解，语料库词汇量为什么是np.sum(N),比如一开始使用的那个例子，显然词汇量应该是7，但是这样算，肯定不是7,实际上是14")]),s._v(" "),t("p",[s._v("大概是词汇量非彼词汇量？")])]),s._v(" "),t("p",[s._v("参数 C 表示共现矩阵，verbose 是决定是否输出运行情况的标 志。当处理大语料库时，设置 verbose=True，可以用于确认运行情 况。")]),s._v(" "),t("p",[s._v("这段代码实现了")]),s._v(" "),t("p",[t("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[t("mjx-math",{staticClass:"MJX-TEX"},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-munder",{attrs:{space:"4",limits:"false"}},[t("mjx-mo",{staticClass:"mjx-sop"},[t("mjx-c",{attrs:{c:"2211"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.285em"}},[t("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"i"}})],1)],1)],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"i"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"x"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-munder",{attrs:{space:"4",limits:"false"}},[t("mjx-mo",{staticClass:"mjx-sop"},[t("mjx-c",{attrs:{c:"2211"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.285em"}},[t("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"i"}})],1)],1)],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"i"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"y"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"N"}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-munder",{attrs:{space:"4",limits:"false"}},[t("mjx-mo",{staticClass:"mjx-sop"},[t("mjx-c",{attrs:{c:"2211"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.285em"}},[t("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"i"}})],1)],1)],1),t("mjx-munder",{attrs:{space:"2",limits:"false"}},[t("mjx-mo",{staticClass:"mjx-sop"},[t("mjx-c",{attrs:{c:"2211"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"-0.285em"}},[t("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"j"}})],1)],1)],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"i"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:","}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"j"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),s._v(" "),t("p",[t("strong",[s._v("还是用之前的文本来查看效果")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("text "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'You say goodbye and I say hello.'")]),s._v("\ncorpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id_to_word "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" preprocess"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nvocab_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nC "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" create_co_matrix"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" vocab_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nW "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ppmi"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nnp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("set_printoptions"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("precision"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 有效位数为3位")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'covariance matrix'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'-'")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'PPMI'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("W"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n\ncovariance matrix\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("\nPPMI\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.807")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.807")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br")])]),t("p",[s._v("我们将共现矩阵转化为了 PPMI 矩阵。此时，PPMI 矩阵 的各个元素均为大于等于 0 的实数。我们得到了一个由更好的指标形 成的矩阵，这相当于获取了一个更好的单词向量。")]),s._v(" "),t("p",[t("strong",[s._v("存在问题")])]),s._v(" "),t("p",[s._v("那就是随着语料库 的词汇量增加，各个单词向量的维数也会增加。如果语料库的词汇量 达到 10 万，则单词向量的维数也同样会达到 10 万。实际上，处理 10 万维向量是不现实的。")]),s._v(" "),t("p",[s._v("如果我们看一下这个矩阵，就会发现其中很多元素都是 0。这 表明向量中的绝大多数元素并不重要，也就是说，每个元素拥有的 “重要性”很低。另外，这样的向量也容易受到噪声影响，稳健性 差。对于这些问题，一个常见的方法是向量降维。")]),s._v(" "),t("h4",{attrs:{id:"降维-svd"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#降维-svd"}},[s._v("#")]),s._v(" 降维(SVD)")]),s._v(" "),t("p",[s._v("降维（dimensionality reduction），顾名思义，就是减少向量维度。但是，并不是简单地减少，而是在尽量保留“重要信息”的基础上减少。如图 2-8 所示，我们要观察数据的分布，并发现重要的“轴”。")]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230408205438365.png"}}),s._v(" "),t("p",[s._v("在图 2-8 中，考虑到数据的广度，导入了一根新轴，以将原来用二维坐标表示的点表示在一个坐标轴上。此时，用新轴上的投影值来表示各个数据点的值。这里非常重要的一点是，选择新轴时要考虑数据的广度。如此，仅使用一维的值也能捕获数据的本质差异。在多维数据")]),s._v(" "),t("p",[s._v("中，也可以进行同样的处理。")]),s._v(" "),t("blockquote",[t("p",[s._v("向量中的大多数元素为 0 的矩阵（或向量）称为"),t("strong",[s._v("稀疏矩阵")]),s._v("（或稀疏向量）。这里的重点是，从稀疏向量中找出重要的轴，用更少的维度对其进行重新表示。结果，稀疏矩阵就会被转化为大多数元素均不为 0 的"),t("strong",[s._v("密集矩阵")]),s._v("。这个密集矩阵就是我们想要的单词的分布式表示。")])]),s._v(" "),t("p",[s._v("奇异值分解（Singular ValueDecomposition)所以简称SVD。SVD 将任意矩阵分解为 3 个矩阵的乘积，如下式所示：")]),s._v(" "),t("p",[t("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[t("mjx-math",{staticClass:"MJX-TEX"},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"X"}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"U"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"S"}})],1),t("mjx-msup",[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"V"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"0.363em","margin-left":"0.087em"}},[t("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"T"}})],1)],1)],1)],1)],1)],1),s._v(" "),t("p",[s._v("其中 U,V是列向量彼此相交的正交矩阵（也就是说，中间没有S，UV^T=单位矩阵），S是"),t("strong",[s._v("除了对角线元素以外其余元素均为 0 的对角矩")]),s._v("阵。图 2-9 中直观地表示出了这些矩阵。")]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230408205745592.png"}}),s._v(" "),t("p",[s._v("U是正交矩阵，这个正交矩阵构成了一些空间中的基轴（基向量），我们可以将矩阵 U作为“单词空间”。S是对角")]),s._v(" "),t("p",[s._v("矩阵，奇异值在对角线上降序排列。简单来说，"),t("strong",[s._v("可以把奇异值视为为“对应的基轴”的重要性")]),s._v("。")]),s._v(" "),t("blockquote",[t("p",[s._v("在线性代数中，基(basis)（也称为基底）是描述、刻画向量空间的基本工具。向量空间的基是它的一个特殊的子集，基的元素称为基向量.好了，还是很复杂，这样说，一般基向量选择单位向量作为基向量")])]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230408212647677.png"}}),s._v(" "),t("p",[s._v("矩阵S的奇异值小，对应的基轴的重要性低，因此，可以通过去除矩阵U中的多余的列向量来近似原始矩阵。用我们正在处理的“单词的 PPMI 矩阵”来说明的话，矩阵 的各行包含对应的单词 ID 的单词向量，"),t("strong",[s._v("这些单词向量使用降维后的矩阵 表示")]),s._v("。")]),s._v(" "),t("blockquote",[t("p",[s._v("看待一个矩阵，可以从多方面看。SVD则是从"),t("a",{attrs:{href:"https://www.zhihu.com/search?q=%E5%88%97%E5%90%91%E9%87%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A196294308%7D",target:"_blank",rel:"noopener noreferrer"}},[s._v("列向量"),t("OutboundLink")],1),s._v("如何生成的角度来看。假设一个矩阵的列向量有100列，但只由"),t("strong",[s._v("少数")]),s._v("几个‘"),t("strong",[s._v("基")]),s._v("’（比如10个吧）"),t("strong",[s._v("组合")]),s._v("而成的，那么如何求出这10个基？如果有了这些‘基’，如何把这些基再组合起来生成这个矩阵？也就是说，找出这些基，就可以实现减少列的目的了**")]),s._v(" "),t("p",[s._v("SVD可以找到这些基，因为肉眼很难找出来，")]),s._v(" "),t("p",[s._v("SVD认为，一组良好的基应该是归一化"),t("strong",[s._v("正交的，"),t("strong",[s._v("因为正交之后")]),s._v("不会出现冗余")]),s._v("的信息。因此就分解出了上面的公式")]),s._v(" "),t("p",[s._v("https://www.zhihu.com/question/34143886/answer/196294308")])]),s._v(" "),t("h5",{attrs:{id:"正交矩阵"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#正交矩阵"}},[s._v("#")]),s._v(" 正交矩阵")]),s._v(" "),t("p",[s._v("看这名字就很抽象，先给出他是啥")]),s._v(" "),t("ul",[t("li",[s._v("正交：可以简单理解成就是垂直.")]),s._v(" "),t("li",[s._v("正交矩阵の定义：满足 "),t("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[t("mjx-math",{staticClass:"MJX-TEX"},[t("mjx-msup",[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"A"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[t("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"T"}})],1)],1)],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"A"}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"E"}})],1)],1)],1),s._v("的矩阵.")],1)]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230408210556875.png"}}),s._v(" "),t("p",[s._v("只需要知道他的性质")]),s._v(" "),t("p",[t("strong",[s._v("凡是正交矩阵，一定可以对角化")]),s._v("。")]),s._v(" "),t("ul",[t("li",[s._v("对角化： 参考相似矩阵，本质就是"),t("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[t("mjx-math",{staticClass:"MJX-TEX"},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"A"}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-msup",{attrs:{space:"4"}},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"0.363em","margin-left":"0.072em"}},[t("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"2212"}})],1)],1)],1),t("mjx-mn",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"1"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"B"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1)],1)],1),s._v(", 也就是说一个矩阵A可以转为一个对角阵B.")],1),s._v(" "),t("li",[s._v("正交矩阵：本身就是相互垂直，只是说它不见得是各个标准轴。以三维空间为例，我们希望正交矩阵是")])]),s._v(" "),t("h4",{attrs:{id:"svd降维实现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#svd降维实现"}},[s._v("#")]),s._v(" SVD降维实现")]),s._v(" "),t("p",[s._v("这里可以使用 NumPy 的linalg 模块中的 svd 方法。linalg 是 linear algebra（线性代")]),s._v(" "),t("p",[s._v("数）的简称。下面，我们创建一个共现矩阵，将其转化为 PPMI 矩阵，然后对其进行 SVD")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" sys\nsys"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("path"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'..'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pyplot "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" common"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("util "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" preprocess"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" create_co_matrix"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ppmi\ntext "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'You say goodbye and I say hello.'")]),s._v("\ncorpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id_to_word "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" preprocess"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("text"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nvocab_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nC "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" create_co_matrix"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" vocab_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" window_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nW "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ppmi"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# SVD")]),s._v("\nU"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" S"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" V "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("linalg"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("svd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("W"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br")])]),t("p",[s._v("我们查看单词ID为0的单词")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 共现矩阵")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# [0 1 0 0 0 0 0]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("W"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# PPMI矩阵")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# [ 0. 1.807 0. 0. 0. 0. 0. ]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("U"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# SVD")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# [ 3.409e-01 -1.110e-16 -1.205e-01 -4.441e-16 0.000e+00")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9.323e-01")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 2.226e-16]")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br")])]),t("p",[s._v("如上所示，原先的稀疏向量 W[0] 经过 SVD 被转化成了密集向量U[0]。如果要对这个密集向量降维，比如把它降维到二维向量，取出")]),s._v(" "),t("p",[s._v("前两个元素即可。")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("U"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# [ 3.409e-01 -1.110e-16]")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("blockquote",[t("p",[s._v("也就是说，第一个单词本来用[ 0. 1.807 0. 0. 0. 0. 0. ]（PPMI表示），现在可以用二维的[ 3.409e-01 -1.110e-16]来表示了")])]),s._v(" "),t("p",[s._v("用二维向量表示单词，并绘图")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    plt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("annotate"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("U"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("word_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" U"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("word_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    plt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("scatter"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("U"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" U"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" alpha"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("blockquote",[t("p",[s._v("plt.annotate(word, x, y) 函数在 2D 图形中坐标为 (x, y) 的地方绘制单词的文本")])]),s._v(" "),t("p",[s._v("对共现矩阵执行 SVD，并在图上绘制各个单词的二维向量（i 和 goodbye 重叠）")]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230408220927283.png"}}),s._v(" "),t("p",[s._v("因为语料库只有一句话，所以感觉结果不太对，下面使用PTB数据集进行实验。")]),s._v(" "),t("blockquote",[t("p",[s._v("如果矩阵大小是 ，SVD 的计算的复杂度将达到 "),t("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[t("mjx-math",{staticClass:"MJX-TEX"},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"O"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-msup",[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"n"}})],1),t("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[t("mjx-mn",{staticClass:"mjx-n",attrs:{size:"s"}},[t("mjx-c",{attrs:{c:"3"}})],1)],1)],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1)],1)],1),s._v("。 这意味着 SVD 需要与 的立方成比例的计算量。因为现实中这 样的计算量是做不到的，所以往往会使用 Truncated SVD等 更快的方法。Truncated SVD 通过截去（truncated）奇异值较小 的部分，从而实现高速化。")],1)]),s._v(" "),t("h4",{attrs:{id:"ptb数据集"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ptb数据集"}},[s._v("#")]),s._v(" PTB数据集")]),s._v(" "),t("p",[s._v("这个 PTB 语料库是以文本文件 的形式提供的，与原始的 PTB 的文章相比，多了若干预处理，包括将 稀有单词替换成特殊字符 "),t("unk",[s._v("（unk 是 unknown 的简称），将具体 的数字替换成“N”等。下面，我们将经过这些预处理之后的文本数据 作为 PTB 语料库使用。")])],1),s._v(" "),t("p",[s._v("如图 2，在 PTB 语料库中，一行保存一个句子。在本书中， 我们将所有句子连接起来，并将其视为一个大的时序数据。此时，在 每个句子的结尾处插入一个特殊字符 "),t("code",[s._v("<eos>")]),s._v("（eos 是 end of sentence 的简称）。")]),s._v(" "),t("img",{staticStyle:{zoom:"70%"},attrs:{src:"https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230408221358187.png"}}),s._v(" "),t("blockquote",[t("p",[s._v("不考虑句子的分割，将多个句子连接起来得到的内容视为一个大的时序数据。")])]),s._v(" "),t("p",[s._v("稍微用一下这个数据集")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" sys\nsys"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("path"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'..'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" dataset "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" ptb\ncorpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id_to_word "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ptb"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("load_data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'train'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'corpus size:'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'corpus[:30]:'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'id_to_word[0]:'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'id_to_word[1]:'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'id_to_word[2]:'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("\"word_to_id['car']:\"")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'car'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("\"word_to_id['happy']:\"")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'happy'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("\"word_to_id['lexus']:\"")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'lexus'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br")])]),t("p",[s._v("结果如下")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("corpus size: "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("929589")]),s._v("\ncorpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(":30"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(": "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("15")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("17")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("19")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("21")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("24")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("25")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("26")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("27")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("28")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("29")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nid_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(": aer\nid_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(": banknote\nid_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(": berlitz\nword_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'car'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3856")]),s._v("\nword_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'happy'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4428")]),s._v("\nword_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'lexus'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(": "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7426")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br")])]),t("p",[s._v("**使用 ptb.load_data() 加载数据。**此时，指定参数 'train'、'test' 和 'valid' 中的一个，它们分别对应训练用数")]),s._v(" "),t("p",[s._v("据、测试用数据和验证用数据中的一个。")]),s._v(" "),t("h4",{attrs:{id:"基于-ptb-数据集的评价"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基于-ptb-数据集的评价"}},[s._v("#")]),s._v(" 基于 PTB 数据集的评价")]),s._v(" "),t("p",[s._v("我们将基于计数的方法应用于 PTB 数据集。这里建议使用更快 速的 SVD 对大矩阵执行 SVD，为此我们需要安装 sklearn 模块。当 然，虽然仍可以使用基本版的 SVD（np.linalg.svd()），但是这需要 更多的时间和内存。我们把源代码一并给出，如下所示")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# coding: utf-8")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" common"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("util "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" most_similar"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" create_co_matrix"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ppmi\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" dataset "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" ptb\n\n\nwindow_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\nwordvec_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v("\n\ncorpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id_to_word "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ptb"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("load_data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'train'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nvocab_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'counting  co-occurrence ...'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nC "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" create_co_matrix"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("corpus"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" vocab_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" window_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'calculating PPMI ...'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nW "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ppmi"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("C"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" verbose"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'calculating SVD ...'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# truncated SVD (fast!)")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("utils"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extmath "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" randomized_svd\n    U"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" S"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" V "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" randomized_svd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("W"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" n_components"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("wordvec_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" n_iter"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                             random_state"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("except")]),s._v(" ImportError"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# SVD (slow)")]),s._v("\n    U"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" S"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" V "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("linalg"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("svd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("W"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nword_vecs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" U"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("wordvec_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\nquerys "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'you'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'year'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" query "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" querys"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    most_similar"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("query"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_to_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" id_to_word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" word_vecs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" top"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    \n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("query"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" you\n i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.702039909619")]),s._v("\n we"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.699448543998")]),s._v("\n 've"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.554828709147")]),s._v("\n do"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.534370693098")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.512044146526")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("query"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" year\n month"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.731561990308")]),s._v("\n quarter"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.658233992457")]),s._v("\n last"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.622425716735")]),s._v("\n earlier"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.607752074689")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("next")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.601592506413")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br")])]),t("p",[s._v("观察结果可知，首先，对于查询词 you，可以看到 i、we 等人称代词，排在前面，这些都是在语法上具有相同用法的词。再者，查询词 year有 month、quarter 等近义词，符合直觉。也就是说，再大一点的数据集上，单词的分布式表示有较好的表现")])])}),[],!1,null,null,null);t.default=r.exports}}]);