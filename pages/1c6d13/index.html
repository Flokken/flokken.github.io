<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>数值微分与梯度 | flokken&#39;s blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="记录学过的东西">
    <meta name="keywords" content="JavaScript,js,ES6,TypeScript,vue,python,css3,html5,Node,git,github,markdown">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.bc84ce4b.css" as="style"><link rel="preload" href="/assets/js/app.6c1ebbcf.js" as="script"><link rel="preload" href="/assets/js/2.28dcc766.js" as="script"><link rel="preload" href="/assets/js/44.4291d737.js" as="script"><link rel="prefetch" href="/assets/js/10.dadef33a.js"><link rel="prefetch" href="/assets/js/100.c21337b1.js"><link rel="prefetch" href="/assets/js/101.eeb225e5.js"><link rel="prefetch" href="/assets/js/102.442361dc.js"><link rel="prefetch" href="/assets/js/103.8495a4a1.js"><link rel="prefetch" href="/assets/js/104.be5e7531.js"><link rel="prefetch" href="/assets/js/105.f968e108.js"><link rel="prefetch" href="/assets/js/106.9c7bcb9d.js"><link rel="prefetch" href="/assets/js/107.5418bfc1.js"><link rel="prefetch" href="/assets/js/108.21c8e4b5.js"><link rel="prefetch" href="/assets/js/109.443388e7.js"><link rel="prefetch" href="/assets/js/11.cb3946f4.js"><link rel="prefetch" href="/assets/js/110.aee2ce54.js"><link rel="prefetch" href="/assets/js/111.c1c4c853.js"><link rel="prefetch" href="/assets/js/112.a77d44c2.js"><link rel="prefetch" href="/assets/js/113.3e1c1563.js"><link rel="prefetch" href="/assets/js/114.b73e18ed.js"><link rel="prefetch" href="/assets/js/115.464712f7.js"><link rel="prefetch" href="/assets/js/116.515a3426.js"><link rel="prefetch" href="/assets/js/117.1de6d86e.js"><link rel="prefetch" href="/assets/js/118.c87898a4.js"><link rel="prefetch" href="/assets/js/119.4d47ac77.js"><link rel="prefetch" href="/assets/js/12.3d11ba1b.js"><link rel="prefetch" href="/assets/js/120.adc822aa.js"><link rel="prefetch" href="/assets/js/121.dea1a90f.js"><link rel="prefetch" href="/assets/js/122.1490ee10.js"><link rel="prefetch" href="/assets/js/123.08cfb23f.js"><link rel="prefetch" href="/assets/js/124.28d0e817.js"><link rel="prefetch" href="/assets/js/125.a7630423.js"><link rel="prefetch" href="/assets/js/126.0d5b60c3.js"><link rel="prefetch" href="/assets/js/127.250521db.js"><link rel="prefetch" href="/assets/js/128.508639a2.js"><link rel="prefetch" href="/assets/js/129.5e6579a1.js"><link rel="prefetch" href="/assets/js/13.74ebc418.js"><link rel="prefetch" href="/assets/js/130.1c66619f.js"><link rel="prefetch" href="/assets/js/131.e83e8060.js"><link rel="prefetch" href="/assets/js/132.7ff3654e.js"><link rel="prefetch" href="/assets/js/133.4125eaa7.js"><link rel="prefetch" href="/assets/js/134.4a100ce2.js"><link rel="prefetch" href="/assets/js/135.789a6a26.js"><link rel="prefetch" href="/assets/js/136.9cc03ec3.js"><link rel="prefetch" href="/assets/js/137.8bd376fe.js"><link rel="prefetch" href="/assets/js/138.532d50a9.js"><link rel="prefetch" href="/assets/js/139.53372ba6.js"><link rel="prefetch" href="/assets/js/14.eaf82e4f.js"><link rel="prefetch" href="/assets/js/140.88405785.js"><link rel="prefetch" href="/assets/js/141.38d215a9.js"><link rel="prefetch" href="/assets/js/142.e0163f88.js"><link rel="prefetch" href="/assets/js/143.b523e1ce.js"><link rel="prefetch" href="/assets/js/144.10873c46.js"><link rel="prefetch" href="/assets/js/145.dfe09936.js"><link rel="prefetch" href="/assets/js/146.b05dc164.js"><link rel="prefetch" href="/assets/js/147.c5b7f960.js"><link rel="prefetch" href="/assets/js/148.80f47df1.js"><link rel="prefetch" href="/assets/js/149.b8d840e3.js"><link rel="prefetch" href="/assets/js/15.e64aec1b.js"><link rel="prefetch" href="/assets/js/150.d4361634.js"><link rel="prefetch" href="/assets/js/151.d8431db2.js"><link rel="prefetch" href="/assets/js/152.47852d30.js"><link rel="prefetch" href="/assets/js/153.47ea2a94.js"><link rel="prefetch" href="/assets/js/154.97384b42.js"><link rel="prefetch" href="/assets/js/155.3026447d.js"><link rel="prefetch" href="/assets/js/156.68e37577.js"><link rel="prefetch" href="/assets/js/157.086f0b3f.js"><link rel="prefetch" href="/assets/js/158.bdcb5b98.js"><link rel="prefetch" href="/assets/js/159.f52cb015.js"><link rel="prefetch" href="/assets/js/16.e312a677.js"><link rel="prefetch" href="/assets/js/160.a2739d99.js"><link rel="prefetch" href="/assets/js/161.7212e5c4.js"><link rel="prefetch" href="/assets/js/162.8006dc05.js"><link rel="prefetch" href="/assets/js/163.bf42549e.js"><link rel="prefetch" href="/assets/js/164.5b2eea28.js"><link rel="prefetch" href="/assets/js/165.d531f59f.js"><link rel="prefetch" href="/assets/js/166.86bf0046.js"><link rel="prefetch" href="/assets/js/167.af7a49eb.js"><link rel="prefetch" href="/assets/js/168.362435ae.js"><link rel="prefetch" href="/assets/js/169.b71a8d5d.js"><link rel="prefetch" href="/assets/js/17.e9813cce.js"><link rel="prefetch" href="/assets/js/170.975564fa.js"><link rel="prefetch" href="/assets/js/171.4949b39a.js"><link rel="prefetch" href="/assets/js/172.8d7529ad.js"><link rel="prefetch" href="/assets/js/173.404d8588.js"><link rel="prefetch" href="/assets/js/174.6641d1c4.js"><link rel="prefetch" href="/assets/js/175.0f46859d.js"><link rel="prefetch" href="/assets/js/176.2fd697ec.js"><link rel="prefetch" href="/assets/js/177.0f744d20.js"><link rel="prefetch" href="/assets/js/178.021de7d2.js"><link rel="prefetch" href="/assets/js/179.593f9493.js"><link rel="prefetch" href="/assets/js/18.0bfadb6c.js"><link rel="prefetch" href="/assets/js/180.8305cce0.js"><link rel="prefetch" href="/assets/js/181.5e83f1b6.js"><link rel="prefetch" href="/assets/js/182.87985f96.js"><link rel="prefetch" href="/assets/js/183.80ba1b3c.js"><link rel="prefetch" href="/assets/js/184.f11d0532.js"><link rel="prefetch" href="/assets/js/185.c859c104.js"><link rel="prefetch" href="/assets/js/186.dc782260.js"><link rel="prefetch" href="/assets/js/187.bc43a42b.js"><link rel="prefetch" href="/assets/js/188.abf4a947.js"><link rel="prefetch" href="/assets/js/189.3911f624.js"><link rel="prefetch" href="/assets/js/19.ebbfaca6.js"><link rel="prefetch" href="/assets/js/190.6ba0f02e.js"><link rel="prefetch" href="/assets/js/191.612eaebf.js"><link rel="prefetch" href="/assets/js/192.7545f46e.js"><link rel="prefetch" href="/assets/js/193.8c879c3b.js"><link rel="prefetch" href="/assets/js/194.2ac85355.js"><link rel="prefetch" href="/assets/js/195.887d8d44.js"><link rel="prefetch" href="/assets/js/196.82fc2486.js"><link rel="prefetch" href="/assets/js/197.f3d5a63f.js"><link rel="prefetch" href="/assets/js/198.acb21d94.js"><link rel="prefetch" href="/assets/js/199.72a831c8.js"><link rel="prefetch" href="/assets/js/20.7946efec.js"><link rel="prefetch" href="/assets/js/200.d22fdf55.js"><link rel="prefetch" href="/assets/js/201.d9df6873.js"><link rel="prefetch" href="/assets/js/202.001109bc.js"><link rel="prefetch" href="/assets/js/203.ba860144.js"><link rel="prefetch" href="/assets/js/204.0bb6f98e.js"><link rel="prefetch" href="/assets/js/205.d9c979cd.js"><link rel="prefetch" href="/assets/js/206.1d24147d.js"><link rel="prefetch" href="/assets/js/207.f3d10dab.js"><link rel="prefetch" href="/assets/js/208.c3ba92f2.js"><link rel="prefetch" href="/assets/js/209.fe7a19e2.js"><link rel="prefetch" href="/assets/js/21.0b137891.js"><link rel="prefetch" href="/assets/js/210.5d424205.js"><link rel="prefetch" href="/assets/js/211.d84d326b.js"><link rel="prefetch" href="/assets/js/212.1d38af17.js"><link rel="prefetch" href="/assets/js/213.061f3dbf.js"><link rel="prefetch" href="/assets/js/214.ecb8325b.js"><link rel="prefetch" href="/assets/js/215.615caf62.js"><link rel="prefetch" href="/assets/js/216.e23dc266.js"><link rel="prefetch" href="/assets/js/217.9933d9c4.js"><link rel="prefetch" href="/assets/js/218.5cdf2ac4.js"><link rel="prefetch" href="/assets/js/219.72e58688.js"><link rel="prefetch" href="/assets/js/22.3762b636.js"><link rel="prefetch" href="/assets/js/220.fbc6f972.js"><link rel="prefetch" href="/assets/js/221.1c8eeced.js"><link rel="prefetch" href="/assets/js/222.163dee0a.js"><link rel="prefetch" href="/assets/js/223.72e37b20.js"><link rel="prefetch" href="/assets/js/224.e09609e5.js"><link rel="prefetch" href="/assets/js/225.34fd5c90.js"><link rel="prefetch" href="/assets/js/226.9991814a.js"><link rel="prefetch" href="/assets/js/227.1e2b8a98.js"><link rel="prefetch" href="/assets/js/228.1d4d1fcf.js"><link rel="prefetch" href="/assets/js/229.cc91769e.js"><link rel="prefetch" href="/assets/js/23.f7ebea5b.js"><link rel="prefetch" href="/assets/js/230.3d3edd0f.js"><link rel="prefetch" href="/assets/js/231.0475038b.js"><link rel="prefetch" href="/assets/js/232.a9e3d0d3.js"><link rel="prefetch" href="/assets/js/233.2ca519d3.js"><link rel="prefetch" href="/assets/js/234.c51411ea.js"><link rel="prefetch" href="/assets/js/235.35616a91.js"><link rel="prefetch" href="/assets/js/236.db361c9c.js"><link rel="prefetch" href="/assets/js/237.c8e14a33.js"><link rel="prefetch" href="/assets/js/238.0f2fcf3a.js"><link rel="prefetch" href="/assets/js/239.a33a3324.js"><link rel="prefetch" href="/assets/js/24.42946d79.js"><link rel="prefetch" href="/assets/js/240.7bf17817.js"><link rel="prefetch" href="/assets/js/241.613e82c4.js"><link rel="prefetch" href="/assets/js/242.5709b7c9.js"><link rel="prefetch" href="/assets/js/243.4f2501de.js"><link rel="prefetch" href="/assets/js/244.63720e3b.js"><link rel="prefetch" href="/assets/js/245.e756153f.js"><link rel="prefetch" href="/assets/js/246.b709da2f.js"><link rel="prefetch" href="/assets/js/247.e6f5dc6f.js"><link rel="prefetch" href="/assets/js/248.79fff09e.js"><link rel="prefetch" href="/assets/js/249.2c7ad7a2.js"><link rel="prefetch" href="/assets/js/25.a86a3678.js"><link rel="prefetch" href="/assets/js/250.29112339.js"><link rel="prefetch" href="/assets/js/251.634c259b.js"><link rel="prefetch" href="/assets/js/252.f020ace1.js"><link rel="prefetch" href="/assets/js/253.21843ce0.js"><link rel="prefetch" href="/assets/js/254.819b0d0b.js"><link rel="prefetch" href="/assets/js/255.a1a36af5.js"><link rel="prefetch" href="/assets/js/256.b331fde3.js"><link rel="prefetch" href="/assets/js/257.d496873b.js"><link rel="prefetch" href="/assets/js/258.d25fd3f2.js"><link rel="prefetch" href="/assets/js/259.e26ffb21.js"><link rel="prefetch" href="/assets/js/26.5fe90cb9.js"><link rel="prefetch" href="/assets/js/260.173d7a1c.js"><link rel="prefetch" href="/assets/js/261.fd2846ac.js"><link rel="prefetch" href="/assets/js/262.110b431f.js"><link rel="prefetch" href="/assets/js/263.deab1489.js"><link rel="prefetch" href="/assets/js/264.b38ed189.js"><link rel="prefetch" href="/assets/js/265.e50c8ee7.js"><link rel="prefetch" href="/assets/js/266.132d2f80.js"><link rel="prefetch" href="/assets/js/267.df5c367d.js"><link rel="prefetch" href="/assets/js/268.94eee0dd.js"><link rel="prefetch" href="/assets/js/269.27287f29.js"><link rel="prefetch" href="/assets/js/27.0ac244ef.js"><link rel="prefetch" href="/assets/js/270.82414c58.js"><link rel="prefetch" href="/assets/js/271.88d41d2f.js"><link rel="prefetch" href="/assets/js/272.fdea98e3.js"><link rel="prefetch" href="/assets/js/273.291d7bce.js"><link rel="prefetch" href="/assets/js/274.6470bef1.js"><link rel="prefetch" href="/assets/js/275.ae5aaecb.js"><link rel="prefetch" href="/assets/js/276.6249c409.js"><link rel="prefetch" href="/assets/js/277.c281acfe.js"><link rel="prefetch" href="/assets/js/278.4bf4de94.js"><link rel="prefetch" href="/assets/js/279.62240a5f.js"><link rel="prefetch" href="/assets/js/28.7b66a9da.js"><link rel="prefetch" href="/assets/js/280.a05c4459.js"><link rel="prefetch" href="/assets/js/281.f5dbccd2.js"><link rel="prefetch" href="/assets/js/282.3c8929fa.js"><link rel="prefetch" href="/assets/js/283.8632920a.js"><link rel="prefetch" href="/assets/js/284.74b2e3cc.js"><link rel="prefetch" href="/assets/js/285.1c3bb787.js"><link rel="prefetch" href="/assets/js/286.145be126.js"><link rel="prefetch" href="/assets/js/287.0a623eba.js"><link rel="prefetch" href="/assets/js/288.e07989da.js"><link rel="prefetch" href="/assets/js/289.2f5fdfd9.js"><link rel="prefetch" href="/assets/js/29.ebd9ba6b.js"><link rel="prefetch" href="/assets/js/290.0b12e49c.js"><link rel="prefetch" href="/assets/js/291.fc65a93a.js"><link rel="prefetch" href="/assets/js/292.2beb238d.js"><link rel="prefetch" href="/assets/js/293.87c822f4.js"><link rel="prefetch" href="/assets/js/294.450b6510.js"><link rel="prefetch" href="/assets/js/295.9191ddf7.js"><link rel="prefetch" href="/assets/js/296.92ec965c.js"><link rel="prefetch" href="/assets/js/297.68c01079.js"><link rel="prefetch" href="/assets/js/298.768b54ab.js"><link rel="prefetch" href="/assets/js/299.c2b57741.js"><link rel="prefetch" href="/assets/js/3.cd795b12.js"><link rel="prefetch" href="/assets/js/30.05a622e0.js"><link rel="prefetch" href="/assets/js/300.f409e502.js"><link rel="prefetch" href="/assets/js/301.56e89c78.js"><link rel="prefetch" href="/assets/js/302.942b0d94.js"><link rel="prefetch" href="/assets/js/303.d3946671.js"><link rel="prefetch" href="/assets/js/304.a346c8aa.js"><link rel="prefetch" href="/assets/js/305.46fa308b.js"><link rel="prefetch" href="/assets/js/306.c7f27ad8.js"><link rel="prefetch" href="/assets/js/307.0c8cf8c0.js"><link rel="prefetch" href="/assets/js/308.1d2db23d.js"><link rel="prefetch" href="/assets/js/309.2055654b.js"><link rel="prefetch" href="/assets/js/31.cc1bdb96.js"><link rel="prefetch" href="/assets/js/310.b6b7887a.js"><link rel="prefetch" href="/assets/js/311.e605ceab.js"><link rel="prefetch" href="/assets/js/312.52192bb7.js"><link rel="prefetch" href="/assets/js/313.2698bd8e.js"><link rel="prefetch" href="/assets/js/314.5d9073d0.js"><link rel="prefetch" href="/assets/js/315.c409cde3.js"><link rel="prefetch" href="/assets/js/316.2bf0e6df.js"><link rel="prefetch" href="/assets/js/317.5798e7df.js"><link rel="prefetch" href="/assets/js/318.95986f30.js"><link rel="prefetch" href="/assets/js/319.e6def8d6.js"><link rel="prefetch" href="/assets/js/32.ef0d5dba.js"><link rel="prefetch" href="/assets/js/320.8b3e8e94.js"><link rel="prefetch" href="/assets/js/321.f936d520.js"><link rel="prefetch" href="/assets/js/322.cdb3332c.js"><link rel="prefetch" href="/assets/js/323.4e193830.js"><link rel="prefetch" href="/assets/js/324.5da1850e.js"><link rel="prefetch" href="/assets/js/325.ff5ccde4.js"><link rel="prefetch" href="/assets/js/326.160651b1.js"><link rel="prefetch" href="/assets/js/327.db3feae7.js"><link rel="prefetch" href="/assets/js/328.4ebf4ae0.js"><link rel="prefetch" href="/assets/js/329.f71c3883.js"><link rel="prefetch" href="/assets/js/33.3c571bbe.js"><link rel="prefetch" href="/assets/js/330.885ae61c.js"><link rel="prefetch" href="/assets/js/331.b1a938ba.js"><link rel="prefetch" href="/assets/js/332.b142c42b.js"><link rel="prefetch" href="/assets/js/333.b8076f78.js"><link rel="prefetch" href="/assets/js/334.ad22ab75.js"><link rel="prefetch" href="/assets/js/335.88564fd2.js"><link rel="prefetch" href="/assets/js/336.39134b8d.js"><link rel="prefetch" href="/assets/js/337.df1ebc2c.js"><link rel="prefetch" href="/assets/js/34.270daa56.js"><link rel="prefetch" href="/assets/js/35.15d989c9.js"><link rel="prefetch" href="/assets/js/36.2e8aeb80.js"><link rel="prefetch" href="/assets/js/37.7b762275.js"><link rel="prefetch" href="/assets/js/38.22ec6ac7.js"><link rel="prefetch" href="/assets/js/39.bdb3430a.js"><link rel="prefetch" href="/assets/js/4.f7fa33d6.js"><link rel="prefetch" href="/assets/js/40.345f3c53.js"><link rel="prefetch" href="/assets/js/41.e93aab58.js"><link rel="prefetch" href="/assets/js/42.e7446174.js"><link rel="prefetch" href="/assets/js/43.3bbfdb12.js"><link rel="prefetch" href="/assets/js/45.82f2cc4f.js"><link rel="prefetch" href="/assets/js/46.342f85bd.js"><link rel="prefetch" href="/assets/js/47.f2f6fe03.js"><link rel="prefetch" href="/assets/js/48.99fd0146.js"><link rel="prefetch" href="/assets/js/49.2634fd40.js"><link rel="prefetch" href="/assets/js/5.ae42b7a0.js"><link rel="prefetch" href="/assets/js/50.691080e8.js"><link rel="prefetch" href="/assets/js/51.292e4b2b.js"><link rel="prefetch" href="/assets/js/52.30b4a61b.js"><link rel="prefetch" href="/assets/js/53.2c6237df.js"><link rel="prefetch" href="/assets/js/54.49456bfa.js"><link rel="prefetch" href="/assets/js/55.4710856c.js"><link rel="prefetch" href="/assets/js/56.0334fc17.js"><link rel="prefetch" href="/assets/js/57.4f70d0ed.js"><link rel="prefetch" href="/assets/js/58.d9a970bf.js"><link rel="prefetch" href="/assets/js/59.7a4b31fd.js"><link rel="prefetch" href="/assets/js/6.d5889eef.js"><link rel="prefetch" href="/assets/js/60.417e05df.js"><link rel="prefetch" href="/assets/js/61.c7980332.js"><link rel="prefetch" href="/assets/js/62.58f3c155.js"><link rel="prefetch" href="/assets/js/63.7229815d.js"><link rel="prefetch" href="/assets/js/64.0d72da6d.js"><link rel="prefetch" href="/assets/js/65.2c623405.js"><link rel="prefetch" href="/assets/js/66.d170f5ad.js"><link rel="prefetch" href="/assets/js/67.01023aac.js"><link rel="prefetch" href="/assets/js/68.018604c5.js"><link rel="prefetch" href="/assets/js/69.abbe4df3.js"><link rel="prefetch" href="/assets/js/7.bf0f2b67.js"><link rel="prefetch" href="/assets/js/70.962b3ba0.js"><link rel="prefetch" href="/assets/js/71.a5606282.js"><link rel="prefetch" href="/assets/js/72.975041a5.js"><link rel="prefetch" href="/assets/js/73.d93206af.js"><link rel="prefetch" href="/assets/js/74.67fe0aca.js"><link rel="prefetch" href="/assets/js/75.a321d6fc.js"><link rel="prefetch" href="/assets/js/76.2a44bacd.js"><link rel="prefetch" href="/assets/js/77.90387be7.js"><link rel="prefetch" href="/assets/js/78.c6455938.js"><link rel="prefetch" href="/assets/js/79.8c3687c2.js"><link rel="prefetch" href="/assets/js/8.0b70db32.js"><link rel="prefetch" href="/assets/js/80.ed6a6259.js"><link rel="prefetch" href="/assets/js/81.9cc4a70c.js"><link rel="prefetch" href="/assets/js/82.4dfd22c3.js"><link rel="prefetch" href="/assets/js/83.bbe5ca26.js"><link rel="prefetch" href="/assets/js/84.0141f56f.js"><link rel="prefetch" href="/assets/js/85.26069038.js"><link rel="prefetch" href="/assets/js/86.c22416bd.js"><link rel="prefetch" href="/assets/js/87.ad2b839e.js"><link rel="prefetch" href="/assets/js/88.de3f91d8.js"><link rel="prefetch" href="/assets/js/89.abb8ff44.js"><link rel="prefetch" href="/assets/js/9.5282ef41.js"><link rel="prefetch" href="/assets/js/90.8dab802c.js"><link rel="prefetch" href="/assets/js/91.67430952.js"><link rel="prefetch" href="/assets/js/92.c95aaeec.js"><link rel="prefetch" href="/assets/js/93.d68e1554.js"><link rel="prefetch" href="/assets/js/94.f9fd1744.js"><link rel="prefetch" href="/assets/js/95.a4fd9b78.js"><link rel="prefetch" href="/assets/js/96.32d95188.js"><link rel="prefetch" href="/assets/js/97.3bf42546.js"><link rel="prefetch" href="/assets/js/98.a032b733.js"><link rel="prefetch" href="/assets/js/99.fc7abb0d.js">
    <link rel="stylesheet" href="/assets/css/0.styles.bc84ce4b.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu have-body-img"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/logo.png" alt="flokken's blog" class="logo"> <span class="site-name can-hide">flokken's blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><!----> <span class="title" style="display:;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>web开发</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/javascript/" class="nav-link">JavaScript</a></li><li class="dropdown-subitem"><a href="/vue/" class="nav-link">Vue</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="后端开发" class="dropdown-title"><!----> <span class="title" style="display:;">后端开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/java/" class="nav-link">Java开发</a></li><li class="dropdown-item"><!----> <a href="/go/" class="nav-link">Go开发</a></li><li class="dropdown-item"><!----> <a href="/microservice/" class="nav-link">微服务开发</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="AI" class="dropdown-title"><!----> <span class="title" style="display:;">AI</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/KG/" class="nav-link">知识图谱</a></li><li class="dropdown-item"><!----> <a href="/DL/" class="nav-link">深度学习</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="安全与运维" class="dropdown-title"><!----> <span class="title" style="display:;">安全与运维</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/reverse/" class="nav-link">逆向</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="大数据" class="dropdown-title"><!----> <span class="title" style="display:;">大数据</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/spark/" class="nav-link">Spark</a></li><li class="dropdown-item"><!----> <a href="/spider/" class="nav-link">Spider</a></li><li class="dropdown-item"><!----> <a href="/mysql/" class="nav-link">MySQL</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法与数据结构" class="dropdown-title"><!----> <span class="title" style="display:;">算法与数据结构</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/algorithm/" class="nav-link">算法</a></li><li class="dropdown-item"><!----> <a href="/datastructure/" class="nav-link">数据结构</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="其他" class="dropdown-title"><!----> <span class="title" style="display:;">其他</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/tips/" class="nav-link">小知识</a></li></ul></div></div> <a href="https://github.com/flokken" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/avtar.png"> <div class="blogger-info"><h3>flokken</h3> <span>一个大水货</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><!----> <span class="title" style="display:;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>web开发</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/javascript/" class="nav-link">JavaScript</a></li><li class="dropdown-subitem"><a href="/vue/" class="nav-link">Vue</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="后端开发" class="dropdown-title"><!----> <span class="title" style="display:;">后端开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/java/" class="nav-link">Java开发</a></li><li class="dropdown-item"><!----> <a href="/go/" class="nav-link">Go开发</a></li><li class="dropdown-item"><!----> <a href="/microservice/" class="nav-link">微服务开发</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="AI" class="dropdown-title"><!----> <span class="title" style="display:;">AI</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/KG/" class="nav-link">知识图谱</a></li><li class="dropdown-item"><!----> <a href="/DL/" class="nav-link">深度学习</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="安全与运维" class="dropdown-title"><!----> <span class="title" style="display:;">安全与运维</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/reverse/" class="nav-link">逆向</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="大数据" class="dropdown-title"><!----> <span class="title" style="display:;">大数据</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/spark/" class="nav-link">Spark</a></li><li class="dropdown-item"><!----> <a href="/spider/" class="nav-link">Spider</a></li><li class="dropdown-item"><!----> <a href="/mysql/" class="nav-link">MySQL</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法与数据结构" class="dropdown-title"><!----> <span class="title" style="display:;">算法与数据结构</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/algorithm/" class="nav-link">算法</a></li><li class="dropdown-item"><!----> <a href="/datastructure/" class="nav-link">数据结构</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="其他" class="dropdown-title"><!----> <span class="title" style="display:;">其他</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/tips/" class="nav-link">小知识</a></li></ul></div></div> <a href="https://github.com/flokken" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>知识图谱</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>深度学习</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Pytorch</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>深度学习-李宏毅2022</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>鱼书-深度学习入门</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/435b55/" class="sidebar-link">numpy与matplotlib</a></li><li><a href="/pages/11726c/" class="sidebar-link">感知机与神经网络</a></li><li><a href="/pages/6c444b/" class="sidebar-link">损失函数</a></li><li><a href="/pages/1c6d13/" aria-current="page" class="active sidebar-link">数值微分与梯度</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/pages/1c6d13/#例子" class="sidebar-link">例子</a></li><li class="sidebar-sub-header level2"><a href="/pages/1c6d13/#偏导数" class="sidebar-link">偏导数</a></li><li class="sidebar-sub-header level2"><a href="/pages/1c6d13/#是什么" class="sidebar-link">是什么</a></li><li class="sidebar-sub-header level2"><a href="/pages/1c6d13/#梯度法" class="sidebar-link">梯度法</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/1c6d13/#梯度下降实现" class="sidebar-link">梯度下降实现</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c6d13/#实例" class="sidebar-link">实例</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c6d13/#学习率的影响" class="sidebar-link">学习率的影响</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/1c6d13/#神经网络的梯度" class="sidebar-link">神经网络的梯度</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/1c6d13/#一个两层神经网络" class="sidebar-link">一个两层神经网络</a></li><li class="sidebar-sub-header level4"><a href="/pages/1c6d13/#参数解释" class="sidebar-link">参数解释</a></li><li class="sidebar-sub-header level4"><a href="/pages/1c6d13/#使用" class="sidebar-link">使用</a></li><li class="sidebar-sub-header level5"><a href="/pages/1c6d13/#加入mini-batch" class="sidebar-link">加入mini-batch</a></li><li class="sidebar-sub-header level5"><a href="/pages/1c6d13/#基于测试数据来评价" class="sidebar-link">基于测试数据来评价</a></li></ul></li></ul></li><li><a href="/pages/81deb7/" class="sidebar-link">误差反向传播</a></li><li><a href="/pages/803669/" class="sidebar-link">神经网络的学习技巧</a></li><li><a href="/pages/88621c/" class="sidebar-link">CNN介绍</a></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>鱼书-自然语言处理</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>论文阅读</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/categories/?category=AI" title="分类" data-v-06225672>AI</a></li><li data-v-06225672><a href="/categories/?category=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" title="分类" data-v-06225672>深度学习</a></li><li data-v-06225672><a href="/categories/?category=%E9%B1%BC%E4%B9%A6-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8" title="分类" data-v-06225672>鱼书-深度学习入门</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/Flokken" target="_blank" title="作者" class="beLink" data-v-06225672>flokken</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-03-27</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">数值微分与梯度<!----></h1>  <div class="theme-vdoing-content content__default"><h1 id="数值微分"><a href="#数值微分" class="header-anchor">#</a> 数值微分</h1> <p>在神经网络学习中，一般使用梯度法。介绍梯度之前，先了解一下导数。</p> <p>当然，我们知道导数就是表示函数某个瞬间的变化量，这里介绍他的定义式:</p> <p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230327221101154.png" alt="image-20230327221101154"></p> <p>一般来说，我们把<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="h"></mjx-c></mjx-mi></mjx-math></mjx-container>定义为<strong>一个比较小的值</strong>，就可以根据上面的公式计算导数了！</p> <p>注意：程序表示浮点数是有精度限制的，例如<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="h"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mn space="3" class="mjx-n"><mjx-c c="5"></mjx-c><mjx-c c="0"></mjx-c></mjx-mn></mjx-math></mjx-container><strong>可以吗？</strong>，理论上可以，实际上不行，因为1e-50太小了，python会2直接把他当成0，<strong>就会导致除以0这个错误</strong>，因此，这里取<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="h"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mn space="3" class="mjx-n"><mjx-c c="4"></mjx-c></mjx-mn></mjx-math></mjx-container>来实现上面的函数。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment">#利用数值微分求导,这里的h就是一个很小的数，也可以更换</span>
<span class="token keyword">def</span> <span class="token function">numerical_diff</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    h <span class="token operator">=</span> <span class="token number">1e-4</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>f<span class="token punctuation">(</span>x<span class="token operator">+</span>h<span class="token punctuation">)</span> <span class="token operator">-</span> f<span class="token punctuation">(</span>x<span class="token operator">-</span>h<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>h<span class="token punctuation">)</span>
    <span class="token comment">#这里使用的中心误差</span>

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><blockquote><p>但是根据以前的知识，好像可以用公式直接求导的啊，是这样的，上面的那种方式叫数值微分求导，我们数学课里一般用的叫解析性求导，比如<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msup space="4"><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container>的导数为<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mn class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-math></mjx-container>所以当<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-math></mjx-container>时，其导数为2，但是上面那个求出来是近似为2</p></blockquote> <h2 id="例子"><a href="#例子" class="header-anchor">#</a> 例子</h2> <p>以<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="0"></mjx-c><mjx-c c="."></mjx-c><mjx-c c="0"></mjx-c><mjx-c c="1"></mjx-c></mjx-mn><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-mn space="3" class="mjx-n"><mjx-c c="0"></mjx-c><mjx-c c="."></mjx-c><mjx-c c="1"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-math></mjx-container></p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">function_1</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">0.01</span><span class="token operator">*</span>x<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token number">0.1</span><span class="token operator">*</span>x
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pylab <span class="token keyword">as</span> plt
x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">20.0</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> function_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">&quot;x&quot;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">&quot;f(x)&quot;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230327112911909.png" style="zoom:70;"> <p>求<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="5"></mjx-c></mjx-mn><mjx-mo space="4" class="mjx-n"><mjx-utext variant="normal" style="font-family:serif;">与</mjx-utext></mjx-mo><mjx-mi space="4" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="1"></mjx-c><mjx-c c="0"></mjx-c></mjx-mn></mjx-math></mjx-container>处的导数</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>t<span class="token operator">=</span>numerical_diff<span class="token punctuation">(</span>function_1<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
z<span class="token operator">=</span>numerical_diff<span class="token punctuation">(</span>function_1<span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">,</span>z<span class="token punctuation">)</span>
<span class="token comment">#0.1999999999990898 0.2999999999986347</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>利用解析性求导我们知道，<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-i"><mjx-c c="d"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="f"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-i"><mjx-c c="d"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="0"></mjx-c><mjx-c c="."></mjx-c><mjx-c c="0"></mjx-c><mjx-c c="2"></mjx-c></mjx-mn><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-mn space="3" class="mjx-n"><mjx-c c="0"></mjx-c><mjx-c c="."></mjx-c><mjx-c c="1"></mjx-c></mjx-mn></mjx-math></mjx-container></p> <p>在<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="5"></mjx-c></mjx-mn></mjx-math></mjx-container>和<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="1"></mjx-c><mjx-c c="0"></mjx-c></mjx-mn></mjx-math></mjx-container>处导数分别是0.2和0.3，因此数值微分可以求到非常近似，可以认为是相等的解。</p> <h2 id="偏导数"><a href="#偏导数" class="header-anchor">#</a> 偏导数</h2> <p>如果函数中，不止有一个变量，那么求导时，<strong>就需要区分是对那个变量求导数</strong></p> <p><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="f"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.288em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn><mjx-spacer style="margin-top:0.18em;"></mjx-spacer><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msubsup><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-msubsup space="3"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.288em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn><mjx-spacer style="margin-top:0.18em;"></mjx-spacer><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msubsup></mjx-math></mjx-container></p> <p>对<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container>求导时<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="f"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container>,<strong>这种就叫做偏导数</strong></p> <p><strong>例子</strong>：</p> <p>求<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="3"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="4"></mjx-c></mjx-mn></mjx-math></mjx-container>时，关于<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container>的偏导数<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="f"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container></p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">tmp1</span><span class="token punctuation">(</span>x0<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x0<span class="token operator">*</span>x0 <span class="token operator">+</span> <span class="token number">4.0</span><span class="token operator">**</span><span class="token number">2.0</span>
t<span class="token operator">=</span>numerical_diff<span class="token punctuation">(</span>tmp1<span class="token punctuation">,</span><span class="token number">3.0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span>
<span class="token comment">#6.00000000000378</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>我们可以发现，求偏导数时，目标变量外的其他变量值应当是一个固定的某个值。</p> <h1 id="梯度"><a href="#梯度" class="header-anchor">#</a> 梯度</h1> <h2 id="是什么"><a href="#是什么" class="header-anchor">#</a> 是什么</h2> <p>如果我们把上面例子中的的<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container>的偏导数一起计算，比如，当<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="3"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="4"></mjx-c></mjx-mn></mjx-math></mjx-container>时<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container>的偏导数<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="f"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mfrac space="2"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="f"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container>。如<strong>果像这样</strong></p> <p><strong>把全部变量的偏导数汇总形成的向量称为梯度</strong>。</p> <blockquote><p>示例 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="f"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.288em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn><mjx-spacer style="margin-top:0.18em;"></mjx-spacer><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msubsup><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-msubsup space="3"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.288em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn><mjx-spacer style="margin-top:0.18em;"></mjx-spacer><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msubsup></mjx-math></mjx-container></p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">function_2</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span>
<span class="token comment">#return np.sum(x**2)</span>
<span class="token keyword">def</span> <span class="token function">numerical_gradient</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    h <span class="token operator">=</span> <span class="token number">1e-4</span>
    grad <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment">#生成和x形状相同数组，并且元素都是0</span>
    
    <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#f(x+h)</span>
        tmp_val <span class="token operator">=</span> x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp_val <span class="token operator">+</span> h
        fxh1 <span class="token operator">=</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment">#f(x-h)</span>
        x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp_val <span class="token operator">-</span> h
        fxh2 <span class="token operator">=</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        
        grad<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>fxh1 <span class="token operator">-</span> fxh2<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> h<span class="token punctuation">)</span>
        x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp_val<span class="token comment">#还原值</span>
    <span class="token keyword">return</span> grad
        
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><p>计算梯度</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">print</span><span class="token punctuation">(</span>numerical_gradient<span class="token punctuation">(</span>function_2<span class="token punctuation">,</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>numerical_gradient<span class="token punctuation">(</span>function_2<span class="token punctuation">,</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#[6. 8.]</span>
<span class="token comment">#[0. 4.]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>有什么用呢，这里如果把梯度表示为箭头，并且画在图上</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># coding: utf-8</span>
<span class="token comment"># cf.http://d.hatena.ne.jp/white_wheels/20100327/p3</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pylab <span class="token keyword">as</span> plt
<span class="token keyword">from</span> mpl_toolkits<span class="token punctuation">.</span>mplot3d <span class="token keyword">import</span> Axes3D


<span class="token keyword">def</span> <span class="token function">_numerical_gradient_no_batch</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    h <span class="token operator">=</span> <span class="token number">1e-4</span> <span class="token comment"># 0.0001</span>
    grad <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    
    <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        tmp_val <span class="token operator">=</span> x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>tmp_val<span class="token punctuation">)</span> <span class="token operator">+</span> h
        fxh1 <span class="token operator">=</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># f(x+h)</span>
        
        x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp_val <span class="token operator">-</span> h 
        fxh2 <span class="token operator">=</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># f(x-h)</span>
        grad<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>fxh1 <span class="token operator">-</span> fxh2<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>h<span class="token punctuation">)</span>
        
        x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp_val <span class="token comment"># 还原值</span>
        
    <span class="token keyword">return</span> grad


<span class="token keyword">def</span> <span class="token function">numerical_gradient</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> X<span class="token punctuation">.</span>ndim <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> _numerical_gradient_no_batch<span class="token punctuation">(</span>f<span class="token punctuation">,</span> X<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        grad <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        
        <span class="token keyword">for</span> idx<span class="token punctuation">,</span> x <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
            grad<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> _numerical_gradient_no_batch<span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> grad


<span class="token keyword">def</span> <span class="token function">function_2</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> x<span class="token punctuation">.</span>ndim <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>x<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>x<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">tangent_line</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    d <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span>
    y <span class="token operator">=</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">-</span> d<span class="token operator">*</span>x
    <span class="token keyword">return</span> <span class="token keyword">lambda</span> t<span class="token punctuation">:</span> d<span class="token operator">*</span>t <span class="token operator">+</span> y
     
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    x0 <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">,</span> <span class="token number">0.25</span><span class="token punctuation">)</span>
    x1 <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">,</span> <span class="token number">0.25</span><span class="token punctuation">)</span>
    X<span class="token punctuation">,</span> Y <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>x0<span class="token punctuation">,</span> x1<span class="token punctuation">)</span>
    
    X <span class="token operator">=</span> X<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
    Y <span class="token operator">=</span> Y<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    grad <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>function_2<span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">)</span>
    
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>quiver<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> <span class="token operator">-</span>grad<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span>grad<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  angles<span class="token operator">=</span><span class="token string">&quot;xy&quot;</span><span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">&quot;#666666&quot;</span><span class="token punctuation">)</span><span class="token comment">#,headwidth=10,scale=40,color=&quot;#444444&quot;)</span>
    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'x0'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'x1'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>draw<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br></div></div><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230327155844159.png" style="zoom:70%;"> <blockquote><p>注意，这里画图时，给梯度加了个负号，也就是负梯度</p></blockquote> <p>我们可以发现，箭头都指向最小值点，并且离最小值最远的点，箭头偏的越厉害。</p> <p>这就是梯度的重要性质：<strong>梯度指向各点处函数值减小最多的方向</strong></p> <blockquote><p>高数中，方向导数为<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="c"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="o"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="s"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="3B8"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="D7"></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-utext variant="normal" style="font-family:serif;">梯</mjx-utext><mjx-utext variant="normal" style="font-family:serif;">度</mjx-utext></mjx-mo></mjx-math></mjx-container>,（<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B8"></mjx-c></mjx-mi></mjx-math></mjx-container>是方向导数与梯度方向夹角），所以沿梯度下降最多</p></blockquote> <h2 id="梯度法"><a href="#梯度法" class="header-anchor">#</a> 梯度法</h2> <p>沿着梯度，函数减少最多。因此在寻找函数的最小值时，可以沿着梯度的方向前进，前进一段距离后，在此处计算新的梯度，用新梯度继续前进，<strong>这种方法就叫梯度法</strong></p> <blockquote><p>注意，梯度法找到的是鞍点（极小值，最小值梯度都是0，梯度为0就叫鞍点），因此梯度法如果进入了一个极小值的区域，他就会停止下降了，但是这个点是极小值，并不是最小值</p></blockquote> <blockquote><p>如果找最小值，叫梯度下降，最大值，叫梯度上升，但是只要反转一下损失函数的符号，这两个问题就是同一个问题，因此一般不做区分，就叫梯度下降法.</p></blockquote> <p>用公式表达更新过程 ，<strong>这个过程会循环进行</strong></p> <p><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="3B7"></mjx-c></mjx-mi><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="f"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container></p> <p><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="3B7"></mjx-c></mjx-mi><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="f"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container></p> <blockquote><p><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B7"></mjx-c></mjx-mi></mjx-math></mjx-container>是学习率，需要手动设置</p></blockquote> <h3 id="梯度下降实现"><a href="#梯度下降实现" class="header-anchor">#</a> 梯度下降实现</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">gradient_descent</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span>init_x<span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>step_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> init_x
    
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>step_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
        grad <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>f<span class="token punctuation">,</span>x<span class="token punctuation">)</span>
        x <span class="token operator">-=</span> lr <span class="token operator">*</span> grad<span class="token comment">#这里可以看成就是向量表示的更新过程</span>
        
    <span class="token keyword">return</span> x
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h3 id="实例"><a href="#实例" class="header-anchor">#</a> 实例</h3> <p>用梯度法求<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="f"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msubsup space="4"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.288em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn><mjx-spacer style="margin-top:0.18em;"></mjx-spacer><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msubsup><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-msubsup space="3"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.288em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn><mjx-spacer style="margin-top:0.18em;"></mjx-spacer><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msubsup></mjx-math></mjx-container>的最小值</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>init_x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>gradient_descent<span class="token punctuation">(</span>function_2<span class="token punctuation">,</span>init_x<span class="token operator">=</span>init_x<span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>step_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#[-6.11110793e-10  8.14814391e-10]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>如果用图来表示这个过程,可以看到原点是最低的地方，函数在一点点靠近哪=那里。</p> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230327163114997.png" style="zoom:70%;"> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># coding: utf-8</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pylab <span class="token keyword">as</span> plt
<span class="token comment">#from gradient_2d import numerical_gradient</span>

<span class="token keyword">def</span> <span class="token function">numerical_gradient</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> X<span class="token punctuation">.</span>ndim <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> _numerical_gradient_no_batch<span class="token punctuation">(</span>f<span class="token punctuation">,</span> X<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        grad <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        
        <span class="token keyword">for</span> idx<span class="token punctuation">,</span> x <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
            grad<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> _numerical_gradient_no_batch<span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> grad


<span class="token keyword">def</span> <span class="token function">gradient_descent</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> init_x<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> step_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> init_x
    x_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>step_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span> x<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">)</span>

        grad <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        x <span class="token operator">-=</span> lr <span class="token operator">*</span> grad

    <span class="token keyword">return</span> x<span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x_history<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">function_2</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span>

init_x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    

lr <span class="token operator">=</span> <span class="token number">0.1</span>
step_num <span class="token operator">=</span> <span class="token number">20</span>
x<span class="token punctuation">,</span> x_history <span class="token operator">=</span> gradient_descent<span class="token punctuation">(</span>function_2<span class="token punctuation">,</span> init_x<span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> step_num<span class="token operator">=</span>step_num<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'--b'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'--b'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_history<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x_history<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'o'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3.5</span><span class="token punctuation">,</span> <span class="token number">3.5</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">4.5</span><span class="token punctuation">,</span> <span class="token number">4.5</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">&quot;X0&quot;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">&quot;X1&quot;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br></div></div><h3 id="学习率的影响"><a href="#学习率的影响" class="header-anchor">#</a> 学习率的影响</h3> <p>学习率过大或者过小，都会导致不能到一个”好的位置“，一般刚开始设置为0.01或者0.001，边学习观察是否正确学习，据此改变学习率。</p> <p>以上面的例子来展现学习率影响</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>lr<span class="token operator">=</span><span class="token number">10.0</span>
init_x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>gradient_descent<span class="token punctuation">(</span>function_2<span class="token punctuation">,</span>init_x<span class="token operator">=</span>init_x<span class="token punctuation">,</span>lr<span class="token operator">=</span>lr<span class="token punctuation">,</span>step_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#[-2.58983747e+13 -1.29524862e+12]</span>
lr<span class="token operator">=</span><span class="token number">1e-10</span>
init_x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>gradient_descent<span class="token punctuation">(</span>function_2<span class="token punctuation">,</span>init_x<span class="token operator">=</span>init_x<span class="token punctuation">,</span>lr<span class="token operator">=</span>lr<span class="token punctuation">,</span>step_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#[-2.99999994  3.99999992]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><blockquote><p>学习率这种需要手工设置的参数叫超参数</p></blockquote> <h2 id="神经网络的梯度"><a href="#神经网络的梯度" class="header-anchor">#</a> 神经网络的梯度</h2> <p>神经网络的梯度指的是损失函数关于权重参数的梯度</p> <p>这里注意<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mo class="mjx-n"><mjx-utext variant="normal" style="font-family:serif;">权</mjx-utext><mjx-utext variant="normal" style="font-family:serif;">重</mjx-utext><mjx-utext variant="normal" style="font-family:serif;">参</mjx-utext><mjx-utext variant="normal" style="font-family:serif;">数</mjx-utext><mjx-utext variant="normal" style="font-family:serif;">向</mjx-utext><mjx-utext variant="normal" style="font-family:serif;">量</mjx-utext></mjx-mo><mjx-mi space="4" class="mjx-i"><mjx-c c="W"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-utext variant="normal" style="font-family:serif;">和</mjx-utext><mjx-utext variant="normal" style="font-family:serif;">梯</mjx-utext><mjx-utext variant="normal" style="font-family:serif;">度</mjx-utext></mjx-mo><mjx-mfrac space="4"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="W"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container>形状相同，<strong>都是2X3</strong></p> <p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230327172347643.png" alt="image-20230327172347643"></p> <p><strong>神经网络学习步骤</strong></p> <ol><li>minibatch</li> <li>计算梯度</li> <li>更新参数</li> <li>重复1,2,3</li></ol> <h3 id="一个两层神经网络"><a href="#一个两层神经网络" class="header-anchor">#</a> 一个两层神经网络</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># coding: utf-8</span>
<span class="token keyword">import</span> sys<span class="token punctuation">,</span> os
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>pardir<span class="token punctuation">)</span>  <span class="token comment"># 为了导入父目录的文件而进行的设定</span>
<span class="token keyword">from</span> common<span class="token punctuation">.</span>functions <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> common<span class="token punctuation">.</span>gradient <span class="token keyword">import</span> numerical_gradient

<span class="token keyword">class</span> <span class="token class-name">TwoLayerNet</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> weight_init_std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 初始化权重</span>
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>output_size<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        W1<span class="token punctuation">,</span> W2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span>
        b1<span class="token punctuation">,</span> b2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span>
    
        a1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> W1<span class="token punctuation">)</span> <span class="token operator">+</span> b1
        z1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>a1<span class="token punctuation">)</span>
        a2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>z1<span class="token punctuation">,</span> W2<span class="token punctuation">)</span> <span class="token operator">+</span> b2
        y <span class="token operator">=</span> softmax<span class="token punctuation">(</span>a2<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> y
        
    <span class="token comment"># x:输入数据, t:监督数据</span>
    <span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> cross_entropy_error<span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        y <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        t <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>t<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        
        accuracy <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y <span class="token operator">==</span> t<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">float</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> accuracy
        
    <span class="token comment"># x:输入数据, t:监督数据</span>
    <span class="token keyword">def</span> <span class="token function">numerical_gradient</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        loss_W <span class="token operator">=</span> <span class="token keyword">lambda</span> W<span class="token punctuation">:</span> self<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t<span class="token punctuation">)</span>
        
        grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> numerical_gradient<span class="token punctuation">(</span>loss_W<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> grads
        
    <span class="token keyword">def</span> <span class="token function">gradient</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        W1<span class="token punctuation">,</span> W2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span>
        b1<span class="token punctuation">,</span> b2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span>
        grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        
        batch_num <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        
        <span class="token comment"># forward</span>
        a1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> W1<span class="token punctuation">)</span> <span class="token operator">+</span> b1
        z1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>a1<span class="token punctuation">)</span>
        a2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>z1<span class="token punctuation">,</span> W2<span class="token punctuation">)</span> <span class="token operator">+</span> b2
        y <span class="token operator">=</span> softmax<span class="token punctuation">(</span>a2<span class="token punctuation">)</span>
        
        <span class="token comment"># backward</span>
        dy <span class="token operator">=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> t<span class="token punctuation">)</span> <span class="token operator">/</span> batch_num
        grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>z1<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dy<span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dy<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        
        da1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dy<span class="token punctuation">,</span> W2<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
        dz1 <span class="token operator">=</span> sigmoid_grad<span class="token punctuation">(</span>a1<span class="token punctuation">)</span> <span class="token operator">*</span> da1
        grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dz1<span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dz1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> grads
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br></div></div><h4 id="参数解释"><a href="#参数解释" class="header-anchor">#</a> 参数解释</h4> <p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230327172439841.png" alt="image-20230327172439841"></p> <p>方法解释</p> <p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230327172457328.png" alt="image-20230327172457328"></p> <h4 id="使用"><a href="#使用" class="header-anchor">#</a> 使用</h4> <p>首先可以看一下<strong>参数形状</strong></p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>net <span class="token operator">=</span> TwoLayerNet<span class="token punctuation">(</span>input_size<span class="token operator">=</span><span class="token number">784</span><span class="token punctuation">,</span> hidden_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> output_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># (784, 100)</span>
net<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># (100,)</span>
net<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># (100, 10)</span>
net<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># (10,)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>注意梯度的形状也是一样的</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span> <span class="token comment"># 伪输入数据（100笔）</span>
t <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment"># 伪正确解标签（100笔）</span>
grads <span class="token operator">=</span> net<span class="token punctuation">.</span>numerical_gradient<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t<span class="token punctuation">)</span> <span class="token comment"># 计算梯度</span>
grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># (784, 100)</span>
grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># (100,)</span>
grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># (100, 10)</span>
grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># (10,)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h5 id="加入mini-batch"><a href="#加入mini-batch" class="header-anchor">#</a> <strong>加入mini-batch</strong></h5> <blockquote><p>随机梯度下降法（stochastic gradient descent）。“随机”指的是“随机选择的”</p> <p>的意思，因此，随机梯度下降法是“对随机选择的数据进行的梯度下降法”。</p> <p>深度学习的很多框架中，随机梯度下降法一般由一个名为<strong>SGD</strong>的函数来实现。</p> <p>比如每10000个数据中，每次随机选一个mini-batch（大小为100），就是随机梯度下降</p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># coding: utf-8</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> dataset<span class="token punctuation">.</span>mnist <span class="token keyword">import</span> load_mnist
<span class="token comment"># 读入数据</span>
<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">)</span> <span class="token operator">=</span> load_mnist<span class="token punctuation">(</span>normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> one_hot_label<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

network <span class="token operator">=</span> TwoLayerNet<span class="token punctuation">(</span>input_size<span class="token operator">=</span><span class="token number">784</span><span class="token punctuation">,</span> hidden_size<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> output_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

iters_num <span class="token operator">=</span> <span class="token number">10000</span>  <span class="token comment"># 适当设定循环的次数</span>
train_size <span class="token operator">=</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
batch_size <span class="token operator">=</span> <span class="token number">100</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.1</span>

train_loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
train_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
test_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

iter_per_epoch <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>train_size <span class="token operator">/</span> batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>iters_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    batch_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>train_size<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>
    x_batch <span class="token operator">=</span> x_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>
    t_batch <span class="token operator">=</span> t_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>
    
    <span class="token comment"># 计算梯度</span>
    grad <span class="token operator">=</span> network<span class="token punctuation">.</span>numerical_gradient<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> t_batch<span class="token punctuation">)</span>
    <span class="token comment">#grad = network.gradient(x_batch, t_batch)</span>
    
    <span class="token comment"># 更新参数</span>
    <span class="token keyword">for</span> key <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">'W1'</span><span class="token punctuation">,</span> <span class="token string">'b1'</span><span class="token punctuation">,</span> <span class="token string">'W2'</span><span class="token punctuation">,</span> <span class="token string">'b2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        network<span class="token punctuation">.</span>params<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> grad<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
    
    loss <span class="token operator">=</span> network<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> t_batch<span class="token punctuation">)</span>
    train_loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
    
    <span class="token keyword">if</span> i <span class="token operator">%</span> iter_per_epoch <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        train_acc <span class="token operator">=</span> network<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">)</span>
        test_acc <span class="token operator">=</span> network<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">)</span>
        train_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>
        test_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;train acc, test acc | &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;, &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br></div></div><h5 id="基于测试数据来评价"><a href="#基于测试数据来评价" class="header-anchor">#</a> <strong>基于测试数据来评价</strong></h5> <p><strong>这里每一个epoch记录一次准确率（一直记录太浪费时间）</strong>，一个epoch指的是一次所有数据的训练，比如60000个数据，每次mini-batch为100，那么需要这600个mini-batch训练完后才算一个epoch</p> <p>公用函数</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment">#公用函数</span>
<span class="token keyword">def</span> <span class="token function">sigmoid_grad</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">relu_grad</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    grad <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    grad<span class="token punctuation">[</span>x<span class="token operator">&gt;=</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> grad


<span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> x<span class="token punctuation">.</span>ndim <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>T
        x <span class="token operator">=</span> x <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        y <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> y<span class="token punctuation">.</span>T 

    x <span class="token operator">=</span> x <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># 溢出对策</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>    

<span class="token keyword">def</span> <span class="token function">relu</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">numerical_gradient</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    h <span class="token operator">=</span> <span class="token number">1e-4</span> <span class="token comment"># 0.0001</span>
    grad <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    
    it <span class="token operator">=</span> np<span class="token punctuation">.</span>nditer<span class="token punctuation">(</span>x<span class="token punctuation">,</span> flags<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'multi_index'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> op_flags<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'readwrite'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">while</span> <span class="token keyword">not</span> it<span class="token punctuation">.</span>finished<span class="token punctuation">:</span>
        idx <span class="token operator">=</span> it<span class="token punctuation">.</span>multi_index
        tmp_val <span class="token operator">=</span> x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>tmp_val<span class="token punctuation">)</span> <span class="token operator">+</span> h
        fxh1 <span class="token operator">=</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># f(x+h)</span>
        
        x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp_val <span class="token operator">-</span> h 
        fxh2 <span class="token operator">=</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># f(x-h)</span>
        grad<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>fxh1 <span class="token operator">-</span> fxh2<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>h<span class="token punctuation">)</span>
        
        x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp_val <span class="token comment"># 还原值</span>
        it<span class="token punctuation">.</span>iternext<span class="token punctuation">(</span><span class="token punctuation">)</span>   
    <span class="token keyword">return</span> grad
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br></div></div><p>实现mini-batch训练，并记录test，train，acc，绘图</p> <p><strong>可以看到基本重叠，也没有发生过拟合现象</strong></p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># coding: utf-8</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> dataset<span class="token punctuation">.</span>mnist <span class="token keyword">import</span> load_mnist

<span class="token comment"># 读入数据</span>
<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">)</span> <span class="token operator">=</span> load_mnist<span class="token punctuation">(</span>normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> one_hot_label<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

network <span class="token operator">=</span> TwoLayerNet<span class="token punctuation">(</span>input_size<span class="token operator">=</span><span class="token number">784</span><span class="token punctuation">,</span> hidden_size<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> output_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

iters_num <span class="token operator">=</span> <span class="token number">10000</span>  <span class="token comment"># 适当设定循环的次数</span>
train_size <span class="token operator">=</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
batch_size <span class="token operator">=</span> <span class="token number">100</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.1</span>

train_loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
train_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
test_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

iter_per_epoch <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>train_size <span class="token operator">/</span> batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>iters_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    batch_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>train_size<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>
    x_batch <span class="token operator">=</span> x_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>
    t_batch <span class="token operator">=</span> t_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>
    
    <span class="token comment"># 计算梯度</span>
    <span class="token comment">#grad = network.numerical_gradient(x_batch, t_batch)</span>
    grad <span class="token operator">=</span> network<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> t_batch<span class="token punctuation">)</span>
    
    <span class="token comment"># 更新参数</span>
    <span class="token keyword">for</span> key <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">'W1'</span><span class="token punctuation">,</span> <span class="token string">'b1'</span><span class="token punctuation">,</span> <span class="token string">'W2'</span><span class="token punctuation">,</span> <span class="token string">'b2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        network<span class="token punctuation">.</span>params<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> grad<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
    
    loss <span class="token operator">=</span> network<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> t_batch<span class="token punctuation">)</span>
    train_loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
    
    <span class="token keyword">if</span> i <span class="token operator">%</span> iter_per_epoch <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        train_acc <span class="token operator">=</span> network<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">)</span>
        test_acc <span class="token operator">=</span> network<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">)</span>
        train_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>
        test_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;train acc, test acc | &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;, &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 绘制图形</span>
markers <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> <span class="token string">'o'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">:</span> <span class="token string">'s'</span><span class="token punctuation">}</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_acc_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> train_acc_list<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train acc'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> test_acc_list<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'test acc'</span><span class="token punctuation">,</span> linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">&quot;epochs&quot;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">&quot;accuracy&quot;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br></div></div><p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230327201652221.png" alt="image-20230327201652221"></p></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/flokken/edit/master/docs/AI/30.深度学习/03.鱼书-深度学习入门/04.数值微分与梯度.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2023/03/29, 14:06:38</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/6c444b/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">损失函数</div></a> <a href="/pages/81deb7/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">误差反向传播</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/6c444b/" class="prev">损失函数</a></span> <span class="next"><a href="/pages/81deb7/">误差反向传播</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/fd9dbf/"><div>
            线程池
            <!----></div></a> <span class="date">09-16</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/64ddd0/"><div>
            消息队列基础知识
            <!----></div></a> <span class="date">09-08</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/4b5092/"><div>
            树状数组和线段树
            <!----></div></a> <span class="date">08-22</span></dt></dl> <dl><dd></dd> <dt><a href="/archives" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:2878846959@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/Flokken" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/my/m/music/playlist?id=807177837" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2023-2024
    <span>flokken | <a href="https://github.com/xugaoyi/vuepress-theme-vdoing/blob/master/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <div class="body-bg" style="background:url() center center / cover no-repeat;opacity:0.5;"></div> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.6c1ebbcf.js" defer></script><script src="/assets/js/2.28dcc766.js" defer></script><script src="/assets/js/44.4291d737.js" defer></script>
  </body>
</html>
