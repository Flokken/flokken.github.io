<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>pytorch入门 | flokken&#39;s blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="记录学过的东西">
    <meta name="keywords" content="JavaScript,js,ES6,TypeScript,vue,python,css3,html5,Node,git,github,markdown">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.bc84ce4b.css" as="style"><link rel="preload" href="/assets/js/app.6c1ebbcf.js" as="script"><link rel="preload" href="/assets/js/2.28dcc766.js" as="script"><link rel="preload" href="/assets/js/34.270daa56.js" as="script"><link rel="prefetch" href="/assets/js/10.dadef33a.js"><link rel="prefetch" href="/assets/js/100.c21337b1.js"><link rel="prefetch" href="/assets/js/101.eeb225e5.js"><link rel="prefetch" href="/assets/js/102.442361dc.js"><link rel="prefetch" href="/assets/js/103.8495a4a1.js"><link rel="prefetch" href="/assets/js/104.be5e7531.js"><link rel="prefetch" href="/assets/js/105.f968e108.js"><link rel="prefetch" href="/assets/js/106.9c7bcb9d.js"><link rel="prefetch" href="/assets/js/107.5418bfc1.js"><link rel="prefetch" href="/assets/js/108.21c8e4b5.js"><link rel="prefetch" href="/assets/js/109.443388e7.js"><link rel="prefetch" href="/assets/js/11.cb3946f4.js"><link rel="prefetch" href="/assets/js/110.aee2ce54.js"><link rel="prefetch" href="/assets/js/111.c1c4c853.js"><link rel="prefetch" href="/assets/js/112.a77d44c2.js"><link rel="prefetch" href="/assets/js/113.3e1c1563.js"><link rel="prefetch" href="/assets/js/114.b73e18ed.js"><link rel="prefetch" href="/assets/js/115.464712f7.js"><link rel="prefetch" href="/assets/js/116.515a3426.js"><link rel="prefetch" href="/assets/js/117.1de6d86e.js"><link rel="prefetch" href="/assets/js/118.c87898a4.js"><link rel="prefetch" href="/assets/js/119.4d47ac77.js"><link rel="prefetch" href="/assets/js/12.3d11ba1b.js"><link rel="prefetch" href="/assets/js/120.adc822aa.js"><link rel="prefetch" href="/assets/js/121.dea1a90f.js"><link rel="prefetch" href="/assets/js/122.1490ee10.js"><link rel="prefetch" href="/assets/js/123.08cfb23f.js"><link rel="prefetch" href="/assets/js/124.28d0e817.js"><link rel="prefetch" href="/assets/js/125.a7630423.js"><link rel="prefetch" href="/assets/js/126.0d5b60c3.js"><link rel="prefetch" href="/assets/js/127.250521db.js"><link rel="prefetch" href="/assets/js/128.508639a2.js"><link rel="prefetch" href="/assets/js/129.5e6579a1.js"><link rel="prefetch" href="/assets/js/13.74ebc418.js"><link rel="prefetch" href="/assets/js/130.1c66619f.js"><link rel="prefetch" href="/assets/js/131.e83e8060.js"><link rel="prefetch" href="/assets/js/132.7ff3654e.js"><link rel="prefetch" href="/assets/js/133.4125eaa7.js"><link rel="prefetch" href="/assets/js/134.4a100ce2.js"><link rel="prefetch" href="/assets/js/135.789a6a26.js"><link rel="prefetch" href="/assets/js/136.9cc03ec3.js"><link rel="prefetch" href="/assets/js/137.8bd376fe.js"><link rel="prefetch" href="/assets/js/138.532d50a9.js"><link rel="prefetch" href="/assets/js/139.53372ba6.js"><link rel="prefetch" href="/assets/js/14.eaf82e4f.js"><link rel="prefetch" href="/assets/js/140.88405785.js"><link rel="prefetch" href="/assets/js/141.38d215a9.js"><link rel="prefetch" href="/assets/js/142.e0163f88.js"><link rel="prefetch" href="/assets/js/143.b523e1ce.js"><link rel="prefetch" href="/assets/js/144.10873c46.js"><link rel="prefetch" href="/assets/js/145.dfe09936.js"><link rel="prefetch" href="/assets/js/146.b05dc164.js"><link rel="prefetch" href="/assets/js/147.c5b7f960.js"><link rel="prefetch" href="/assets/js/148.80f47df1.js"><link rel="prefetch" href="/assets/js/149.b8d840e3.js"><link rel="prefetch" href="/assets/js/15.e64aec1b.js"><link rel="prefetch" href="/assets/js/150.d4361634.js"><link rel="prefetch" href="/assets/js/151.d8431db2.js"><link rel="prefetch" href="/assets/js/152.47852d30.js"><link rel="prefetch" href="/assets/js/153.47ea2a94.js"><link rel="prefetch" href="/assets/js/154.97384b42.js"><link rel="prefetch" href="/assets/js/155.3026447d.js"><link rel="prefetch" href="/assets/js/156.68e37577.js"><link rel="prefetch" href="/assets/js/157.086f0b3f.js"><link rel="prefetch" href="/assets/js/158.bdcb5b98.js"><link rel="prefetch" href="/assets/js/159.f52cb015.js"><link rel="prefetch" href="/assets/js/16.e312a677.js"><link rel="prefetch" href="/assets/js/160.a2739d99.js"><link rel="prefetch" href="/assets/js/161.7212e5c4.js"><link rel="prefetch" href="/assets/js/162.8006dc05.js"><link rel="prefetch" href="/assets/js/163.bf42549e.js"><link rel="prefetch" href="/assets/js/164.5b2eea28.js"><link rel="prefetch" href="/assets/js/165.d531f59f.js"><link rel="prefetch" href="/assets/js/166.86bf0046.js"><link rel="prefetch" href="/assets/js/167.af7a49eb.js"><link rel="prefetch" href="/assets/js/168.362435ae.js"><link rel="prefetch" href="/assets/js/169.b71a8d5d.js"><link rel="prefetch" href="/assets/js/17.e9813cce.js"><link rel="prefetch" href="/assets/js/170.975564fa.js"><link rel="prefetch" href="/assets/js/171.4949b39a.js"><link rel="prefetch" href="/assets/js/172.8d7529ad.js"><link rel="prefetch" href="/assets/js/173.404d8588.js"><link rel="prefetch" href="/assets/js/174.6641d1c4.js"><link rel="prefetch" href="/assets/js/175.0f46859d.js"><link rel="prefetch" href="/assets/js/176.2fd697ec.js"><link rel="prefetch" href="/assets/js/177.0f744d20.js"><link rel="prefetch" href="/assets/js/178.021de7d2.js"><link rel="prefetch" href="/assets/js/179.593f9493.js"><link rel="prefetch" href="/assets/js/18.0bfadb6c.js"><link rel="prefetch" href="/assets/js/180.8305cce0.js"><link rel="prefetch" href="/assets/js/181.5e83f1b6.js"><link rel="prefetch" href="/assets/js/182.87985f96.js"><link rel="prefetch" href="/assets/js/183.80ba1b3c.js"><link rel="prefetch" href="/assets/js/184.f11d0532.js"><link rel="prefetch" href="/assets/js/185.c859c104.js"><link rel="prefetch" href="/assets/js/186.dc782260.js"><link rel="prefetch" href="/assets/js/187.bc43a42b.js"><link rel="prefetch" href="/assets/js/188.abf4a947.js"><link rel="prefetch" href="/assets/js/189.3911f624.js"><link rel="prefetch" href="/assets/js/19.ebbfaca6.js"><link rel="prefetch" href="/assets/js/190.6ba0f02e.js"><link rel="prefetch" href="/assets/js/191.612eaebf.js"><link rel="prefetch" href="/assets/js/192.7545f46e.js"><link rel="prefetch" href="/assets/js/193.8c879c3b.js"><link rel="prefetch" href="/assets/js/194.2ac85355.js"><link rel="prefetch" href="/assets/js/195.887d8d44.js"><link rel="prefetch" href="/assets/js/196.82fc2486.js"><link rel="prefetch" href="/assets/js/197.f3d5a63f.js"><link rel="prefetch" href="/assets/js/198.acb21d94.js"><link rel="prefetch" href="/assets/js/199.72a831c8.js"><link rel="prefetch" href="/assets/js/20.7946efec.js"><link rel="prefetch" href="/assets/js/200.d22fdf55.js"><link rel="prefetch" href="/assets/js/201.d9df6873.js"><link rel="prefetch" href="/assets/js/202.001109bc.js"><link rel="prefetch" href="/assets/js/203.ba860144.js"><link rel="prefetch" href="/assets/js/204.0bb6f98e.js"><link rel="prefetch" href="/assets/js/205.d9c979cd.js"><link rel="prefetch" href="/assets/js/206.1d24147d.js"><link rel="prefetch" href="/assets/js/207.f3d10dab.js"><link rel="prefetch" href="/assets/js/208.c3ba92f2.js"><link rel="prefetch" href="/assets/js/209.fe7a19e2.js"><link rel="prefetch" href="/assets/js/21.0b137891.js"><link rel="prefetch" href="/assets/js/210.5d424205.js"><link rel="prefetch" href="/assets/js/211.d84d326b.js"><link rel="prefetch" href="/assets/js/212.1d38af17.js"><link rel="prefetch" href="/assets/js/213.061f3dbf.js"><link rel="prefetch" href="/assets/js/214.ecb8325b.js"><link rel="prefetch" href="/assets/js/215.615caf62.js"><link rel="prefetch" href="/assets/js/216.e23dc266.js"><link rel="prefetch" href="/assets/js/217.9933d9c4.js"><link rel="prefetch" href="/assets/js/218.5cdf2ac4.js"><link rel="prefetch" href="/assets/js/219.72e58688.js"><link rel="prefetch" href="/assets/js/22.3762b636.js"><link rel="prefetch" href="/assets/js/220.fbc6f972.js"><link rel="prefetch" href="/assets/js/221.1c8eeced.js"><link rel="prefetch" href="/assets/js/222.163dee0a.js"><link rel="prefetch" href="/assets/js/223.72e37b20.js"><link rel="prefetch" href="/assets/js/224.e09609e5.js"><link rel="prefetch" href="/assets/js/225.34fd5c90.js"><link rel="prefetch" href="/assets/js/226.9991814a.js"><link rel="prefetch" href="/assets/js/227.1e2b8a98.js"><link rel="prefetch" href="/assets/js/228.1d4d1fcf.js"><link rel="prefetch" href="/assets/js/229.cc91769e.js"><link rel="prefetch" href="/assets/js/23.f7ebea5b.js"><link rel="prefetch" href="/assets/js/230.3d3edd0f.js"><link rel="prefetch" href="/assets/js/231.0475038b.js"><link rel="prefetch" href="/assets/js/232.a9e3d0d3.js"><link rel="prefetch" href="/assets/js/233.2ca519d3.js"><link rel="prefetch" href="/assets/js/234.c51411ea.js"><link rel="prefetch" href="/assets/js/235.35616a91.js"><link rel="prefetch" href="/assets/js/236.db361c9c.js"><link rel="prefetch" href="/assets/js/237.c8e14a33.js"><link rel="prefetch" href="/assets/js/238.0f2fcf3a.js"><link rel="prefetch" href="/assets/js/239.a33a3324.js"><link rel="prefetch" href="/assets/js/24.42946d79.js"><link rel="prefetch" href="/assets/js/240.7bf17817.js"><link rel="prefetch" href="/assets/js/241.613e82c4.js"><link rel="prefetch" href="/assets/js/242.5709b7c9.js"><link rel="prefetch" href="/assets/js/243.4f2501de.js"><link rel="prefetch" href="/assets/js/244.63720e3b.js"><link rel="prefetch" href="/assets/js/245.e756153f.js"><link rel="prefetch" href="/assets/js/246.b709da2f.js"><link rel="prefetch" href="/assets/js/247.e6f5dc6f.js"><link rel="prefetch" href="/assets/js/248.79fff09e.js"><link rel="prefetch" href="/assets/js/249.2c7ad7a2.js"><link rel="prefetch" href="/assets/js/25.a86a3678.js"><link rel="prefetch" href="/assets/js/250.29112339.js"><link rel="prefetch" href="/assets/js/251.634c259b.js"><link rel="prefetch" href="/assets/js/252.f020ace1.js"><link rel="prefetch" href="/assets/js/253.21843ce0.js"><link rel="prefetch" href="/assets/js/254.819b0d0b.js"><link rel="prefetch" href="/assets/js/255.a1a36af5.js"><link rel="prefetch" href="/assets/js/256.b331fde3.js"><link rel="prefetch" href="/assets/js/257.d496873b.js"><link rel="prefetch" href="/assets/js/258.d25fd3f2.js"><link rel="prefetch" href="/assets/js/259.e26ffb21.js"><link rel="prefetch" href="/assets/js/26.5fe90cb9.js"><link rel="prefetch" href="/assets/js/260.173d7a1c.js"><link rel="prefetch" href="/assets/js/261.fd2846ac.js"><link rel="prefetch" href="/assets/js/262.110b431f.js"><link rel="prefetch" href="/assets/js/263.deab1489.js"><link rel="prefetch" href="/assets/js/264.b38ed189.js"><link rel="prefetch" href="/assets/js/265.e50c8ee7.js"><link rel="prefetch" href="/assets/js/266.132d2f80.js"><link rel="prefetch" href="/assets/js/267.df5c367d.js"><link rel="prefetch" href="/assets/js/268.94eee0dd.js"><link rel="prefetch" href="/assets/js/269.27287f29.js"><link rel="prefetch" href="/assets/js/27.0ac244ef.js"><link rel="prefetch" href="/assets/js/270.82414c58.js"><link rel="prefetch" href="/assets/js/271.88d41d2f.js"><link rel="prefetch" href="/assets/js/272.fdea98e3.js"><link rel="prefetch" href="/assets/js/273.291d7bce.js"><link rel="prefetch" href="/assets/js/274.6470bef1.js"><link rel="prefetch" href="/assets/js/275.ae5aaecb.js"><link rel="prefetch" href="/assets/js/276.6249c409.js"><link rel="prefetch" href="/assets/js/277.c281acfe.js"><link rel="prefetch" href="/assets/js/278.4bf4de94.js"><link rel="prefetch" href="/assets/js/279.62240a5f.js"><link rel="prefetch" href="/assets/js/28.7b66a9da.js"><link rel="prefetch" href="/assets/js/280.a05c4459.js"><link rel="prefetch" href="/assets/js/281.f5dbccd2.js"><link rel="prefetch" href="/assets/js/282.3c8929fa.js"><link rel="prefetch" href="/assets/js/283.8632920a.js"><link rel="prefetch" href="/assets/js/284.74b2e3cc.js"><link rel="prefetch" href="/assets/js/285.1c3bb787.js"><link rel="prefetch" href="/assets/js/286.145be126.js"><link rel="prefetch" href="/assets/js/287.0a623eba.js"><link rel="prefetch" href="/assets/js/288.e07989da.js"><link rel="prefetch" href="/assets/js/289.2f5fdfd9.js"><link rel="prefetch" href="/assets/js/29.ebd9ba6b.js"><link rel="prefetch" href="/assets/js/290.0b12e49c.js"><link rel="prefetch" href="/assets/js/291.fc65a93a.js"><link rel="prefetch" href="/assets/js/292.2beb238d.js"><link rel="prefetch" href="/assets/js/293.87c822f4.js"><link rel="prefetch" href="/assets/js/294.450b6510.js"><link rel="prefetch" href="/assets/js/295.9191ddf7.js"><link rel="prefetch" href="/assets/js/296.92ec965c.js"><link rel="prefetch" href="/assets/js/297.68c01079.js"><link rel="prefetch" href="/assets/js/298.768b54ab.js"><link rel="prefetch" href="/assets/js/299.c2b57741.js"><link rel="prefetch" href="/assets/js/3.cd795b12.js"><link rel="prefetch" href="/assets/js/30.05a622e0.js"><link rel="prefetch" href="/assets/js/300.f409e502.js"><link rel="prefetch" href="/assets/js/301.56e89c78.js"><link rel="prefetch" href="/assets/js/302.942b0d94.js"><link rel="prefetch" href="/assets/js/303.d3946671.js"><link rel="prefetch" href="/assets/js/304.a346c8aa.js"><link rel="prefetch" href="/assets/js/305.46fa308b.js"><link rel="prefetch" href="/assets/js/306.c7f27ad8.js"><link rel="prefetch" href="/assets/js/307.0c8cf8c0.js"><link rel="prefetch" href="/assets/js/308.1d2db23d.js"><link rel="prefetch" href="/assets/js/309.2055654b.js"><link rel="prefetch" href="/assets/js/31.cc1bdb96.js"><link rel="prefetch" href="/assets/js/310.b6b7887a.js"><link rel="prefetch" href="/assets/js/311.e605ceab.js"><link rel="prefetch" href="/assets/js/312.52192bb7.js"><link rel="prefetch" href="/assets/js/313.2698bd8e.js"><link rel="prefetch" href="/assets/js/314.5d9073d0.js"><link rel="prefetch" href="/assets/js/315.c409cde3.js"><link rel="prefetch" href="/assets/js/316.2bf0e6df.js"><link rel="prefetch" href="/assets/js/317.5798e7df.js"><link rel="prefetch" href="/assets/js/318.95986f30.js"><link rel="prefetch" href="/assets/js/319.e6def8d6.js"><link rel="prefetch" href="/assets/js/32.ef0d5dba.js"><link rel="prefetch" href="/assets/js/320.8b3e8e94.js"><link rel="prefetch" href="/assets/js/321.f936d520.js"><link rel="prefetch" href="/assets/js/322.cdb3332c.js"><link rel="prefetch" href="/assets/js/323.4e193830.js"><link rel="prefetch" href="/assets/js/324.5da1850e.js"><link rel="prefetch" href="/assets/js/325.ff5ccde4.js"><link rel="prefetch" href="/assets/js/326.160651b1.js"><link rel="prefetch" href="/assets/js/327.db3feae7.js"><link rel="prefetch" href="/assets/js/328.4ebf4ae0.js"><link rel="prefetch" href="/assets/js/329.f71c3883.js"><link rel="prefetch" href="/assets/js/33.3c571bbe.js"><link rel="prefetch" href="/assets/js/330.885ae61c.js"><link rel="prefetch" href="/assets/js/331.b1a938ba.js"><link rel="prefetch" href="/assets/js/332.b142c42b.js"><link rel="prefetch" href="/assets/js/333.b8076f78.js"><link rel="prefetch" href="/assets/js/334.ad22ab75.js"><link rel="prefetch" href="/assets/js/335.88564fd2.js"><link rel="prefetch" href="/assets/js/336.39134b8d.js"><link rel="prefetch" href="/assets/js/337.df1ebc2c.js"><link rel="prefetch" href="/assets/js/35.15d989c9.js"><link rel="prefetch" href="/assets/js/36.2e8aeb80.js"><link rel="prefetch" href="/assets/js/37.7b762275.js"><link rel="prefetch" href="/assets/js/38.22ec6ac7.js"><link rel="prefetch" href="/assets/js/39.bdb3430a.js"><link rel="prefetch" href="/assets/js/4.f7fa33d6.js"><link rel="prefetch" href="/assets/js/40.345f3c53.js"><link rel="prefetch" href="/assets/js/41.e93aab58.js"><link rel="prefetch" href="/assets/js/42.e7446174.js"><link rel="prefetch" href="/assets/js/43.3bbfdb12.js"><link rel="prefetch" href="/assets/js/44.4291d737.js"><link rel="prefetch" href="/assets/js/45.82f2cc4f.js"><link rel="prefetch" href="/assets/js/46.342f85bd.js"><link rel="prefetch" href="/assets/js/47.f2f6fe03.js"><link rel="prefetch" href="/assets/js/48.99fd0146.js"><link rel="prefetch" href="/assets/js/49.2634fd40.js"><link rel="prefetch" href="/assets/js/5.ae42b7a0.js"><link rel="prefetch" href="/assets/js/50.691080e8.js"><link rel="prefetch" href="/assets/js/51.292e4b2b.js"><link rel="prefetch" href="/assets/js/52.30b4a61b.js"><link rel="prefetch" href="/assets/js/53.2c6237df.js"><link rel="prefetch" href="/assets/js/54.49456bfa.js"><link rel="prefetch" href="/assets/js/55.4710856c.js"><link rel="prefetch" href="/assets/js/56.0334fc17.js"><link rel="prefetch" href="/assets/js/57.4f70d0ed.js"><link rel="prefetch" href="/assets/js/58.d9a970bf.js"><link rel="prefetch" href="/assets/js/59.7a4b31fd.js"><link rel="prefetch" href="/assets/js/6.d5889eef.js"><link rel="prefetch" href="/assets/js/60.417e05df.js"><link rel="prefetch" href="/assets/js/61.c7980332.js"><link rel="prefetch" href="/assets/js/62.58f3c155.js"><link rel="prefetch" href="/assets/js/63.7229815d.js"><link rel="prefetch" href="/assets/js/64.0d72da6d.js"><link rel="prefetch" href="/assets/js/65.2c623405.js"><link rel="prefetch" href="/assets/js/66.d170f5ad.js"><link rel="prefetch" href="/assets/js/67.01023aac.js"><link rel="prefetch" href="/assets/js/68.018604c5.js"><link rel="prefetch" href="/assets/js/69.abbe4df3.js"><link rel="prefetch" href="/assets/js/7.bf0f2b67.js"><link rel="prefetch" href="/assets/js/70.962b3ba0.js"><link rel="prefetch" href="/assets/js/71.a5606282.js"><link rel="prefetch" href="/assets/js/72.975041a5.js"><link rel="prefetch" href="/assets/js/73.d93206af.js"><link rel="prefetch" href="/assets/js/74.67fe0aca.js"><link rel="prefetch" href="/assets/js/75.a321d6fc.js"><link rel="prefetch" href="/assets/js/76.2a44bacd.js"><link rel="prefetch" href="/assets/js/77.90387be7.js"><link rel="prefetch" href="/assets/js/78.c6455938.js"><link rel="prefetch" href="/assets/js/79.8c3687c2.js"><link rel="prefetch" href="/assets/js/8.0b70db32.js"><link rel="prefetch" href="/assets/js/80.ed6a6259.js"><link rel="prefetch" href="/assets/js/81.9cc4a70c.js"><link rel="prefetch" href="/assets/js/82.4dfd22c3.js"><link rel="prefetch" href="/assets/js/83.bbe5ca26.js"><link rel="prefetch" href="/assets/js/84.0141f56f.js"><link rel="prefetch" href="/assets/js/85.26069038.js"><link rel="prefetch" href="/assets/js/86.c22416bd.js"><link rel="prefetch" href="/assets/js/87.ad2b839e.js"><link rel="prefetch" href="/assets/js/88.de3f91d8.js"><link rel="prefetch" href="/assets/js/89.abb8ff44.js"><link rel="prefetch" href="/assets/js/9.5282ef41.js"><link rel="prefetch" href="/assets/js/90.8dab802c.js"><link rel="prefetch" href="/assets/js/91.67430952.js"><link rel="prefetch" href="/assets/js/92.c95aaeec.js"><link rel="prefetch" href="/assets/js/93.d68e1554.js"><link rel="prefetch" href="/assets/js/94.f9fd1744.js"><link rel="prefetch" href="/assets/js/95.a4fd9b78.js"><link rel="prefetch" href="/assets/js/96.32d95188.js"><link rel="prefetch" href="/assets/js/97.3bf42546.js"><link rel="prefetch" href="/assets/js/98.a032b733.js"><link rel="prefetch" href="/assets/js/99.fc7abb0d.js">
    <link rel="stylesheet" href="/assets/css/0.styles.bc84ce4b.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu have-body-img"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/logo.png" alt="flokken's blog" class="logo"> <span class="site-name can-hide">flokken's blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><!----> <span class="title" style="display:;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>web开发</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/javascript/" class="nav-link">JavaScript</a></li><li class="dropdown-subitem"><a href="/vue/" class="nav-link">Vue</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="后端开发" class="dropdown-title"><!----> <span class="title" style="display:;">后端开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/java/" class="nav-link">Java开发</a></li><li class="dropdown-item"><!----> <a href="/go/" class="nav-link">Go开发</a></li><li class="dropdown-item"><!----> <a href="/microservice/" class="nav-link">微服务开发</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="AI" class="dropdown-title"><!----> <span class="title" style="display:;">AI</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/KG/" class="nav-link">知识图谱</a></li><li class="dropdown-item"><!----> <a href="/DL/" class="nav-link">深度学习</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="安全与运维" class="dropdown-title"><!----> <span class="title" style="display:;">安全与运维</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/reverse/" class="nav-link">逆向</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="大数据" class="dropdown-title"><!----> <span class="title" style="display:;">大数据</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/spark/" class="nav-link">Spark</a></li><li class="dropdown-item"><!----> <a href="/spider/" class="nav-link">Spider</a></li><li class="dropdown-item"><!----> <a href="/mysql/" class="nav-link">MySQL</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法与数据结构" class="dropdown-title"><!----> <span class="title" style="display:;">算法与数据结构</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/algorithm/" class="nav-link">算法</a></li><li class="dropdown-item"><!----> <a href="/datastructure/" class="nav-link">数据结构</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="其他" class="dropdown-title"><!----> <span class="title" style="display:;">其他</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/tips/" class="nav-link">小知识</a></li></ul></div></div> <a href="https://github.com/flokken" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/avtar.png"> <div class="blogger-info"><h3>flokken</h3> <span>一个大水货</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><!----> <span class="title" style="display:;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>web开发</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/javascript/" class="nav-link">JavaScript</a></li><li class="dropdown-subitem"><a href="/vue/" class="nav-link">Vue</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="后端开发" class="dropdown-title"><!----> <span class="title" style="display:;">后端开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/java/" class="nav-link">Java开发</a></li><li class="dropdown-item"><!----> <a href="/go/" class="nav-link">Go开发</a></li><li class="dropdown-item"><!----> <a href="/microservice/" class="nav-link">微服务开发</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="AI" class="dropdown-title"><!----> <span class="title" style="display:;">AI</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/KG/" class="nav-link">知识图谱</a></li><li class="dropdown-item"><!----> <a href="/DL/" class="nav-link">深度学习</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="安全与运维" class="dropdown-title"><!----> <span class="title" style="display:;">安全与运维</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/reverse/" class="nav-link">逆向</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="大数据" class="dropdown-title"><!----> <span class="title" style="display:;">大数据</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/spark/" class="nav-link">Spark</a></li><li class="dropdown-item"><!----> <a href="/spider/" class="nav-link">Spider</a></li><li class="dropdown-item"><!----> <a href="/mysql/" class="nav-link">MySQL</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法与数据结构" class="dropdown-title"><!----> <span class="title" style="display:;">算法与数据结构</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/algorithm/" class="nav-link">算法</a></li><li class="dropdown-item"><!----> <a href="/datastructure/" class="nav-link">数据结构</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="其他" class="dropdown-title"><!----> <span class="title" style="display:;">其他</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/tips/" class="nav-link">小知识</a></li></ul></div></div> <a href="https://github.com/flokken" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>知识图谱</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>深度学习</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>Pytorch</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/f85c0c/" aria-current="page" class="active sidebar-link">pytorch入门</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#制作自己的数据集" class="sidebar-link">制作自己的数据集</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#迭代数据集" class="sidebar-link">迭代数据集</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#totensor" class="sidebar-link">ToTensor</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#shape" class="sidebar-link">shape</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#attributes-of-a-tensor" class="sidebar-link">Attributes of a Tensor</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#operations-on-tensors" class="sidebar-link">Operations on Tensors</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level4"><a href="/pages/f85c0c/#transopse" class="sidebar-link">Transopse</a></li><li class="sidebar-sub-header level4"><a href="/pages/f85c0c/#squeeze" class="sidebar-link">Squeeze</a></li><li class="sidebar-sub-header level4"><a href="/pages/f85c0c/#unsqueeze" class="sidebar-link">Unsqueeze</a></li><li class="sidebar-sub-header level4"><a href="/pages/f85c0c/#cat" class="sidebar-link">Cat</a></li><li class="sidebar-sub-header level4"><a href="/pages/f85c0c/#tensors-pytorch-v-s-numpy" class="sidebar-link">Tensors – PyTorch v.s. NumPy</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#微分示例" class="sidebar-link">微分示例</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#基本原理" class="sidebar-link">基本原理</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#前向传播" class="sidebar-link">前向传播</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#反向传播" class="sidebar-link">反向传播</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#实例演示" class="sidebar-link">实例演示</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#理论分析" class="sidebar-link">理论分析</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_1-准备数据" class="sidebar-link">1）准备数据</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_2-目标函数" class="sidebar-link">2）目标函数</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_3-优化" class="sidebar-link">3）优化</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_4-批量输入" class="sidebar-link">4）批量输入</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_5-训练" class="sidebar-link">5）训练</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#代码实现" class="sidebar-link">代码实现</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_1-准备数据-2" class="sidebar-link">1）准备数据</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_2-训练" class="sidebar-link">2）训练</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#大规模数据集实例" class="sidebar-link">大规模数据集实例</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_1-准备数据-3" class="sidebar-link">1）准备数据</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_2-定义模型" class="sidebar-link">2）定义模型</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_3-实例化模型" class="sidebar-link">3）实例化模型</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_4-损失函数" class="sidebar-link">4）损失函数</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_5-优化器" class="sidebar-link">5）优化器</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_6-训练" class="sidebar-link">6）训练</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#激活函数" class="sidebar-link">激活函数</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#人工神经网络" class="sidebar-link">人工神经网络</a></li><li class="sidebar-sub-header level4"><a href="/pages/f85c0c/#_1-准备数据-4" class="sidebar-link">1）准备数据</a></li><li class="sidebar-sub-header level4"><a href="/pages/f85c0c/#_2-建立模型" class="sidebar-link">2）建立模型</a></li><li class="sidebar-sub-header level4"><a href="/pages/f85c0c/#_3-训练" class="sidebar-link">3）训练</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#sigmoid-函数" class="sidebar-link">sigmoid 函数</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#交叉熵损失函数" class="sidebar-link">交叉熵损失函数</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#逻辑回归示例" class="sidebar-link">逻辑回归示例</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_1-准备数据-5" class="sidebar-link">1）准备数据</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_2-建立模型-2" class="sidebar-link">2）建立模型</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_3-训练-2" class="sidebar-link">3）训练</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#softmax-函数" class="sidebar-link">softmax 函数</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#多元分类示例" class="sidebar-link">多元分类示例</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_1-准备数据-6" class="sidebar-link">1）准备数据</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_2-建立模型-3" class="sidebar-link">2）建立模型</a></li><li class="sidebar-sub-header level3"><a href="/pages/f85c0c/#_3-训练-3" class="sidebar-link">3）训练</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#引入卷积" class="sidebar-link">引入卷积</a></li><li class="sidebar-sub-header level2"><a href="/pages/f85c0c/#池化" class="sidebar-link">池化</a></li></ul></li><li><a href="/pages/720944/" class="sidebar-link">pytorch常用函数</a></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>深度学习-李宏毅2022</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>鱼书-深度学习入门</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>鱼书-自然语言处理</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>论文阅读</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/categories/?category=AI" title="分类" data-v-06225672>AI</a></li><li data-v-06225672><a href="/categories/?category=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" title="分类" data-v-06225672>深度学习</a></li><li data-v-06225672><a href="/categories/?category=Pytorch" title="分类" data-v-06225672>Pytorch</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/Flokken" target="_blank" title="作者" class="beLink" data-v-06225672>flokken</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-03-13</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABH1JREFUSA3tVl1oHFUUPmdmd2ltklqbpJDiNnXFmgbFktho7YMPNiJSSZM0+CAYSkUELVhM6YuwIPpgoOKDqOBDC0XE2CQoNtQXBUFTTcCi+Wlh1V2TQExsUzcltd3M9Tt3ZjZzZ2fT+OJTL8yeM+eee757fmeJbq//KQL8X3DUSFOcfr7cRsRtxNQMWueeVzOkaITIGqQHNg5y8+jNW9ldM7A6nTpAjuolUikAwq7CE3WcM2RRDz+XGVgN3FptU/aUSlvq9Pa3iZ1+sgAqJyyAFqkipd9dqiwHF3P65YycLWc/6sqGrvoEoIp6DOFaX5h6+dnfjkWprwqsPk0dUGq5vySwDImC10KxFHgGL1SWoc92O3eVht09qdXNH11I2SsTsJYqMWzihqGMi+A+Garf3BAuuLI5oGlULyNfyB/HYNujwktOfRrMr5t77NmevqaUopx0grnKAyvVpmwUDB4x6FPXuGvYLTDwWsejwgtgkYKPqRJg8SV6xaiZ3ZTppGneS4yfH5/66fZSDHv+QZci/+h5c5UHtpy67JUqGppM0sh0Nc1dW6/N1W5Yoqat8/TU/VnadmdeW2PLLSyh0cvxBs3KbqTmwYPpxN4do/mzE8nEpvX/UMu2Wbp74zUAK5q6WkHns7V0eWkdPbPzd3rxkTGybadYySumVzhcaJFbs5UrEkQ/+CK8gF5dnh/6ciIZ73gwQ927L1IitoxKLXYP3SjYdOrHHfTZhRRlFyrorafPk20B3HPD1y2G3qKZME5Jcf3t/HUC13/8tSd++vqFveMUTwAUxSUFI1QekR1+bIze3D9MF2aq6cPvG72CgnldWCFqyRw3lwH8ZMerjTD9ElRO7Gv44wNpC90aASqGfVlz/Rx17srQ57/UU26hkhQqUB7dBR71WmzQhHUnblGmVOEw0jhbV1n9OlXUDCIRGaNV5Jp43N516fN7JmnTHdfp7Hgy0luO4aMhtkLL8Bi3bUWYvzh5Mn1dTxrL6QmGuRhGL/TiTTxRoEdTszSaq9GR0NGA3KdkOz3hqSV3MIDhQ5IVX/Ivx3umBti2es2h4eZby7x8br1rkf7Mo90AqC8aQ3sJeNzqFRu+vSANAQe3PL7l0HGOAdwDCeZYvNKeoZp1Qfs6Aipndh86HmFRi0LAnEO47wsqM6cdfjh3jBPUzhZy7nvlUfFsamED1VQt6aISHVymXZ/B2aCtIG8AI8xfobj2d3en1wWVhOeHELKmLQ1s211s88comkv4UCwWyF787mJdYXtNfhKAXVqnKTq8QZvGAGGOfaTo5pGZ/PwbUCr5+DPr/1J92JNHr9aOl/F3iI5+O1nfybsGxoimvZ3ViWSluDITw3P37mypheDIPY0tw7+O/5ApbkYw+zpfaUVu32Pi98+defdUhEpZkRFq0aqyNh9FuL9hpYbEm6iwi0z2REd09ZmyENEbuhjDWzKvZXTqKYaBIr3tt5kuPtQBZFvEUwHt60vfCNu41XsksH9Ij1BMMz1Y0OOunHNShFIP5868g5zeXmuLwL9T4b6Q2+KejgAAAABJRU5ErkJggg==">pytorch入门<!----></h1>  <div class="theme-vdoing-content content__default"><blockquote><p>参考：https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html</p></blockquote> <h1 id="数据模块"><a href="#数据模块" class="header-anchor">#</a> 数据模块</h1> <div class="language-python line-numbers-mode"><pre class="language-python"><code> <span class="token comment">#torch.utils.data.DataLoader 从DataSet中加载数据</span>
 <span class="token comment">#torch.utils.data.Dataset 存储数据集，包括样本和他们的标签</span>
<span class="token comment"># 有预制数据集，分为三类TorchText, TorchVision, and TorchAudio</span>

<span class="token comment">##一个常用的导入</span>
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> ToTensor

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>加载预制的MINIST数据集</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>training_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
    root<span class="token operator">=</span><span class="token string">&quot;data&quot;</span><span class="token punctuation">,</span>
    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment"># Download test data from open datasets.</span>
test_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
    root<span class="token operator">=</span><span class="token string">&quot;data&quot;</span><span class="token punctuation">,</span>
    train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><h2 id="制作自己的数据集"><a href="#制作自己的数据集" class="header-anchor">#</a> 制作自己的数据集</h2> <p>自定义数据集类必须实现三个函数。<strong>init</strong>, <strong>len</strong>, 和 <strong>getitem</strong>。</p> <p>示例：</p> <p>FashionMNIST的图像被存储在一个目录img_dir中，它们的标签被分别存储在一个CSV文件annotations_file中</p> <p>annotations_file类似于：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tshirt1<span class="token punctuation">.</span>jpg<span class="token punctuation">,</span> <span class="token number">0</span>
tshirt2<span class="token punctuation">.</span>jpg<span class="token punctuation">,</span> <span class="token number">0</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
ankleboot999<span class="token punctuation">.</span>jpg<span class="token punctuation">,</span> <span class="token number">9</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> os
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>io <span class="token keyword">import</span> read_image

<span class="token keyword">class</span> <span class="token class-name">CustomImageDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> annotations_file<span class="token punctuation">,</span> img_dir<span class="token punctuation">,</span> transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> target_transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>img_labels <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>annotations_file<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>img_dir <span class="token operator">=</span> img_dir
        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform
        self<span class="token punctuation">.</span>target_transform <span class="token operator">=</span> target_transform

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_labels<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
函数 __getitem__ 在给定的索引idx处加载并返回数据集中的一个样本。基于索引，它确定图像在磁盘上的位置，使用read_image将其转换为张量，从self.img_labels中的csv数据中获取相应的标签，对其调用转换函数（如果适用），并在一个元组中返回张量图像和相应标签
&quot;&quot;&quot;</span>
    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        img_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_dir<span class="token punctuation">,</span> self<span class="token punctuation">.</span>img_labels<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        image <span class="token operator">=</span> read_image<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>
        label <span class="token operator">=</span> self<span class="token punctuation">.</span>img_labels<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">:</span>
            image <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>target_transform<span class="token punctuation">:</span>
            label <span class="token operator">=</span> self<span class="token punctuation">.</span>target_transform<span class="token punctuation">(</span>label<span class="token punctuation">)</span>
        <span class="token keyword">return</span> image<span class="token punctuation">,</span> label

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br></div></div><h2 id="迭代数据集"><a href="#迭代数据集" class="header-anchor">#</a> 迭代数据集</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code>train_features<span class="token punctuation">,</span> train_labels <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Feature batch shape: </span><span class="token interpolation"><span class="token punctuation">{</span>train_features<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Labels batch shape: </span><span class="token interpolation"><span class="token punctuation">{</span>train_labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
img <span class="token operator">=</span> train_features<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
label <span class="token operator">=</span> train_labels<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">&quot;gray&quot;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Label: </span><span class="token interpolation"><span class="token punctuation">{</span>label<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

<span class="token comment">#Output</span>
Feature batch shape<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Labels batch shape<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Label<span class="token punctuation">:</span> <span class="token number">5</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><h1 id="transforms"><a href="#transforms" class="header-anchor">#</a> TRANSFORMS</h1> <p><strong>对数据进行转换</strong>，FashionMNIST 为例</p> <p>FashionMNIST 特征是 PIL 图像格式，标签是整数。对于训练，我们需要将特征作为归一化张量，并将标签作为单热编码张量。为了进行这些转换，我们使用了 ToTensor 和 Lambda。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> ToTensor<span class="token punctuation">,</span> Lambda

ds <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
    root<span class="token operator">=</span><span class="token string">&quot;data&quot;</span><span class="token punctuation">,</span>
    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    target_transform<span class="token operator">=</span>Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> y<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h2 id="totensor"><a href="#totensor" class="header-anchor">#</a> ToTensor</h2> <p>将 PIL 图像或 NumPy ndarray 转换为 FloatTensor。并在 [0., 1.] 范围内缩放图像的像素强度值</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>target_transform <span class="token operator">=</span> Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> y<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>
    <span class="token number">10</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h1 id="tensors"><a href="#tensors" class="header-anchor">#</a> Tensors</h1> <p>张量是一种特殊的数据结构，与数组和矩阵非常相似。在 PyTorch 中，使用张量对模型的输入和输出以及模型的参数进行编码</p> <p>Tensor也类似于numpy中的ndarray,从底层内存来说，两者很像，但是区别是tensor可以用于GPU硬件加速。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import torch
import numpy as np
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h2 id="shape"><a href="#shape" class="header-anchor">#</a> shape</h2> <p><strong>dim</strong> in PyTorch == <strong>axis</strong> in NumPy</p> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/20230313204109.png" alt="image-20220123174701303" style="zoom:100%;"> <p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230313204328534.png" alt="image-20230313204328534"></p> <p>创建一个tensor</p> <p>从数组：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>从numpy array</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>np_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
x_np <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np_array<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>随机生成</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">)</span>
rand_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>
ones_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>
zeros_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Random Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>rand_tensor<span class="token punctuation">}</span></span><span class="token string"> \n&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Ones Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>ones_tensor<span class="token punctuation">}</span></span><span class="token string"> \n&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Zeros Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>zeros_tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

<span class="token comment">#output</span>
Random Tensor<span class="token punctuation">:</span>
 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5420</span><span class="token punctuation">,</span> <span class="token number">0.6001</span><span class="token punctuation">,</span> <span class="token number">0.1662</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">0.9223</span><span class="token punctuation">,</span> <span class="token number">0.7110</span><span class="token punctuation">,</span> <span class="token number">0.2290</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

Ones Tensor<span class="token punctuation">:</span>
 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

Zeros Tensor<span class="token punctuation">:</span>
 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><h2 id="attributes-of-a-tensor"><a href="#attributes-of-a-tensor" class="header-anchor">#</a> Attributes of a Tensor</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Shape of tensor: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Datatype of tensor: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>dtype<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Device tensor is stored on: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>device<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token comment">#Out</span>
Shape of tensor<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Datatype of tensor<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>float32
Device tensor <span class="token keyword">is</span> stored on<span class="token punctuation">:</span> cpu
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>pytorch，numpy size，shape对比</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
a<span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
b<span class="token operator">=</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
b<span class="token operator">=</span>b<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;torch size():&quot;</span><span class="token punctuation">,</span>a<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;torch.shape:&quot;</span><span class="token punctuation">,</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;numpy size:&quot;</span><span class="token punctuation">,</span>b<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;numpy shape:&quot;</span><span class="token punctuation">,</span>b<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment">#Output</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.6614</span><span class="token punctuation">,</span>  <span class="token number">0.2669</span><span class="token punctuation">,</span>  <span class="token number">0.0617</span><span class="token punctuation">,</span>  <span class="token number">0.6213</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.4519</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1661</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.5228</span><span class="token punctuation">,</span>  <span class="token number">0.3817</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0276</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5631</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8923</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0583</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">2</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">3</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
torch size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token number">4</span>
torch<span class="token punctuation">.</span>shape<span class="token punctuation">:</span> <span class="token number">4</span>
numpy size<span class="token punctuation">:</span> <span class="token number">4</span>
numpy shape<span class="token punctuation">:</span> <span class="token number">2</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><h2 id="operations-on-tensors"><a href="#operations-on-tensors" class="header-anchor">#</a> Operations on Tensors</h2> <p>GPU加速，注意一个Tensor默认创建在CPU上</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p><strong>切片：</strong></p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;tensor: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;First row: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;First column: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token format-spec">, 0]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Last column: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
tensor<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>

<span class="token comment">#Output</span>
tensor<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
First row<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
First column<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Last column<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><p><strong>numpy和tensor的底层关系</strong>：</p> <p><strong>CPU</strong>上的张量和NumPy数组可以共享它们的底层内存位置，改变一个将改变另一个。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;t: </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
n <span class="token operator">=</span> t<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;n: </span><span class="token interpolation"><span class="token punctuation">{</span>n<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token comment">#Output</span>
t<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
n<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1.</span> <span class="token number">1.</span> <span class="token number">1.</span> <span class="token number">1.</span> <span class="token number">1.</span><span class="token punctuation">]</span>

t<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;t: </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;n: </span><span class="token interpolation"><span class="token punctuation">{</span>n<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
<span class="token comment">#Output</span>
t<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
n<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">2.</span> <span class="token number">2.</span> <span class="token number">2.</span> <span class="token number">2.</span> <span class="token number">2.</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><h4 id="transopse"><a href="#transopse" class="header-anchor">#</a> Transopse</h4> <blockquote><p>Transpose: transpose two specified dimensions</p></blockquote> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230314152111164.png" style="zoom:67%;"> <h4 id="squeeze"><a href="#squeeze" class="header-anchor">#</a> Squeeze</h4> <blockquote><p><strong>Squeeze</strong>: remove the specified dimension with length = 1.</p></blockquote> <p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230313205557115.png" alt="image-20230313205557115"></p> <ul><li>如果传给 <code>squueeze</code> 的 dim 在矩阵上 length ≠ 1，那么不会做任何改变。</li></ul> <h4 id="unsqueeze"><a href="#unsqueeze" class="header-anchor">#</a> Unsqueeze</h4> <blockquote><p><strong>Unsqueeze</strong>: expand a new dimension.</p></blockquote> <p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230313205616112.png" alt="image-20230313205616112"></p> <h4 id="cat"><a href="#cat" class="header-anchor">#</a> Cat</h4> <blockquote><p><strong>Cat</strong>: concatenate multiple tensors.</p></blockquote> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230313205626447.png" alt="image-20220123174701303" style="zoom:80%;"> <h4 id="tensors-pytorch-v-s-numpy"><a href="#tensors-pytorch-v-s-numpy" class="header-anchor">#</a> <strong>Tensors – PyTorch v.s. NumPy</strong></h4> <blockquote><p>Many functions have the same names as well</p></blockquote> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230314152814760.png" style="zoom:67%;"> <h1 id="autograd"><a href="#autograd" class="header-anchor">#</a> Autograd</h1> <p><strong>Autograd</strong> （Automatic differentiation是另一种翻译）中文是<strong>自动微分</strong>，它<em>在运行时动态地跟踪你的计算</em>，它可以轻松地计算多个偏导数（也称为梯度),是神经网络优化的核心。</p> <p>由于我们主要是在训练的背景下讨论 autograd，<strong>我们感兴趣的输出将是模型的损失</strong>。此函数表示我们的模型预测与特定输入的理想输出相差多远。 在训练模型时，我们希望最小化损失。在完美模型的理想情况下，这意味着调整其学习权重——即函数的可调参数——使得所有输入的损失为零。在现实世界中，这意味着一个不断调整学习权重的迭代过程，直到我们看到我们对各种输入的损失是可以容忍的。</p> <h2 id="微分示例"><a href="#微分示例" class="header-anchor">#</a> 微分示例</h2> <p>假设一个向量<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="["></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mo space="2" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c="]"></mjx-c></mjx-mo></mjx-math></mjx-container> 作为输入,<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="z"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-munderover space="4" limits="false"><mjx-mo class="mjx-sop"><mjx-c c="2211"></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.285em;"><mjx-TeXAtom size="s"></mjx-TeXAtom><mjx-spacer style="margin-top:0.762em;"></mjx-spacer><mjx-TeXAtom size="s"></mjx-TeXAtom></mjx-script></mjx-munderover><mjx-mi space="2" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-munderover space="2" limits="false"><mjx-mo class="mjx-sop"><mjx-c c="2211"></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.285em;"><mjx-TeXAtom size="s"></mjx-TeXAtom><mjx-spacer style="margin-top:0.762em;"></mjx-spacer><mjx-TeXAtom size="s"></mjx-TeXAtom></mjx-script></mjx-munderover><mjx-mi space="2" class="mjx-i"><mjx-c c="j"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-msubsup><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.284em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn><mjx-spacer style="margin-top:0.18em;"></mjx-spacer><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msubsup><mjx-msub><mjx-mo noIC="true" class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="j"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-TeXAtom></mjx-math></mjx-container>,那么z关于x的偏导是：</p> <p><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="z"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-msub><mjx-mo noIC="true" class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="j"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-msub><mjx-mo noIC="true" class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="j"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math></mjx-container></p> <p>其偏微分值为：</p> <p><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="z"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="["></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mo space="2" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c="]"></mjx-c></mjx-mo></mjx-TeXAtom></mjx-math></mjx-container></p> <p>pytorch中代码为</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> x <span class="token operator">=</span> torch.tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span>., <span class="token number">0</span>.<span class="token punctuation">]</span>, <span class="token punctuation">[</span>-1., <span class="token number">1</span>.<span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token assign-left variable">requires_grad</span><span class="token operator">=</span>True<span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> z <span class="token operator">=</span> x.pow<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>.sum<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> z.backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> x.grad
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">2</span>., -2.<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h2 id="基本原理"><a href="#基本原理" class="header-anchor">#</a> 基本原理</h2> <p>上面的计算过程中，<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="4" class="mjx-n"><mjx-utext variant="normal" style="font-family:serif;">、</mjx-utext></mjx-mo><mjx-TeXAtom space="4"><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.017em;"><mjx-mi class="mjx-i"><mjx-c c="z"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-math></mjx-container> 都被当做<strong>节点</strong>，运行过程被抽象为<strong>信息流</strong>，复杂的计算也可以被抽象成一张<strong>计算图</strong>：</p> <p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220116182148630.png" alt="image-20220116182148630"></p> <ul><li>在<strong>计算图</strong>中，往往是节点代表运算（如加法或矩阵乘），箭头代表传输的值。</li></ul> <p>微分示例中，<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 是叶子节点，<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.017em;"><mjx-mi class="mjx-i"><mjx-c c="z"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 是中间节点，<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-math></mjx-container> 是输出节点，他们三者都是   Tensor。</p> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220116183156678.png" alt="image-20220116183156678" style="zoom:80%;"> <center>计算图：绿色是叶子节点，橙色是中间节点，红色是输出节点，蓝色箭头表示信息流</center> <p>Tensor 在自动微分方面有三个重要属性：</p> <ul><li><strong>requires_grad</strong>：一个布尔值，默认 False，当其为 True 时表示该 Tensor 需要自动微分</li> <li><strong>grad</strong>：用于存储 Tensor 的微分值</li> <li><strong>grad_fn</strong>：用于存储 Tensor 的微分函数</li></ul> <p>当叶子节点的 <code>requires_grad</code> 为 True 时，<strong>信息流经过该节点时，所有中间节点的 <code>requires_grad</code>  属性都会变成 True</strong>，只要在输出节点调用反向传播函数 <code>backward()</code>，PyTorch 就会自动求出叶子节点的微分值并更新存储在叶子节点的 grad 属性。注意，<strong>只有叶子节点的 <code>grad</code> 属性能被更新</strong>。</p> <h2 id="前向传播"><a href="#前向传播" class="header-anchor">#</a> 前向传播</h2> <p>Autograd 技术可以帮助我们从叶子节点开始追踪信息流，记下整个过程使用的函数，知道输出节点，这个过程被称为<strong>前向传播</strong>。</p> <p>首先初始化叶子节点 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container>：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>one<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>requires_grad
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>打印出 False，因为默认情况下 Tensor 的 <code>requires_grad</code> 为 False。为了让 PyTorch 帮我们自动求微分，我们需要将其设为 True：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> X<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> X
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>此时 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container>  的 <code>grad</code> 和 <code>grad_fn</code> 属性为空。接下来我们计算 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.017em;"><mjx-mi class="mjx-i"><mjx-c c="z"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container>：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> z <span class="token operator">=</span> <span class="token number">4</span> <span class="token operator">*</span> X
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> z
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MulBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>这里面的 <code>grad_fn</code> 是<u>微分函数</u>，在此处是乘法的反向函数。最后我们用 norm() 函数求其长度得到 y：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> y <span class="token operator">=</span> z<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> y
tensor<span class="token punctuation">(</span><span class="token number">5.6569</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>CopyBackwards<span class="token operator">&gt;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h2 id="反向传播"><a href="#反向传播" class="header-anchor">#</a> 反向传播</h2> <p>接下来，调用输出节点的 <code>backward()</code> 函数对整个图进行反向传播，求出微分值：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> X<span class="token punctuation">.</span>grad
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.8284</span><span class="token punctuation">,</span> <span class="token number">2.8284</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>运行后可以发现 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 的 grad 属性更新为 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 的微分值，这个结果与我们人工计算的结果一致。</p> <p>再查看一下 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.017em;"><mjx-mi class="mjx-i"><mjx-c c="z"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-math></mjx-container> 的 grad 值，发现并没有改变，因为他们都不是叶子节点：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> z<span class="token punctuation">.</span>grad
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> y<span class="token punctuation">.</span>grad
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h2 id="实例演示"><a href="#实例演示" class="header-anchor">#</a> 实例演示</h2> <p>假设我们要训练一个线性回归模型：<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi></mjx-math></mjx-container>，即输入是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-TeXAtom space="4"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-TeXAtom></mjx-math></mjx-container>，输出是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container>，真正的值是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-math></mjx-container>；</p> <p>又令损失函数是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mi space="2" class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi><mjx-msup><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container>，那么当输入一个 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 后，梯度的求法为：</p> <ul><li><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-TeXAtom></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container></li> <li><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-TeXAtom></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container></li> <li><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-TeXAtom></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-TeXAtom space="4"><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-math></mjx-container></li></ul> <p>求得损失值对于各参数的梯度后，便可以优化参数，设学习率为 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B7"></mjx-c></mjx-mi></mjx-math></mjx-container>：</p> <ul><li><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="3B7"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container></li> <li><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="3B7"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container></li> <li><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mi space="4" class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="3B7"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container></li></ul> <p>以上便模拟了一个深度学习的计算过程。</p> <h1 id="线性回归"><a href="#线性回归" class="header-anchor">#</a> 线性回归</h1> <p>本节我们将实现一个<strong>线性回归</strong>（LR）模型。</p> <h2 id="理论分析"><a href="#理论分析" class="header-anchor">#</a> 理论分析</h2> <h3 id="_1-准备数据"><a href="#_1-准备数据" class="header-anchor">#</a> 1）准备数据</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">14.4</span><span class="token punctuation">,</span> <span class="token number">29.6</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">,</span> <span class="token number">85</span><span class="token punctuation">,</span> <span class="token number">113.4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>得到图：<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220116200141925.png" alt="image-20220116200141925"></p> <h3 id="_2-目标函数"><a href="#_2-目标函数" class="header-anchor">#</a> 2）目标函数</h3> <p>因为我们假设用一条直线去拟合，所以可以假设该函数为：<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container>。我们的目标就是找到一组合适的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container>。</p> <p>我们把上面 y 改写一下得到：<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container>，这样 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msup><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-script style="vertical-align:0.492em;"><mjx-TeXAtom size="s"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-TeXAtom></mjx-script></mjx-msup></mjx-math></mjx-container> 是由样本中的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-TeXAtom></mjx-script></mjx-msup></mjx-math></mjx-container> 传入线性模型后计算得到的输出，<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-TeXAtom></mjx-script></mjx-msup></mjx-math></mjx-container> 是我们真实样本值。因为测量会产生误差，我们用一个函数来衡量 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msup><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-script style="vertical-align:0.492em;"><mjx-TeXAtom size="s"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-TeXAtom></mjx-script></mjx-msup></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-TeXAtom></mjx-script></mjx-msup></mjx-math></mjx-container> 之间的误差，这个函数就是<strong>损失函数</strong>。在这里，我们采用的损失函数是均方误差函数（Mean-Square Error，<strong>MSE</strong>）：</p> <p><mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-munderover space="4" limits="false"><mjx-mo class="mjx-sop"><mjx-c c="2211"></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.285em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="5"></mjx-c></mjx-mn><mjx-spacer style="margin-top:0.276em;"></mjx-spacer><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-munderover><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-msup><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-script style="vertical-align:0.492em;"><mjx-TeXAtom size="s"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-TeXAtom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-TeXAtom></mjx-script></mjx-msup><mjx-msup><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container></p> <p>因此，我们的目标就是找一组合适的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> 使得损失函数的 L 值最小。</p> <h3 id="_3-优化"><a href="#_3-优化" class="header-anchor">#</a> 3）优化</h3> <p>为了让损失函数值 L 降到最小，我们就要开始调整参数 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> 的值了！这个过程被称为<strong>优化</strong>。这里我们采用一种<strong>梯度下降</strong>的方法来寻找这个函数的最小值。</p> <p>L 的梯度是：<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-n"><mjx-c c="2207"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mfrac space="2"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mi class="mjx-n"><mjx-c c="2202"></mjx-c></mjx-mi><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container></p> <p>这样优化的过程就是做这样的运算：<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msup><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.191em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-script style="vertical-align:0.528em;"><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msup><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.191em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-script style="vertical-align:0.528em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi class="mjx-n"><mjx-c c="2207"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-msup><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.191em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-script style="vertical-align:0.528em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="3" class="mjx-n"><mjx-c c="D7"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="3B4"></mjx-c></mjx-mi></mjx-math></mjx-container>，其中 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B4"></mjx-c></mjx-mi></mjx-math></mjx-container> 是学习率。</p> <h3 id="_4-批量输入"><a href="#_4-批量输入" class="header-anchor">#</a> 4）批量输入</h3> <p>上面的表达式是一次一个样本的形式，在实际的优化中，我们是让多个样本同时在一个公式中出现，所有公式中的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 都要增加一个维度，<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 升级为矩阵 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-b mjx-i"><mjx-c c="X"></mjx-c></mjx-mi></mjx-math></mjx-container>，<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 升级为 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.028em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> ，最终结果为：<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.028em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mi space="4" class="mjx-b mjx-i"><mjx-c c="X"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-TeXAtom space="3"><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.191em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container></p> <p>损失函数 L 可以表示为：<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="|"></mjx-c></mjx-mo><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.028em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-TeXAtom space="3"><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.056em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base style="padding-left:0.005em;"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-msup><mjx-mo class="mjx-n"><mjx-c c="|"></mjx-c></mjx-mo><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container></p> <h3 id="_5-训练"><a href="#_5-训练" class="header-anchor">#</a> 5）训练</h3> <p>训练就是不断地通过前向传播和反向传播，对参数 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.191em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 进行调优，最终让损失函数的损失值 L 达到最小的过程：</p> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220116203409197.png" alt="image-20220116203409197" style="zoom:80%;"> <h2 id="代码实现"><a href="#代码实现" class="header-anchor">#</a> 代码实现</h2> <h3 id="_1-准备数据-2"><a href="#_1-准备数据-2" class="header-anchor">#</a> 1）准备数据</h3> <p>x，y 仍然使用我们之前的数据，我们首先对输入变量和各参数进行初始化：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 准备数据</span>

<span class="token comment"># 生成矩阵X</span>
<span class="token keyword">def</span> <span class="token function">Produce_X</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
	x0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">)</span> <span class="token comment"># 用ones产生初始值为1，大小与x相同的向量</span>
	X <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>x0<span class="token punctuation">)</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment"># stack函数将两个向量拼合</span>
	<span class="token keyword">return</span> X


x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">21</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">14.4</span><span class="token punctuation">,</span><span class="token number">29.6</span><span class="token punctuation">,</span><span class="token number">62</span><span class="token punctuation">,</span><span class="token number">85.5</span><span class="token punctuation">,</span><span class="token number">113.4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> Produce_X<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># 定义权重w的变量</span>
w <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

inputs <span class="token operator">=</span> X 
target <span class="token operator">=</span> y
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><ul><li><p><code>Produce_X</code> 函数将 x 与一个与之相同形状的全 1 向量进行合并得到一个 X，它的实际数据如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>tensor([[ 1.4000,  1.0000],
        [ 5.0000,  1.0000],
        [11.0000,  1.0000],
        [16.0000,  1.0000],
        [21.0000,  1.0000]])
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>这样 X 与 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.191em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 的乘积便相当于一个 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-msub space="4"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container>。</p></li> <li><p>用 <code>rand()</code> 函数来初始化参数向量 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.191em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container>，根据 Autograd 中所介绍的，参数 w 属于计算图的叶子节点，需要进行自动微分并利用梯度下降来更新，因此需要专门将 w 的 <code>requires_grad</code> 设置为 True。</p></li></ul> <h3 id="_2-训练"><a href="#_2-训练" class="header-anchor">#</a> 2）训练</h3> <p>每一轮的训练分成两部分：前向传播和反向传播</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment">#训练</span>
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epochs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>learning_rate<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>

		<span class="token comment">#前向传播</span>
		output <span class="token operator">=</span> inputs<span class="token punctuation">.</span>mv<span class="token punctuation">(</span>w<span class="token punctuation">)</span> <span class="token comment">#公式：y=Xw</span>
		loss <span class="token operator">=</span> <span class="token punctuation">(</span>output <span class="token operator">-</span> target<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 公式：L = ∑(y-y')^2</span>

		<span class="token comment">#反向传播</span>
		loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> 
		w<span class="token punctuation">.</span>data <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> w<span class="token punctuation">.</span>grad  <span class="token comment"># 更新权重w，公式：w_(t+1)= w_(t) - 𝜼*▽J</span>
		
		w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 清空grad的值</span>

		<span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">80</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
			draw<span class="token punctuation">(</span>output<span class="token punctuation">,</span>loss<span class="token punctuation">)</span>

	<span class="token comment">#plt.savefig('plot1.png', format='png')</span>

	<span class="token keyword">return</span> w<span class="token punctuation">,</span> loss
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><ul><li>注意，<strong>我们更新完 w 后，必须清空 w 的 grad 的值，否则 grad 的值会持续累加</strong>。所以，这里使用 <code>zero_()</code> 函数来清空梯度值。</li></ul> <p>为了能够观察到训练的变化，我们可以让程序每进行 80 次循环就更新一次图像，于是定义一个 <code>draw()</code> 函数：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment">#绘图</span>
<span class="token keyword">def</span> <span class="token function">draw</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span>loss<span class="token punctuation">)</span><span class="token punctuation">:</span>
	plt<span class="token punctuation">.</span>cla<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 清空函数图像</span>
	plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 绘制散点图</span>
	
	plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">'r-'</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token comment"># 绘制出回归直线</span>
	plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token string">'Loss=%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>fontdict<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'size'</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token string">'color'</span><span class="token punctuation">:</span><span class="token string">'red'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
	<span class="token comment">#plt.text(3, 9,'Loss=%s' % (loss.item()),fontdict={'size':20,'color':'red'})</span>
	<span class="token comment">#plt.axis([10, 160, 0, 0.03])</span>

	plt<span class="token punctuation">.</span>pause<span class="token punctuation">(</span><span class="token number">0.005</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>于是便可以训练了：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>w<span class="token punctuation">,</span> loss <span class="token operator">=</span> train<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span>learning_rate <span class="token operator">=</span> <span class="token number">1e-4</span><span class="token punctuation">)</span>  <span class="token comment">#学习率设置为1x10^(-4)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>训练完之后打印最终结果：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;final loss:&quot;</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;weights:&quot;</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>运行结果：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>final loss: 8.2430419921875
weights: tensor([5.0840, 5.5849])
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h2 id="大规模数据集实例"><a href="#大规模数据集实例" class="header-anchor">#</a> 大规模数据集实例</h2> <p>之前训练时我们将 5 个数据样本同时输入程序，这种方式叫做<strong>批输入</strong>，这种方式是快速而有效的。</p> <p>人们通过对神经元的研究，对其进行数学抽象得到了<strong>人工神经元模型</strong>：</p> <p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220117175443927.png" alt="image-20220117175443927"></p> <p>PyTorch 为我们预先编写好了损失函数和优化函数等，我们将代码再重新编写一次：</p> <h3 id="_1-准备数据-3"><a href="#_1-准备数据-3" class="header-anchor">#</a> 1）准备数据</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span> optim
<span class="token keyword">from</span> time <span class="token keyword">import</span> perf_counter

<span class="token comment"># 用linspace产生（-3，3）区间内的100000个点，并使用unsqueeze函数增加一个维度</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">100000</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 假设真实函数是y=x，我们在上面增加一些误差，更加符合实际情况</span>
y <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token number">1.2</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><h3 id="_2-定义模型"><a href="#_2-定义模型" class="header-anchor">#</a> 2）定义模型</h3> <p>定义一个线性回归的模型 LR，它继承自 <code>nn.Module</code>，并在其中使用 <code>nn.Linear()</code> 构造线性模型：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">LR</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LR<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><ul><li><code>nn.Linear()</code> 的第一个参数代表输入数据的维度，第二个参数代表输出数据的维度。这里 x 和 y 都是一维的，因此设置为 <code>nn.Linear(1, 1)</code>。</li> <li><code>forward()</code> 函数来构造神经网络前向传播的计算步骤。</li></ul> <h3 id="_3-实例化模型"><a href="#_3-实例化模型" class="header-anchor">#</a> 3）实例化模型</h3> <p>如果平台支持 CUDA，实例化 LR 类后需要调用 <code>cuda()</code> 方法：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment">#如果支持CUDA，则采用CUDA加速</span>
CUDA <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> CUDA<span class="token punctuation">:</span>
	LR_model <span class="token operator">=</span> LR<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
	inputs <span class="token operator">=</span> x<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
	target <span class="token operator">=</span> y<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	LR_model <span class="token operator">=</span> LR<span class="token punctuation">(</span><span class="token punctuation">)</span>
	inputs <span class="token operator">=</span> x
	target <span class="token operator">=</span> y
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h3 id="_4-损失函数"><a href="#_4-损失函数" class="header-anchor">#</a> 4）损失函数</h3> <p>nn 模块中预设有均方误差函数：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="_5-优化器"><a href="#_5-优化器" class="header-anchor">#</a> 5）优化器</h3> <p>下面采用“随机梯度下降”的方法来更新权重。<strong>随机梯度下降</strong>实际上就是梯度下降法的改良版，不采用梯度下降法中把全部数据拿来计算梯度的方法，而是<u>每次随机挑选一个数据样本计算梯度值，并进行权值更新</u>。这样做的<strong>好处</strong>是可以避免一次性加载全部数据导致的内存溢出问题，还可以防止优化的时候陷入局部最小值。这里我们使用 PyTorch 预设的随机梯度下降函数 <code>SGD()</code> 进行更新：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>LR_model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li><code>SGD()</code> 函数的第一个参数是<strong>需要优化的神经网络模型的参数</strong>，第二个参数是<strong>学习率</strong>。</li></ul> <h3 id="_6-训练"><a href="#_6-训练" class="header-anchor">#</a> 6）训练</h3> <p>开始编写 <code>train()</code> 函数，其参数依次是被训练的神经网络模型、损失函数、优化器和训练轮数：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">draw</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span>loss<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;可视化&quot;&quot;&quot;</span>
    <span class="token keyword">if</span> CUDA<span class="token punctuation">:</span>
        output <span class="token operator">=</span> output<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>cla<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">'r-'</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token string">'Loss=%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>fontdict<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'size'</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token string">'color'</span><span class="token punctuation">:</span><span class="token string">'red'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>pause<span class="token punctuation">(</span><span class="token number">0.005</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">global</span> loss
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># forward</span>
        output <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span>

        <span class="token comment"># backward</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>


        <span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">80</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            draw<span class="token punctuation">(</span>output<span class="token punctuation">,</span>loss<span class="token punctuation">)</span>

    <span class="token keyword">return</span> model<span class="token punctuation">,</span> loss
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><ul><li>如果采用了 CUDA 加速，draw 函数的 output 需要还原成 CPU 的数据类型才能进行绘图</li> <li>在<strong>前向传播</strong>阶段，我们将 inputs 输入神经网络模型 model 得到 output，接下来用定义的损失函数 criterion 来计算损失值。</li> <li>在<strong>反向传播</strong>阶段，先用 optimizer.zero_grad() 清空权值的 grad 值，随后用 backward() 计算梯度，并用优化器 optimizer.stip() 函数进行权值更新。</li></ul> <p>接下来我们定义初试时间 start，并传入模型、损失函数、优化器以及训练轮数（10 000 次）：</p> <div class="language-python line-numbers-mode"><div class="highlight-lines"><br><div class="highlighted"> </div><br><br><br><br><br><br><br></div><pre class="language-python"><code>start <span class="token operator">=</span> perf_counter<span class="token punctuation">(</span><span class="token punctuation">)</span>
LR_model<span class="token punctuation">,</span>loss <span class="token operator">=</span> train<span class="token punctuation">(</span>LR_model<span class="token punctuation">,</span>criterion<span class="token punctuation">,</span>optimizer<span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">)</span>
finish <span class="token operator">=</span> perf_counter<span class="token punctuation">(</span><span class="token punctuation">)</span>
time <span class="token operator">=</span> finish <span class="token operator">-</span> start

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;计算时间:%s&quot;</span> <span class="token operator">%</span> time<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;final loss:&quot;</span><span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;weights:&quot;</span><span class="token punctuation">,</span><span class="token builtin">list</span><span class="token punctuation">(</span>LR_model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>代码的训练结果如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>计算时间:164.62969759999942
final loss: 0.12093639373779297
weights: [Parameter containing:
tensor([[0.9995]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.5632], device='cuda:0', requires_grad=True)]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h1 id="非线性回归"><a href="#非线性回归" class="header-anchor">#</a> 非线性回归</h1> <p>非线性就是说我们的拟合函数并非直线或者平面，而是更加复杂的曲线或曲面。</p> <h3 id="激活函数"><a href="#激活函数" class="header-anchor">#</a> 激活函数</h3> <p>在人工神经元图中的后半段还有一个激活函数 f，但我们之前讨论的线性回归忽略了它。在没有激活函数的情况下，多个神经元的堆叠相当于多个线性模型的叠加，从总体上看，其神经网络本质上还是个线性模型。<strong>激活函数</strong>的出现就是为了让神经网络可以<strong>拟合复杂的非线性函数</strong>。激活函数 f 实际上<strong>是一个非常简单的非线性函数</strong>，但只要多个带有激活函数的神经元组合在一起，就具有拟合复杂非线性函数的强大能力。</p> <blockquote><p>各类激活函数可以百度，这里我们一般使用 ReLU 函数。</p> <p>ReLU 函数：<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="R"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="U"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mi space="4" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-utext variant="normal" style="font-family:serif;">（</mjx-utext></mjx-mo><mjx-mi space="4" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="&gt;"></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn><mjx-mo space="4" class="mjx-n"><mjx-utext variant="normal" style="font-family:serif;">）</mjx-utext></mjx-mo><mjx-mo class="mjx-n"><mjx-c c=";"></mjx-c></mjx-mo><mjx-mo space="2" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="2264"></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container></p></blockquote> <p>因此整个神经元的计算过程如下：<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mi space="4" class="mjx-i"><mjx-c c="R"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="U"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-TeXAtom space="3"><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.191em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container></p> <h3 id="人工神经网络"><a href="#人工神经网络" class="header-anchor">#</a> 人工神经网络</h3> <p>为方便，我们可以将网络分成三层：输入层、隐含层（可以有多层）和输出层。隐含层的层数大于等于 2 的神经网络称之为<strong>深度神经网络</strong>。</p> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220118002521894.png" alt="image-20220118002521894" style="zoom:67%;"> <ul><li>在这种示意图中，往往是用圆圈 ○ 表示神经元，用箭头表示它们的连接。此时，<strong>在箭头上有权重</strong>，这个权重和对应的<strong>神经元的值</strong>分别相乘，其和（严格来说，是经过激活函数变换后的值）作为下一个神经元的输入。</li></ul> <h4 id="_1-准备数据-4"><a href="#_1-准备数据-4" class="header-anchor">#</a> 1）准备数据</h4> <p>我们根据一元三次方程自动生成一批数据样本，随后使用他们来演示神经网络的非线性回归：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1.3</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>s<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h4 id="_2-建立模型"><a href="#_2-建立模型" class="header-anchor">#</a> 2）建立模型</h4> <p>我们使用仅含有一层隐含层的神经网络来处理上面的数据：</p> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220118003356722.png" alt="image-20220118003356722" style="zoom:67%;"> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span>optim
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 继承 torch.nn 的 Module</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_feature<span class="token punctuation">,</span> num_hidden<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 继承 __init__ </span>
        <span class="token comment"># 定义每层神经元的结构与数目</span>
        self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_feature<span class="token punctuation">,</span> num_hidden<span class="token punctuation">)</span>   <span class="token comment"># 线性隐含层</span>
        self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hidden<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span>   <span class="token comment"># 输出层</span>
 
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>  
        <span class="token comment"># 前向传播输入值</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token comment"># 激励函数ReLU处理隐含层的输出</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>x<span class="token punctuation">)</span>             <span class="token comment"># 最终输出值</span>
        <span class="token keyword">return</span> x
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><ul><li>激活函数的使用直接调用 <code>torch.nn.functional.F.relu</code> 即可。</li></ul> <p>实例化 Net，设置输入为 1 维，隐含层节点数为 20，输出为 1 维：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>CUDA <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> CUDA<span class="token punctuation">:</span>
	<span class="token comment">#初始化输入神经元数目为1，隐含层数目为20，输出神经元数目为1的神经网络模型</span>
	net <span class="token operator">=</span> Net<span class="token punctuation">(</span>input_feature<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> num_hidden<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
	inputs <span class="token operator">=</span> x<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
	target <span class="token operator">=</span> y<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	net <span class="token operator">=</span> Net<span class="token punctuation">(</span>input_feature<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> num_hidden<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
	inputs <span class="token operator">=</span> x
	target <span class="token operator">=</span> y
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>与线性回归一样，优化器选择随机梯度下降，损失函数为均方误差：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token comment"># 传入 net 的所有参数, 学习率</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 预测值和真实值的误差计算公式 (均方差)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h4 id="_3-训练"><a href="#_3-训练" class="header-anchor">#</a> 3）训练</h4> <p>训练函数 train() 与之前类似，也是<strong>分成前向传播和反向传播两个步骤</strong>：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">draw</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span>loss<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">if</span> CUDA<span class="token punctuation">:</span>
		output <span class="token operator">=</span> output<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
	plt<span class="token punctuation">.</span>cla<span class="token punctuation">(</span><span class="token punctuation">)</span>
	plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">'r-'</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
	plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token string">'Loss=%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>fontdict<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'size'</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token string">'color'</span><span class="token punctuation">:</span><span class="token string">'red'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
	plt<span class="token punctuation">.</span>pause<span class="token punctuation">(</span><span class="token number">0.005</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span>criterion<span class="token punctuation">,</span>optimizer<span class="token punctuation">,</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token comment"># forward</span>
		output <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
		loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span>

		<span class="token comment"># backward</span>
		optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
		loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
		optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
		
		<span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">80</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
			draw<span class="token punctuation">(</span>output<span class="token punctuation">,</span>loss<span class="token punctuation">)</span>

	<span class="token keyword">return</span> model<span class="token punctuation">,</span>loss

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br></div></div><p>我们训练 10000 次，并打印最终结果：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>net<span class="token punctuation">,</span>loss <span class="token operator">=</span> train<span class="token punctuation">(</span>net<span class="token punctuation">,</span>criterion<span class="token punctuation">,</span>optimizer<span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;final loss:&quot;</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h1 id="逻辑回归"><a href="#逻辑回归" class="header-anchor">#</a> 逻辑回归</h1> <p>线性回归和非线性回归的输出都是连续的，而<strong>逻辑回归的输出是二元离散的</strong>，即输出 y 只有两种结果，因此，<u>逻辑回归也常常被当作二元分类问题</u>。</p> <h2 id="sigmoid-函数"><a href="#sigmoid-函数" class="header-anchor">#</a> sigmoid 函数</h2> <p>非线性 sigmoid 函数（常简写为 <strong>sigm</strong>）：<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="s"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="g"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="m"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mo class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-script></mjx-msup></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220118144558229.png" alt="image-20220118144558229" style="zoom:67%;"></p> <p>二元分类的模型结构如下：</p> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220118144717708.png" alt="image-20220118144717708" style="zoom:67%;"> <p>这样将输入 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 经过网络后，通过 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="s"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="g"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="m"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-TeXAtom space="3"><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.191em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> 映射为集合 （0， 1） 中的一个实数，我们可以将这个最终输出当作 y=1 的概率 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="P"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="u"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-TeXAtom space="2"><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.191em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-TeXAtom space="2"><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> 。</p> <p>sigmoid 已预置在 PyTorch 的 <code>torch.sigmoid()</code> 中，该函数可以将输入的 Tensor 输出成（0,1）之间的数，且和为 1：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> a
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2128</span><span class="token punctuation">,</span>  <span class="token number">0.5412</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.4470</span><span class="token punctuation">,</span> <span class="token number">0.6321</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h2 id="交叉熵损失函数"><a href="#交叉熵损失函数" class="header-anchor">#</a> 交叉熵损失函数</h2> <p><strong>交叉熵损失函数</strong>是分类问题中常用的损失函数。在 PyTorch 中已经预置在 <code>nn.CrossEntropyLoss()</code> 中了。</p> <blockquote><p>为什么用交叉熵函数？我们可以将二元分类问题抽象成数学中的伯努利模型，然后对其使用最大似然法得到似然度的计算公式，通过对其进行转化，可以将求似然度的最大值转化为求一个损失函数的最小值，这里的损失函数便是交叉熵函数。</p></blockquote> <h2 id="逻辑回归示例"><a href="#逻辑回归示例" class="header-anchor">#</a> 逻辑回归示例</h2> <h3 id="_1-准备数据-5"><a href="#_1-准备数据-5" class="header-anchor">#</a> 1）准备数据</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span>optim

means <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment">#ones函数生成500x2的数据</span>
data0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">4</span> <span class="token operator">*</span> means<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment">#构造一个均值为4，标准差为2的数据簇</span>
data1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">4</span> <span class="token operator">*</span> means<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment">#构造一个均值为-4，标准差为2的数据簇</span>
label0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span> <span class="token comment">#500个标签0</span>
label1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span> <span class="token comment">#500个标签1</span>

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>data0<span class="token punctuation">,</span> data1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span> 
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>label0<span class="token punctuation">,</span> label1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'RdYlGn'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220118151820205.png" alt="image-20220118151820205"></p> <h3 id="_2-建立模型-2"><a href="#_2-建立模型-2" class="header-anchor">#</a> 2）建立模型</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token comment"># 继承 torch 的 Module</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># 继承 __init__ 功能</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

CUDA <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> CUDA<span class="token punctuation">:</span>
    net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    inputs <span class="token operator">=</span> x<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    target <span class="token operator">=</span> y<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
    inputs <span class="token operator">=</span> x
    target <span class="token operator">=</span> y
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><ul><li><code>nn.Linear(2, 2)</code> 的输入包括两个特征 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container>，分别代表横轴和纵轴；输出的是两个类“得分”情况，我们假设哪一类分数高，就属于哪一类。<strong>可以使用 sigmoid 函数来生成两个类的概率</strong>。</li></ul> <p>我们仍然使用随机梯度下降来优化，损失函数使用交叉熵函数：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="_3-训练-2"><a href="#_3-训练-2" class="header-anchor">#</a> 3）训练</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">draw</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> CUDA<span class="token punctuation">:</span>
        output<span class="token operator">=</span>output<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>cla<span class="token punctuation">(</span><span class="token punctuation">)</span>
    output <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> 
    pred_y <span class="token operator">=</span> output<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
    target_y <span class="token operator">=</span> y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>pred_y<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'RdYlGn'</span><span class="token punctuation">)</span>
    accuracy <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>pred_y <span class="token operator">==</span> target_y<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">1000.0</span>  
    plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'Accuracy=%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>accuracy<span class="token punctuation">)</span><span class="token punctuation">,</span> fontdict<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'size'</span><span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token string">'color'</span><span class="token punctuation">:</span>  <span class="token string">'red'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>pause<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span>criterion<span class="token punctuation">,</span>optimizer<span class="token punctuation">,</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#forward</span>
        output <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>

        <span class="token comment">#backward</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">40</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            draw<span class="token punctuation">(</span>output<span class="token punctuation">)</span>


train<span class="token punctuation">(</span>net<span class="token punctuation">,</span>criterion<span class="token punctuation">,</span>optimizer<span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br></div></div><ul><li>第 5 行的 <code>torch.max()</code> 会返回 output 中概率最大的一组数值与该类别的标签。</li></ul> <div class="custom-block tip"><p class="custom-block-title">torch.max()</p> <p><code>torch.max()</code> 会返回选定维度中的最大值和序列号，例如 <code>torch.max(b, 1)</code> 会返回第一维的最大值和序列号：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> b
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.4022</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7402</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span> <span class="token number">1.4084</span><span class="token punctuation">,</span>  <span class="token number">0.0899</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.5336</span><span class="token punctuation">,</span>  <span class="token number">0.8580</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span> <span class="token number">0.7828</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5670</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1495</span><span class="token punctuation">,</span>  <span class="token number">0.0716</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>
values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.4022</span><span class="token punctuation">,</span> <span class="token number">1.4084</span><span class="token punctuation">,</span> <span class="token number">0.8580</span><span class="token punctuation">,</span> <span class="token number">0.7828</span><span class="token punctuation">,</span> <span class="token number">0.0716</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div></div> <h1 id="多元分类"><a href="#多元分类" class="header-anchor">#</a> 多元分类</h1> <p>逻辑回归是二元分类，属于多元分类的特殊情况。</p> <h2 id="softmax-函数"><a href="#softmax-函数" class="header-anchor">#</a> softmax 函数</h2> <p>多元分类与二元分类类似，区别在于用 softmax 代替 sigmoid。<strong>多元分类的神经网络要求输出层的神经元数目与所需分类的类别数保持一致</strong>。<strong>softmax 能将所有分类的分数值 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3B7"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3B7"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mo space="2" class="mjx-n"><mjx-c c="22EF"></mjx-c></mjx-mo><mjx-mo space="2" class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3B7"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container> 转化为概率 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3C0"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3C0"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mo space="2" class="mjx-n"><mjx-c c="22EF"></mjx-c></mjx-mo><mjx-mo space="2" class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3C0"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container>，且各概率和为 1</strong>。</p> <p>多元分类模型的结构：</p> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220118165313230.png" alt="image-20220118165313230" style="zoom:80%;"> <p>softmax 函数：<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3C0"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="l"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-msup size="s"><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3B7"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.34em;"><mjx-mi class="mjx-i"><mjx-c c="l"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-TeXAtom></mjx-script></mjx-msup></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-munderover limits="false"><mjx-mo class="mjx-sop"><mjx-c c="2211"></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.285em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi><mjx-spacer style="margin-top:0.284em;"></mjx-spacer><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="j"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-munderover><mjx-TeXAtom space="2"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="e"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.472em;"><mjx-TeXAtom size="s"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3B7"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.307em;"><mjx-mi class="mjx-i"><mjx-c c="j"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-TeXAtom></mjx-script></mjx-msup></mjx-TeXAtom></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container></p> <p>softmax 巧妙地将多个分类的分数转化为（0,1）的值并且和为 1：<mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-munderover limits="false"><mjx-mo class="mjx-sop"><mjx-c c="2211"></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.285em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi><mjx-spacer style="margin-top:0.284em;"></mjx-spacer><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-munderover><mjx-TeXAtom space="2"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3C0"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-TeXAtom><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-math></mjx-container></p> <h2 id="多元分类示例"><a href="#多元分类示例" class="header-anchor">#</a> 多元分类示例</h2> <h3 id="_1-准备数据-6"><a href="#_1-准备数据-6" class="header-anchor">#</a> 1）准备数据</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span>optim
 
<span class="token comment"># 生成数据</span>
means <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> 
data0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">4</span><span class="token operator">*</span>means<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>      
data1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">4</span><span class="token operator">*</span>means<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    
data2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">8</span><span class="token operator">*</span>means<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>     
label0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>
label1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>                
label2 <span class="token operator">=</span> label1<span class="token operator">*</span><span class="token number">2</span>  <span class="token comment">#500个标签2</span>
 
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>data0<span class="token punctuation">,</span> data1<span class="token punctuation">,</span> data2<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span>  
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>label0<span class="token punctuation">,</span> label1<span class="token punctuation">,</span> label2<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">)</span>    
 
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'RdYlGn'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br></div></div><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220118170525699.png" alt="image-20220118170525699" style="zoom:80%;"> <h3 id="_2-建立模型-3"><a href="#_2-建立模型-3" class="header-anchor">#</a> 2）建立模型</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_feature<span class="token punctuation">,</span> num_hidden<span class="token punctuation">,</span>outputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>     
        self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_feature<span class="token punctuation">,</span> num_hidden<span class="token punctuation">)</span>   <span class="token comment"># 线性隐含层</span>
        self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hidden<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span>       <span class="token comment"># 输出层</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token comment"># 激励函数ReLU处理隐含层的输出</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>x<span class="token punctuation">)</span>     <span class="token comment">#使用softmax将输出层的数据转换成概率值           </span>
        <span class="token keyword">return</span> x

CUDA <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> CUDA<span class="token punctuation">:</span>
    net <span class="token operator">=</span> Net<span class="token punctuation">(</span>input_feature<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> num_hidden<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>outputs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    inputs <span class="token operator">=</span> x<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    target <span class="token operator">=</span> y<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    net <span class="token operator">=</span> Net<span class="token punctuation">(</span>input_feature<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> num_hidden<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>outputs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
    inputs <span class="token operator">=</span> x
    target <span class="token operator">=</span> y

optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br></div></div><h3 id="_3-训练-3"><a href="#_3-训练-3" class="header-anchor">#</a> 3）训练</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code>ef draw<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> CUDA<span class="token punctuation">:</span>
        output<span class="token operator">=</span>output<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>cla<span class="token punctuation">(</span><span class="token punctuation">)</span>
    output <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> 
    pred_y <span class="token operator">=</span> output<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
    target_y <span class="token operator">=</span> y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>pred_y<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'RdYlGn'</span><span class="token punctuation">)</span>
    accuracy <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>pred_y <span class="token operator">==</span> target_y<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">1500.0</span>  
    plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'Accuracy=%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>accuracy<span class="token punctuation">)</span><span class="token punctuation">,</span> fontdict<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'size'</span><span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token string">'color'</span><span class="token punctuation">:</span>  <span class="token string">'red'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>pause<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span>criterion<span class="token punctuation">,</span>optimizer<span class="token punctuation">,</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#forward</span>
        output <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span>

        <span class="token comment">#backward</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">40</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            draw<span class="token punctuation">(</span>output<span class="token punctuation">)</span>

train<span class="token punctuation">(</span>net<span class="token punctuation">,</span>criterion<span class="token punctuation">,</span>optimizer<span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><h1 id="卷积神经网络"><a href="#卷积神经网络" class="header-anchor">#</a> 卷积神经网络</h1> <h2 id="引入卷积"><a href="#引入卷积" class="header-anchor">#</a> 引入卷积</h2> <p>经过对猫的脑皮层研究发现，<u>视觉系统的信息处理是分级的</u>。卷积神经网络模仿人脑的视觉处理机制，采用分级提取特征的原理，每一级的特征均由网络学习提取。</p> <p>在前面介绍的神经网络中，输入层被描述为一列神经元。而在卷积神经网络里，我们<strong>把输入层看做二维的神经元</strong>，如果输入的是像素大小为 28 * 28 的图片，则可以看做 28 * 28 的二维神经元，<strong>它的每一个节点对应图片在这个像素点的灰度值</strong>。</p> <p>在传统神经网络中，我们会把输入层的节点与隐含层的节点采用全连接，而在 CNN 中，我们采用“<strong>局部感知</strong>”的方法，即不再把输入层的每个节点都连接到隐含层的每一个神经元节点上，而是用一个局部感知域（过滤器）不断移动进行卷积：</p> <p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220119151430747.png" alt="image-20220119151430747"></p> <p>在卷积神经网络中，这种隐含层也被称为<strong>特征图</strong>。</p> <details class="custom-block details"><summary>为什么卷积？</summary> <p>在传统全连接的神经网络中，如果要对一张图片进行分类，连接方式如下图所示。我们把一张大小为 100×100 的图片的每个像素点都连接到每一个隐含层的节点上，如果隐含层的节点数为 10000，那么连接的权重总数则为 <mjx-container jax="CHTML" class="MathJax"><mjx-math class="MJX-TEX"><mjx-msup><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c><mjx-c c="0"></mjx-c></mjx-mn><mjx-script style="vertical-align:0.393em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="8"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container> 个。当图片像素更大，隐含层的节点数目更多时，则需要更加庞大的权重数目。</p> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220119152111741.png" alt="image-20220119152111741" style="zoom:50%;"> <p>在卷积神经网络中，我们不再需要如此庞大的权重数目。，在利用 10×10 的过滤器对 100×100 的原图进行卷积时，该过滤器在不断滑动的过程中对应生成一张特征图，即一个过滤器(100个权重值)可对应一张特征图。如果我们有 100 张特征图，则一共只需要 104 个权重值。<u>如此一来，在一个隐含层的情况下，卷积神经网络的权重数目可以减小至全连接神经网络权重数目的一万分之一，大大减少计算量，提高计算效率</u>。</p> <p>另外一个原因：想象一下，假设你想从一张图片中找到某个物体。 合理的假设是：无论哪种方法找到这个物体，都应该和物体的位置无关。 理想情况下，我们的系统应该能够利用常识：猪通常不在天上飞，飞机通常不在水里游泳。 但是，如果一只猪出现在图片顶部，我们还是应该认出它。 我们可以从儿童游戏”沃尔多在哪里”中得到灵感： 在这个游戏中包含了许多充斥着活动的混乱场景，而沃尔多通常潜伏在一些不太可能的位置，读者的目标就是找出他。 尽管沃尔多的装扮很有特点，但是在眼花缭乱的场景中找到他也如大海捞针。 然而沃尔多的样子并不取决于他潜藏的地方，因此我们可以使用一个“沃尔多检测器”扫描图像。 该检测器将图像分割成多个区域，并为每个区域包含沃尔多的可能性打分。 卷积神经网络正是将<em>空间不变性</em>（spatial invariance）的这一概念系统化，从而基于这个模型使用较少的参数来学习有用的表示。</p> <p>现在，我们将上述想法总结一下，从而帮助我们设计适合于计算机视觉的神经网络架构：</p> <ol><li><em>平移不变性</em>（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。</li> <li><em>局部性</em>（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。</li></ol></details> <p>进行卷积操作之前需要定义一个<strong>过滤器</strong>，其中每一格都有一个权重值。卷积的过程就是将格子中的权重值与图片对应的像素值相乘并累加。得到的隐含层的结果就是我们通过卷积生成的<strong>特征图</strong>：</p> <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220119152953200.png" alt="image-20220119152953200" style="zoom:40%;"> <p>重要术语：卷积计算、过滤器（卷积核）、步长（stride）、填充（padding）</p> <h2 id="池化"><a href="#池化" class="header-anchor">#</a> 池化</h2> <p><strong>池化</strong>的目的是降低数据的维度，过程实际上就是<strong>下采样</strong>：</p> <p><img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20220119155254565.png" alt="image-20220119155254565"></p> <p>图示为最大池化，实际应用中生成池化特征的方式一般有两种：</p> <ul><li><strong>最大值池化</strong>（Max-Pooling）：将池化窗口内的最大值作为池化结果的特征值</li> <li><strong>平均值池化</strong>（Mean-Pooling）：将池化窗口内的所有值的平均值作为池化结果的特征值</li></ul></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/flokken/edit/master/docs/AI/30.深度学习/01.Pytorch/01.pytorch入门.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2023/03/15, 09:28:20</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/f7970b/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">Prompt Engineering</div></a> <a href="/pages/720944/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">pytorch常用函数</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/f7970b/" class="prev">Prompt Engineering</a></span> <span class="next"><a href="/pages/720944/">pytorch常用函数</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/fd9dbf/"><div>
            线程池
            <!----></div></a> <span class="date">09-16</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/64ddd0/"><div>
            消息队列基础知识
            <!----></div></a> <span class="date">09-08</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/4b5092/"><div>
            树状数组和线段树
            <!----></div></a> <span class="date">08-22</span></dt></dl> <dl><dd></dd> <dt><a href="/archives" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:2878846959@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/Flokken" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/my/m/music/playlist?id=807177837" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2023-2024
    <span>flokken | <a href="https://github.com/xugaoyi/vuepress-theme-vdoing/blob/master/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <div class="body-bg" style="background:url() center center / cover no-repeat;opacity:0.5;"></div> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.6c1ebbcf.js" defer></script><script src="/assets/js/2.28dcc766.js" defer></script><script src="/assets/js/34.270daa56.js" defer></script>
  </body>
</html>
