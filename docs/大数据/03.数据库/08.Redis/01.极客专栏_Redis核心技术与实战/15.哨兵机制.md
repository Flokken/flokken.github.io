---
title: 哨兵机制：主库挂了，如何不间断服务？
date: 2023-10-19
tags: 
  - Java
categories: 
  - 大数据
  - Redis
  - 极客专栏_Redis核心技术与实战
---

## 引言

上一节学习了主从库集群模式。在这个模式下，如果从库发生故障了，客户端可以继续向主库或其他从库发送请求，进行相关的操作。

**但是如果主库发生故障了**，那就直接会影响到从库的同步，因为从库没有相应的主库可以进行数据复制操作了。

并且，在主从库集群模式下的读写分离也会出问题，因为主库才能进行写操作，如下图：

> 主库挂了，两点影响，一是数据不能同步了，二是不能处理写操作了

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231019194539455.png" alt="image-20231019194539455" style="zoom:80%;" />

**无论是写服务中断，还是从库无法进行数据同步，都是不能接受的。所以，如果主库挂了，我们就需要运行一个新主库**，比如说把一个从库切换为主库，把它当成主库。这就涉及到三个问题：

1. 主库真的挂了吗？
2. 该选择哪个从库作为主库？
3. 怎么把新主库的相关信息通知给从库和客户端呢？

**在Redis主从集群中，利用哨兵机制实现主从库自动切换，**并且解决了上述三个问题

## 哨兵机制的基本流程

**哨兵其实就是一个运行在特殊模式下的Redis进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：**

**监控、选主（选择主库）和通知。**

- 监控是指哨兵进程在运行时，周期性地给所有的主从库发送PING命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的PING命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的PING命令，哨兵就会判定主库下线，然后开始**自动切换主库**的流程。
- 选主。主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。
- 通知。在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行replicaof命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。

![image-20231019195111403](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231019195111403.png)

## 主观下线和客观下线

在监控任务中，哨兵需要判断主库是否处于下线状态；**哨兵对主库的下线判断有“主观下线”和“客观下线”两种。**

> 其实就是分布式共识里的著名的问题，从库如何判断主库已经下线？

**主观下线**

**哨兵进程会使用PING命令检测它自己和主、从库的网络连接情况，用来判断实例的状态**。如果哨兵发现主库或从库对PING命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。

**如果检测的是从库，那么，哨兵简单地把它标记为“主观下线”就行了，因为从库的下线影响一般不太大，集群的对外服务不会间断。**

但是，如果检测的是主库，那么，哨兵还不能简单地把它标记为“主观下线”，开启主从切换。**因为很有可能存在这么一个情况：那就是哨兵误判了，其实主库并没有故障**。可是，一旦启动了主从切换，后续的选主和通知操作都会带来额外的计算和通信开销。

> 误判可能出现在网络压力大的时候，虽然主库没有响应哨兵，但只是因为网络不好，主库其实还活着。
>
> 误判应该尽量避免，因为两个master，会造成脑裂

**Redis采用哨兵集群避免误判。**引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，**多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。**

**客观下线**

有了集群，如何判断是否下线？对于这个问题，**用到了大多数原则。当有N个哨兵实例时，最好要有N/2 + 1个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。**

> 这个客观下线就和paxos中节点对提案达成共识一样，只要有了大多数接受，那么这个提案就被批准了。这个里面就是任务主库已经下线了。

## 如何选新主库？

一般来说，我把哨兵选择新主库的过程称为“筛选+打分”。简单来说，我们在多个从库中，先按照**一定的筛选条件**，把不符合条件的从库去掉。然后，我们再按照**一定的规则**，给剩下的从库逐个打分，将得分最高的从库选为新主库，如下图所示：

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231019204758406.png" alt="image-20231019204758406" style="zoom:80%;" />

### **筛选**

首先要保证从库的网络良好，因为我们希望从库变成主库之后能良好运行。

**除了检查从库的当前在线状态，还要判断它之前的网络连接状态。如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了。**

具体怎么判断呢？你使用配置项down-after-milliseconds * 10。其中，down-after-milliseconds是我们认定主从库断连的最大连接超时时间。如果在down-after-milliseconds毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了10次，就说明这个从库的网络状况不好，不适合作为新主库。

### **按规则打分**

> 哨兵就是为了帮忙从库进行选主的

从库的打分按照三个规则依次进行三轮打分

**从库优先级、从库复制进度以及从库ID号**。只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮。

**第一轮：优先级最高的从库得分高。**

用户可以通过slave-priority配置项，给不同的从库设置不同优先级。比如，你有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时，哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。

**第二轮：和旧主库同步程度最接近的从库得分高。**

这个规则的依据是，如果选择和旧主库同步最接近的那个从库作为主库，那么，这个新主库上就有最新的数据。

**如何判断从库和旧主库间的同步进度呢？**

主从库同步时有个命令传播的过程。在这个过程中，主库会用master_repl_offset记录当前的最新写操作在repl_backlog_buffer中的位置，而从库会用slave_repl_offset这个值记录当前的复制进度。

此时，我们想要找的从库，它的slave_repl_offset需要最接近master_repl_offset。如果在所有从库中，有从库的slave_repl_offset最接近master_repl_offset，那么它的得分就最高，可以作为新主库。

就像下图所示，旧主库的master_repl_offset是1000，从库1、2和3的slave_repl_offset分别是950、990和900，那么，从库2就应该被选为新主库。

![image-20231019205443346](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231019205443346.png)

当然，如果有两个从库的slave_repl_offset值大小是一样的（例如，从库1和从库2的slave_repl_offset值都是990），我们就需要给它们进行第三轮打分了。

**第三轮：ID号小的从库得分高。**

每个实例都会有一个ID，这个ID就类似于这里的从库的编号。目前，Redis在选主库时，有一个默认的规定：**在优先级和复制进度都相同的情况下，ID号最小的从库得分最高，会被选为新主库**。

到这里，新主库就被选出来了，“选主”这个过程就完成了。

我们再回顾下这个流程。首先，哨兵会按照在线状态、网络状态，筛选过滤掉一部分不符合要求的从库，然后，依次按照优先级、复制进度、ID号大小再对剩余的从库进行打分，只要有得分最高的从库出现，就把它选为新主库。

## 小结

**哨兵机制是实现Redis不间断服务的重要保证**。具体来说，主从集群的数据同步，是数据可靠的基础保证；而在主库发生故障时，自动的主从切换是服务不间断的关键支撑。

Redis的哨兵机制自动完成了以下三大功能，从而实现了主从库的自动切换，可以降低Redis集群的运维开销：

- 监控主库运行状态，并判断主库是否客观下线；
- 在主库客观下线后，选取新主库；
- 选出新主库后，通知从库和客户端。

为了降低误判率，在实际应用时，哨兵机制通常采用多实例的方式进行部署，多个哨兵实例通过“少数服从多数”的原则，来判断主库是否客观下线。一般来说，我们可以部署三个哨兵，如果有两个哨兵认定主库“主观下线”，就可以开始切换过程。当然，如果你希望进一步提升判断准确率，也可以再适当增加哨兵个数，比如说使用五个哨兵。

**但是，使用多个哨兵实例来降低误判率，其实相当于组成了一个哨兵集群，我们会因此面临着一些新的挑战，例如：**

- 哨兵集群中有实例挂了，怎么办，会影响主库状态判断和选主吗？
- 哨兵集群多数实例达成共识，判断出主库“客观下线”后，由哪个实例来执行主从切换呢？

这些问题下一节会提到。

## Q&A

1.主库切换过程中，客户端能否正常地进行请求操作呢

A：主从集群一般是采用读写分离模式，当主库故障后，客户端仍然可以把读请求发送给从库，让从库服务。但是，对于写请求操作，客户端就无法执行了。

2.如果想要应用程序不感知服务的中断，还需要哨兵或需要客户端再做些什么吗？

**一方面，客户端需要能缓存应用发送的写请求。只要不是同步写操作（Redis应用场景一般也没有同步写），写请求通常不会在应用程序的关键路径上，所以，客户端缓存写请求后，给应用程序返回一个确认就行。**

另一方面，主从切换完成后，客户端要能和新主库重新建立连接，哨兵需要提供订阅频道，让客户端能够订阅到新主库的信息。同时，客户端也需要能主动和哨兵通信，询问新主库的信息。
