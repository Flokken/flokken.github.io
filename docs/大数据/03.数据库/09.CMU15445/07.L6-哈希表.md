---
title: L6-哈希表
date: 2023-12-11
tags: 
  - null
categories: 
  - 大数据
  - CMU15445
---

## Access Methods

首先我们看一下cmu这个课的体系，我们之前已经学习了disk manager和buffer pool manager。

那么我们现在就需要去找到一种东西支持我们去读写页页上的数据，这种支持是什么呢，就是数据结构。

<img src="C:/Users/28788/AppData/Roaming/Typora/typora-user-images/image-20231211095105965.png" alt="image-20231211095105965" style="zoom:50%;" />

**重点是两种数据结构**

- Hash Tables
- Trees

## Hash Table

我们设计的hash表重点关注两个方面：

- **DataOrganization**：如何在内存/pages中布局数据，并且存储那些数据来支持有效的读取
- **Concurrency**：我们需要允许多个进程并发读写hash表
  - 这里可以提一嘴java的concurrentHashTable。就能支持并发读写hash表

Hash表我们很熟悉，通过一个hash函数，将key映射到value

比如  对于长度为n的数组，我们选取hash函数是 i%n,这样就能得打一个hash表。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211100318553.png" alt="image-20231211100318553" style="zoom:50%;" />

这里注意，value不一定存的就是value，也可以是**value的地址的指针**。同时，我们还注意到一个问题，就是hash函数对不同的可以映射之后的value可能一样，这回导致**hash冲突**。  比如上面的取模hash函数，假设n=100,那么key105,205时就会产生hash碰撞

![image-20231211100809000](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211100809000.png)

复杂度:

- 时间复杂度：  O(n)
- 空间复杂度：平均是O(1),最差是O(n)

### Hash Function

- hash函数：对于一个输入的key，返回一个整数代表这个key
- 我们不想使用加密算法去算hash值
  - 开销太大
  - 不能反译
- **我们希望他尽量快，尽量少发送hash碰撞**

这是一些出名的hash函数的表现

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211101822938.png" alt="image-20231211101822938" style="zoom:50%;" />

### Statci Hashing Schemes

课上介绍了三种静态hash函数

> 了解即可，并不常用

#### Liner Probe Hashing

> 线性探测hash，也翻译成开放地址hash
>
> 重点看看这个

原理非常简单，就是我有一个hash数据，然后经过一个线性的函数进行映射（比如ax+b）到hash数组。

- 如果value对应的地方是空的，可以直接存
- 如果发生碰撞，就从碰撞的地方往下移，直到没数据的地方再存起来

我们查询的时候呢，如果发现当前位置不是自己对应的value，就往下探（这其实也有问题，查key的时候就已经知道val了，还查什么）

> 这里假设，Hash(A)=Hash(C),    ,然后来讨论一些问题

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211102551787.png" alt="image-20231211102551787" style="zoom:50%;" />

删除的时候。举例，我们删除C的hash值。但是我们注意C存的地方是被移动过的，存在了D本来该被存的位置。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211102746742.png" alt="image-20231211102746742" style="zoom:50%;" />

这时候引起一个很棘手的问题，我们如果查询D，我们发现D的位置没有东西了，那么我们只能认为当前数据没有了，只能重新插入

解决办法一个是墓碑。就是弄一个死亡标记，让D往下接着查

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211102906946.png" alt="image-20231211102906946" style="zoom:50%;" />

还有一个就是每次删除后整理hash表，让他对的上（但是这也很困难，有很多工作要做）

#### Robin HooD Hashing

> 均富方法。这个方法核心就是尽量减少value的移动次数。

这个方法是基于上面的开放地址hash进行了一点改进。

这里假设，Hash(A)=Hash(E)=Hahs(C)  来讨论问题。  val表示从hash碰撞位置开始移动的次数。

这里我们插入E时，后面再下移动每个位置的对应移动次数。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211104036858.png" alt="image-20231211104036858" style="zoom:50%;" />

发现D移动次数比我们移到这里小，所以把他挤下去，然后插入。

这样D和E移动次数都是2了

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211104217511.png" alt="image-20231211104217511" style="zoom:50%;" />

#### CUCKOO  Hashing

> 杜鹃鸟算法，杜鹃鸟经常把蛋下到别人窝里。

这个算法有两个hash表，在两个hash表上，key对应的位置应该不一样。如果一个表冲突，就插入到另一个表，如果两个都冲突，比如下面的情况：

我们C两个都冲突

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211104821888.png" alt="image-20231211104821888" style="zoom:50%;" />

于是C就把B的位置占了，然后把B丢到#1表里，但是B又占了A的位置，于是把A丢到#2,这时候终于不碰撞，完成了。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211105029694.png" alt="image-20231211105029694" style="zoom:50%;" />

#### Observation

上面几种静态的hash函数都有一个问题，**他们的容量一开始就已经定了**，也即是我们一开始就得知道有多少个key。

### Chained  Hashing（重要）

> 链式hash
>
> 上面的静态hash并不常用，链式hash很多地方都在用，比如java的hashmap

**核心思想是引入`bucket`即桶，一个桶可以存一个数据也可以多个数据（容量固定），如果碰撞了，就继续开一个桶（链表连起来）接着存。**

**发生hash冲突时**

- 如果桶里有空位置，就存空位置
- 如果桶满了，就再开一个桶，并且把他们和上一个桶连起来

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211105425798.png" alt="image-20231211105425798" style="zoom:50%;" />

> 拓展：
>
> java中的hashmap就是上面这种思想,
>
> bucket大小是1，如果发生碰撞就在来一个bucket来存。
>
> 如果碰撞数超过10，后面用红黑树来存。

#### Extendibale  hashing（重要+带实验）

> 可扩容的的hash，常用
>
> [参考](https://blog.csdn.net/q2453303961/article/details/128153709)
>
> [很长很详细的讲解](https://www.geeksforgeeks.org/extendible-hashing-dynamic-approach-to-dbms/)

**这里核心思想就是如果运行过程中发现bucket太小了，bucket的链表可能会很长，那就把bucket的容量提高，避免太长的链表出现。**

> 因为在链表查找一个数是O(n)的复杂度，如果碰撞太多，出现很长的链表显然是不行滴

要完成这个 task 首先要明确 可拓展散列 的概念，其中有 几 个关键名词，**目录，桶，全局位深度和局部位深度**

> 这个数据结构还是有点绕，耐心理解一下

- 首先是目录(directory)，目录就是存放着桶指针的表
  - 所以这里的扩容实际上这个目录也会扩张，扩张的办法就是多增加一个二进制位（double）
  - **注意这里的一个索引指向一个bucket，而不是一条记录。也就是不同的key，对应的索引有可能一样**
  - index的计算方式，直接截断hash(key)的前i位（   i.e.  globaldepth=2,mask=11）
  - <img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231214173043552.png"/>
- 桶(bucket)，就是用来存放数据的。桶应该有一个固定大小S。
- 全局位深度(global depth)，这里写作 G ,可以看作目录中最多有 2 的 G 次方个桶。
  - 同时注意，给定一个key**，需要用global depth取出这个key的低n位的二进制值**。例如，一个key的二进制是10111，如果global depth是3，通过`IndexOf(key)`函数，得到返回值的二进制值是111，即为7。这个值用来索引directory[111]位置的bucket。
- 局部位深度(local depth)，这里写作 L ,是桶特有的，每个桶独自保存一个 L。在当前的bucket之下，每个元素的key的低n位都是相同的（。
  - 这里的低是自己定义的，可以前n位也可以是后n位

- **根据global depth  和local depth的关系，插入时的行为不同：**
  - 对于一个bucket来说，**如果当前的global depth等于local depth，那说明这个bucket只有一个指针指向它。**
    - 如果是这个情况下满了，目录加倍，分裂成两个bucket，GlobalDepth++,localdepth++
  - 如果当前的global depth大于local depth，必定不止一个指针指向它。
    - 如果是这个情况下满了，目录不会加倍,分裂成两个bucket，localdepth++
  - 计算当前bucket有几个指针指向他的公式是$2^{globalDepth-localDepth}$（对于实现好像没什么用）

find和remove很简单，这里只涉及`Inset(k,v)`。

> 复习一下移位运算，$1<<num$,1左移num位，$num<<1$,num左移一位

首先我们初始时，只有一个桶，目录深度也是0.并且value没有意义，所以我们这里讨论的都是hash(key)或者索引

![image-20231214174549089](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231214174549089.png)

此时我们插入a,b,即`Insert(a,v1)`,`Insert(b,v2)`

>假设，Hash(a)=0010，Hash(b)=1100，
>
>那么此时的Index中mask =0，Index (a)=0&0010=0,Index(b)=1&1100=0，所以都会索引到B1这个桶

![image-20231214174835084](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231214174835084.png)

我们继续插入,`Insert(c,v3)`,此时还是索引到B1（因为G还是0），但是此时就会发现B1满了

>Hash(c)=1111，由于此时mask=0,索引还是索引到0

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231214175757569.png" alt="image-20231214175757569" style="zoom:80%;" />

此时就需要扩容，我们根据上面的逻辑**，此时G和L相等，所以目录加倍，分裂成两个bucket，GlobalDepth++,localdepth++**

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231214175624271.png" alt="image-20231214175624271" style="zoom: 80%;" />



首先是目录扩容，扩容后，**目录索引的bucket关系需要保留，具体做法就是复制原有的dir到新增的那一部分即可**

> 为什么扩容时原来的i+capacity?因为indexof中，我们多取了一位，所以我们要把多一位的那个地方也要存过去，保证新计算的index能正确查到值。
>
> 这里实际上是在新增的capacity中，映射了原有的过去，为什么?
>
> 假设hash(a)=0111, 如果 取一位，indexof得到索引就是1，取两位indexof得到是11,而11=1+01，正好是上一次的索引+capacity。
>
> 如果是hash(b)=0101,如果 取一位，indexof得到索引就是1，取两位indexof得到是01,但是我们让11也指向原来的桶了？这样会有错吗？
>
> 其实不会，我们只要保证新增索引位后，索引变了的也要能正常访问即可。
>
> 因为新增位数后，索引不变的，他就算指向了一个新桶，没影响啊，因为查询时会返回false，不影响正确性！

```C++
if(target_bucket->GetDepth() == GetGlobalDepthInternal()){
      global_depth_++;
      int capacity = dir_.size();
      dir_.resize(capacity<<1);//翻倍大小
      for(int i=0;i<capacity;i++){
        dir_[i+capacity]=dir_[i];//复制原有的到新增的dir_中
      }
    }
```

分裂其实就是按照索引，把这个满了的bucket给他重新索引一下

```C++
    int mask = 1<<target_bucket->GetDepth();
    auto bucket_0 = std::make_shared<Bucket>(bucket_size_, target_bucket->GetDepth() + 1);
    auto bucket_1 = std::make_shared<Bucket>(bucket_size_, target_bucket->GetDepth() + 1);

    for(const auto & item :target_bucket->GetItems()){//将原来的满了的bucket的item分配到两个新桶里
      size_t hash_key = std::hash<K>()(item.first);
      // int mask = (1 << global_depth_) - 1;
      //  return std::hash<K>()(key) & mask;//截取前glocalth二进制位
      if((hash_key&mask)!=0U){
        bucket_1->Insert(item.first,item.second);
      }else{
        bucket_0->Insert(item.first,item.second);
      }
    }
//下面给bucket插入新加的hash(c)那条记录
```

> **java go也有类似的思想，进行hash扩容**，比如java差不多就是发现hash表容量到了75%左右就会进行扩容，

#### Linear Hashing

> 用的少，不记录了

这个方法的核心是觉得上面的方面，一次直接扩容，扩容导致的重新hash操作，**会导致比较长的等待时间**，所以应该慢慢的扩容。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211111653483.png" alt="image-20231211111653483" style="zoom:50%;" />

#### Conclusion

Hash表好处是不管多少数据基本可以是O(1)的查询速度。

**但是hash表一般不能当数据库索引，因为不能范围查询**

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211111904587.png" alt="image-20231211111904587" style="zoom:50%;" />

### NON-UniQue Keys

hash理论上不准key重复，但是我们知道数据库经常有重复的可以，如果有重复的key怎么办？

有两种方法：

- 第一种是把相同key的value的值用链表给链接起来
- 第二种是存的时候把key存上，存key-value当value

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231211103240074.png" alt="image-20231211103240074" style="zoom:50%;" />