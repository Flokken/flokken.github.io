---
title: lab2-raft
date: 2023-11-16
tags: 
  - null
categories: 
  - 大数据
  - Mit6.824
---

> 参考：
>
> 课程中的包括架构和锁的建议： [locking](http://nil.csail.mit.edu/6.824/2022/labs/raft-locking.txt) and [structure](http://nil.csail.mit.edu/6.824/2022/labs/raft-structure.txt) (重要，比如什么情况加锁，释放锁，如果实现election time out等等)
>
> GO race竞争检测的介绍[`-race` flag](https://go.dev/blog/race-detector).
>
> [Raft论文 (Extended Version)](http://nil.csail.mit.edu/6.824/2022/papers/raft-extended.pdf)
>
> [MIT 6.824 分布式系统](https://www.zhihu.com/column/c_1294335950039019520)

Mit的课程的确非常硬核，并且有很多细节值得思考和学习，很后悔没有早点去学习mit的课程，不然我不会这么垃圾

## 准备工作

**学习或者复习一下`Raft`**

1. **[官网简单介绍](https://link.zhihu.com/?target=https%3A//raft.github.io/)**，只需要看到`Raft Visualization`标题之前。
2. **[一个很棒的可视化](https://link.zhihu.com/?target=http%3A//thesecretlivesofdata.com/raft/)**，慢慢把所有动画放完（这个真的很不错）。
3. **[Raft论文 (Extended Version)](http://nil.csail.mit.edu/6.824/2022/papers/raft-extended.pdf)**主要看`Figure 2`和`Section 5`。
4. [助教的guidance](https://thesquareplanet.com/blog/students-guide-to-raft/) （很重要，涉及很多细节的提示点，比如`nextIndex`,`matchIndex`的含义等等）。

**看看[lab2页面](http://nil.csail.mit.edu/6.824/2022/labs/lab-raft.html)的任务指引**

- `task description`
- `skeleton code`在`src/raft/raft.go`,src/raft下的其它文件都是为**测试**服务的，测试主要流程在test_test.go。

## Part-2A

`Lab 2A`要求我们实现`leader election`。

- 主要编程指引在**[Raft论文](https://link.zhihu.com/?target=https%3A//pdos.csail.mit.edu/6.824/papers/raft-extended.pdf)**的`Figure 2`中，必须按照它的逻辑严格执行，不要自己乱写

经验：

- 请理解清楚raft再开始写，要定义什么方法，方法的逻辑是什么样的，都要想清楚

**tips:**

- 在lab2A里没有涉及到对日志的处理，是简化版的`leader election`
- **死锁**：解决死锁问题最好的方法当然是不要让他出现。确保每次加锁的顺序一直，对于锁A和锁B，要么在所有情况下都是先A后B，要么都是先B后A
- 在一些异步发送gorutine的场景下，使用了`Go.sync.Cond()`来实现互斥的操作，这部分语法介绍可以参考[深入理解Go语言中的sync.Cond](https://zhuanlan.zhihu.com/p/615592097)
  - 调用`wait`之前，需要获取锁
  - sync.Cond 底层实际上维护了一个通知队列（阻塞队列）


**测试内容**

- `InitialElection`测试启动后Raft集群是否能够选出一个`leader`，并检查在网络稳定的情况，也就是不应该发生心跳信号等待超时的情况下，是否能保持原来的`leader`和`term`状态不变。
- `ReElection`测试在上一个测试的基础上，检查发生`leader`离线情况的行为。先等待集群产生一个`leader`，然后让这个`leader`离线，检查集群能否再产生一个`leader`。若能，令原来的`leader`上线，检查`leader`不应该发生变化，因为后来的`leader`的`term`大于原来的`leader`。如果满足要求，令一个`leader`和一个`follower`离线，检查此时集群不应该再产生新`leader`，因为超过半数的服务器离线了。
- `ManyElections`测试是上一个测试的现实版本。每次随机令2个服务器离线，检查集群状态是否符合要求，重复10次（这里可以改大一点，因为通过10次可能只是运气好）

> [Lab2A 代码](https://gitee.com/flokken/mit6.824/tree/lab1/)

### 数据结构

这里记录一下，也方便之后复习

首先是`raft peer`,我们自己加了一个计时器相关变量，以及上一次接受到心跳的时间，来帮助我们实现`raft peer`的超时进入选举

```go
type Raft struct {
	mu        sync.Mutex          // Lock to protect shared access to this peer's state
	peers     []*labrpc.ClientEnd // RPC end points of all peers
	persister *Persister          // Object to hold this peer's persisted state
	me        int                 // this peer's index into peers[]
	dead      int32               // set by Kill()
	state *RaftState
	//发送心跳用到
	lastAppendEntriesTime time.Time
	//计时器
	electionTimer bool
	electionTimerMutex sync.Mutex

```

还有就是两个RPC,这里注意，**RPC的包的字段都必须大写,因为大写开头的意味着可导出，而RPC的字段显然是要给其他包用的，都得大写**

在Lab2A中，跟日志有关的我们都暂时不用管

`RequestVote`

```go
type RequestVoteArgs struct {
	Term int
	CandidateId int //candidate requesting vote
    //lab2用不到下面两个，下面两个分别是日志的最后一条的索引和对应任期
	LastLogIndex int //index of candidate’s last log entry 
	LastLogTerm int //term of candidate’s last log entry
}
type RequestVoteReply struct {
	Term int
	VoteGranted bool  // true means candidate received vote
}
```

`AppendEntries`

```go
type AppendEntriesArgs struct {
	Term int
	LeaderId int
	PrevLogIndex int	//prev preceding entry index,紧邻新日志条目之前的日志条目的索引.注意prev是上一个的意思。
	//举例：当前要处理的第i条日志，那么这里发送的是i-1条日志的索引,也就是他的上一条
	PrevLogTerm int//prev precceding entry term,当然这里指的也是上一条日志的任期
	Entries []LogEntry
	LeaderCommit int//当前leader记录的已经批准的日志目录
}
type AppendEntriesReply struct {
	Term int
	Success bool
	ConflictTerm int
	//第一个和传来的心跳冲突的日志的索引的之前一个位置的索引
	ConflictTermPrevIndex int
}
```

**waitTime**

在raft中，我们有`election timeout`,论文里给的范围是`150ms-300ms`,这里我们可以稍微缩小一点，因为测试要求我们5s之内选出leader。而且我们不能使用一样的时间，因为这很容易导致`split vote`，也就是同时出现几个candidate，导致一直选不出leader。具体来说随机时间可以这么搞

```go
rand.Seed(time.Now().UnixNano())
func getWaitTime(randomMax int ,unitMs int) time.Duration {
	unit := rand.Intn(randomMax)
	//(次数，单元时间/ms)
	// 生成随机等待时间，比如选举时间，
	return time.Duration(unitMs*unit) * time.Millisecond
}
```

### election 

> Tips:我们统计选票是需要等所有follower返回结果，那我们go语言中有【条件变量Cond】，为`sync.Cond`，可以实现同步操作
>
> 这里强烈建议去看上面介绍的动画演示

这里假设有n个节点。

流程

- 每个`raft peer`都是follower状态，经过一段随机时间等待后，其中一个先进入`candidate`状态，并发送`RequestVote`	
  - candidate会先投给自己,并且term++
- 其余`raft peer`收到后立刻重置计时器，并投票，candidate收到超过>n/2-1的票数即可变为`leader`（因为自己投了一票）

选举中比较麻烦的就是怎么处理`Election timeout`以及重置选举超时，这里根据课前资料，做一下整理

#### **waitTime**

在raft中，我们有`election timeout`,论文里给的范围是`150ms-300ms`,这里我们可以稍微缩小一点，因为测试要求我们5s之内选出leader。而且我们不能使用一样的时间，因为这很容易导致`split vote`，也就是同时出现几个candidate，导致一直选不出leader。具体来说随机时间可以这么搞

```go
rand.Seed(time.Now().UnixNano())
func getWaitTime(randomMax int ,unitMs int) time.Duration {
	unit := rand.Intn(randomMax)
	//(次数，单元时间/ms)
	// 生成随机等待时间，比如选举时间，
	return time.Duration(unitMs*unit) * time.Millisecond
}
```

#### **计时器**

如何在收到心跳时，重置选举时间呢？这里选择参考资料`structure`里提到的，在raft里维护一个变量`  lastAppendEntriesTime time.Time`,记录上一次收到心跳的时间，并且利用上面的waittime来实现随机范围内的等待时间

**需要重置计时器的地方**

- `raft peer`收到了`appendEntries`
- `raft peer`开始选举
- 收到其他服务器的`Request Vote`

`RequestVote`

> lab2A只看term是否为最新的即可

```go
//该函数是投票时，term相关的逻辑,会根据结果修改rf server状态
func (rf*Raft) requestVoteState( args *RequestVoteArgs, reply *RequestVoteReply) bool {

	//这里应该要考虑日志和term，先只考虑term，因为partA好像没日志？
	if(args.Term > rf.state.currentTerm){//如果RPC传来的信息中term比当前server的大,那么该server投票给这个server
		//更新本服务器
		rf.state.currentTerm = args.Term
		rf.state.votedFor = args.CandidateId
		rf.state.rule = followerState
		Debug(dVote,"S%d vote for S%d at T%d because of term larger than current\n",rf.me,args.CandidateId,args.Term)
		return true

	}
	//reply false if term<rf.currentTerm
	if(args.Term < rf.state.currentTerm){//如果RPC传来的信息中term比当前server的小，直接拒绝
		//reply.VoteGranted = false
		Debug(dVote,"S%d reject vote for S%d at T%d beacause of term smaller than current\n",rf.me,args.CandidateId,args.Term)
		return false
	}
	//执行到这里时，只有两者term相等
	//如果这个server没投票，或者已经投给了这个candidate
	if(rf.state.votedFor == args.CandidateId||rf.state.votedFor == -1){
		rf.state.votedFor = args.CandidateId
		return true
	}
	return false
}
```

### 心跳

raft中只有两种RPC，除了`RequestVote`就是`AppendEntries`,而心跳就是空的`AppendEntries`而已。

注意只有leader能发心跳。

1.如果leader在发送心跳的时候，突然收到一个`term`更大的心跳，那他应该转为`follower`

2.`leader`如果没有收到回复，需要重发，所以也需要一个最大重试次数

```go
//被Leader远程调用的Raft peer的AppendEntries
func (rf *Raft)AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) {
	//先给reply一个默认初始值
	reply.Success = false
	//对state进行写操作，要加写锁
	rf.logRw.Lock()//这里给日志也加个锁
	rf.state.wLock()
	reply.Term = rf.state.currentTerm
	if args.Term > rf.state.currentTerm {
		//大于则更新term,也代表接受自己当follower
		rf.state.currentTerm = args.Term
		rf.state.votedFor = args.LeaderId
		rf.state.rule = followerState
		Debug(dLeader,"current Leader %d encounter larger term %d from %d\n ",args.LeaderId,rf.state.currentTerm,rf.me)
	}

	if args.Term < rf.state.currentTerm {
		//小于直接返回false
		Debug(dLeader,"current Leader %d encounter larger term %d from %d\n ",args.LeaderId,rf.state.currentTerm,rf.me)
		rf.logRw.Unlock()
		rf.state.wUnlock()
		return
	}
	//注意，只要这个方法被调用，说明这个followe收到了心跳，所以计时器清零
	rf.electionTimerMutex.Lock()
	rf.electionTimer = true
	rf.electionTimerMutex.Unlock()

	// TODO：对日志的判断

	reply.Success = true
}

//Leader执行该函数
func (rf * Raft)doSendAppendEntries(){
	now :=time.Now()
	duration := time.Since(rf.lastAppendEntriesTime)
	rf.lastAppendEntriesTime = now
	rf.state.rLock()
	okArray := make([]bool, len(rf.peers))

	for i := 0; i < len(okArray); i++ {
		okArray[i] = false
	}
	sentArray := make([]bool, len(rf.peers))
	recvedArray := make([]bool, len(rf.peers))
	Debug(dLog,"since last time %v nextIndex %v\n", duration, rf.nextIndex)

	for i:=0;i<len(rf.peers);i++{
		if i == rf.me{
			continue
		}
		//如果不再是leader则跳出
		if rf.state.rule!=leaderState{
			rf.state.rUnlock()
			return
		}
		//同样的，发送心跳的过程也不应该阻塞主线程，所以让协程去执行他
		go func(server int, sentArray *[]bool, recvedArray *[]bool){
			rf.logRw.RLock()
			rf.state.rLock()
			args := &AppendEntriesArgs{
				Term: rf.state.currentTerm,
				LeaderId: rf.state.votedFor,
			}
			//注意，锁的定义顺序和解开顺序最好一样，不然会引发很多问题
			rf.logRw.RUnlock()
			rf.state.rUnlock()
			(*sentArray)[server] = true
			reply := &AppendEntriesReply{}
			Debug(dLeader,"Leader %d send to follower %d  %d entries\n",rf.me,server,len(args.Entries))
			ok := rf.sendAppendEntries(server,args,reply)
			Debug(dLeader,"follower %d reply %t\n",server,reply.Success)
			rf.logRw.Lock()
			rf.state.wLock()//注意连着用两个锁的话，解锁的时候也最好保证顺序一样的
        }
    }
}
```

上面只是leader发送心跳，我们对于followrer也需要实现对心跳的检查。如果一段时间没有收到心跳，就要转变为`candidate`

```go
const followerMaxCheck = 30
const followerWaitUnitMs=10
func (rf*Raft)follower() {
	//follower干的事
	//随机睡眠一段时间，并且如果这段时间之后没有收到心跳，转变为选举状态
	Debug(dFollower,"enter follower %d loop\n",rf.me)
	for num :=0;num<followerMaxCheck;num++{
		time.Sleep(time.Duration(followerWaitUnitMs)*time.Millisecond) 
		rf.state.rLock()
		if rf.state.rule != followerState{
			rf.state.rUnlock()
			Debug(dFollower,"follower %d exit \n",rf.me)
			break
		}
		rf.state.rUnlock()
		rf.electionTimerMutex.Lock()
		if rf.electionTimer == true{
			//如果为true，说明收到了心跳，我们就应该清零计时器
			rf.electionTimer = false
			num =0
			Debug(dTimer,"election timer cleared\n")
		}
		rf.electionTimerMutex.Unlock()
	}
	rf.state.wLock()
	//执行到这里，说明已经超时了，没有接受到心跳，转变为candidate
	if rf.state.rule == followerState{
		rf.state.rule = candidateState
		Debug(dFollower,"Election timeout ,follower %d change to candidate\n",rf.me)
	}
	rf.state.wUnlock()
}
```



## Part-2B

写在前面：

> 由于一开始并没有设计什么框架，对怎么写心里也没个数，代码很难看，并且lab2B始终有部分过不去，有时候basic aggrement都过不去。
>
> 痛定思痛，参考很多大佬的notes，和实现后，决定先写出来大体框架，再接着做！坚持一定迎来最终胜利！
>
> 很多地方都是搬砖大佬的，但我自己现在的水平的确想不到，先模仿，再学习，才能最后有成长把
>
> 参考
>
> https://github.com/SwordHarry/MIT6.824_2021_note/blob/main/lab/lab2B_log_replication.md
>
> https://github.com/OneSizeFitsQuorum/MIT6.824-2021/blob/master/docs/lab2.md#%E6%80%9D%E8%B7%AF

首先我们再把Fig2的图搬过来，认真了解清楚Raft和RPC的结构体里各个属性的作用。

![img](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/116203223-0bbb5680-a76e-11eb-8ccd-4ef3f1006fb3.png)

### **数据结构属性解释**

**Raft的各个属性解释**

**currentTerm**

currentTerm 指当前 peer 的任期，且单调递增，lab2A就应该完成

**votedFor**

指代投票给谁，candiateId，在 lab2A 也是做完了的

**log[]**

日志条目，在 lab2B 中，一条日志条目应该包含以下信息

- Term
- Command

**commitIndex**

已知可以提交的日志条目下标，会和`lastApplied`搭配使用

**lastApplied**

已经提交了的日志条目下标

`commitIndex`和`lastApplied`组成了 follower 的日志提交方式

**nextIndex[]**

- leader 专有，助教的 guide 里也有说明，`nextIndex`为乐观估计，**指代 leader 保留的对应 follower 的下一个需要传输的日志条目**，应该初始化为(lastIndex + 1)。

**matchIndex[]**

- leader 专有，`matchIndex`为悲观/保守估计，应该初始化为 0（或者-1？） ，**指代 leader 已经传输给对应 follower 的日志条目下标，即follower 目前所拥有的的总日志条目**，通常为 nextIndex - 1
- `commitIndex`，`lastApplied`，`nextIndex[]`，`matchIndex[]`共同组成了 leader 的提交规则，并且 leader 总是最先提交的，可以认为 leader 为这个集群的代表，leader 提交后，follower 才会提交

##### AppendEntries

follower 只会在收到`AppendEntries` rpc 请求后执行提交，图2 说明得很清楚，流程如下：

1. 若 term < currentTerm，返回 false
2. 若 `prevLogIndex`处的日志条目不匹配，如找不到，term不对等，返回 false
3. 强制覆盖写：若 leader 发来的日志条目和已存在的日志条目不匹配，则截断不匹配的下标，并拼接 leader 的剩余日志
4. 若 `leaderCommit > commitIndex`，`commitIndex = min(leaderCommit, 最后一个日志条目下标)`

这里比较绕的是强制覆盖写，尽量不要创造晦涩难懂的代码，需要分类讨论

##### follower 提交规则：[lastApplied, commitIndex]滑动窗口

可以将`[lastApplied, commitIndex]`想象成**滑动窗口**，更新了`commitIndex`后，将从 `log[lastApplied -> commitIndex]`制造出`ApplyMsg`，一直提交到`lastApplied == commitIndex`，之后`commitIndex `等待 leader 通知再次更新，再次导致`commitIndex > lastApplied`，然后再来一次提交规则

所以，这个滑动窗口的规则可以用一个 goroutine 持续监听，一旦发现`commitIndex > lastApplied`，开始并发执行提交

> 并且 applyCh <- ApplyMsg 时不要占用锁，lab2B 可以过，在 lab2D 时将可能导致死锁

follower 的 `commitIndex` 是 leader 进行通知更新的，那么 leader 的 `commitIndex` 怎么更新？

答：`matchIndex[]`

## Part-2C



## Part-2D