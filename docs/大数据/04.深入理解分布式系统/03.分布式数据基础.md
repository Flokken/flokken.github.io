---
title: 分布式数据基础
date: 2023-06-06
tags: 
  - 深入理解分布式系统
categories: 
  - 大数据
  - 深入理解分布式系统
---

单机系统性能有限，为了提升可用性和性能，运维人员决定增加一个数据库，两个数据库一起分担流量，例如最常见的主从数据库，一个数据库处理写请求，另一个数据处理读请求，同时处理写请求的数据库会将数据同步给读数据库。就这样，单机系统就买迈向了分布式架构。**主从系统时分布式中常见的架构。**

## 分区

分布式系统带来的好处就是实现了可拓展性，使我们能够存储和处理单台机器所容纳的大得多的数据库。

分区指的是将数据集分成多个小的数据集，并且将这些数据集分别存储到分布式系统的各个节点上。

分区分为垂直分区和水平分区

>https://learn.microsoft.com/zh-cn/azure/architecture/best-practices/data-partitioning

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605102250580.png" style="zoom:70%">

<center> 水平分区</center>

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605102426663.png" style="zoom:70%">



<center> 垂直分区</center>

- 垂直分区是对表的列进行拆分（注意显然都会保留主键），减小了表的宽度。**注意，列式数据库可以看做垂直分区的数据库。**不过显然的，表的宽度有限，因此分区数有限。
- 水平分区是把不同行放到不同表里，由于所有的列都还在，所以表的特性依然可以保留。**水平分区也叫分片**

> 列式数据库（Column-Oriented DBMS）也叫列存数据库，主要适用于批量数据处理和即时查询。一般来说，行式数据库适用于联机事务处理（OLTP）这类频繁处理事务的场景，列式数据库更适用于联机分析处理（OLAP）这类在海量数据中进行复杂查询的场景

### 水平分区算法

#### 范围分区

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605111823181.png" style="zoom:90%">

指根据指定的关键字将数据集拆分为若干连续的范围，每个范围存储到一个单独的节点上，**用来分区的关键字也叫分区键**。

优点：能够使用分区的关键字范围查询，实现简单

缺点：不能使用分区以外的关键字范围查询

> 使用该方法的有Bigtable，HBase，PingCAPKTY

#### 哈希分区

根据指定的关键字经过一个hash函数计算，根据计算到的值决定该数据集分区

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605111902419.png" style="zoom:90%">

优点：数据分布更均匀，能够在一定程度上避免热点问题

缺点：在删除或添加节点时，由于每个节点都需要一个相应hash值，所以增加节点需要修改hash函数。这导致许多数据都要重新映射，引起数据大规模移动。**并且不能进行范围查询（除非存储额外数据）**

#### 一致性分区

一致性哈希（Consistent Hashing），在分布式存储系统中用来**缓解哈希分区增加或删除节点时引起的大规模数据移动问题。**

一致性哈希算法将整个哈希值组织成-个抽象的圆环称为哈希环（Hashing Ring）。

哈希 函数的输出值一般在0到INT_MAX（通常为2^32-1）之间,这些输出值可以均匀地映射到哈希环边上。

##### **举个例子**

假设哈希函数hash()的输出值[0,11],那么整个哈希环 看起来如:

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605113334988.png" style="zoom:90%">

假设系统中有三个节点N1、N2和N3,  **系统管理员可以通过机器名称或IP地址将节点映射到环上**，假设节点分布到哈希环上如：

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605113452074.png" style="zoom:90%">

将需要存储的数据的关键字输入哈希函数,计算出哈希值,根据哈希值将数据映射 到哈希环上。假设此时要存储三个键值对数据,它们的关键字分别为a、b和c,假设经过哈希 函数计算后的哈希值分别为1,5,9。并且，**这些节点按照顺时针遇到的第一个节点来确定分区**

![image-20230605113847098](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605113847098.png)

关键字a顺时针方向遇到的第一个节点是N1，所以a存储 在节点N1上； 同理,关键字b存储在节点N2上； 关键字c存储在节点N3上

##### 添加节点

假设集群此时要添加一个节点N4， 并添加到所示的哈希环位置，那么按照顺时针计算的方法，原本存储到节点 N2上的关键字a将转移到N4上，其他数据保持不动

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605114218575.png" style="zoom:90%">



可见，相比于普通的哈希分区添加或删除节点时会导致大量映射失效，—致性哈希很好地处理了这种情况。对于添加—台服务器这种情况。受影响的仅仅是新节点在哈希环上与相邻的另一个节点之间的数据，其他数据并不会受到影响。只有节点N2上的一部分数据会迁移到节点N4，而节点N1和N3上的数据不需要进行迁移

**此外—致性哈希也不需要修改哈希函数，直接将新节点指定到哈希环上的某 个位置即可。相比简单的哈希分区一致性，哈希有着更好的可扩展性和可管理性**

一致性哈希仍然有明显的缺点,当系统节点太少时’还是容易产生数据分布不均的 问题。**另外,一个较为严重的缺点是：当一个节点发生异常需要下线时,该节点的数据全部转 移到顺时针方向的节点上，从而导致顺时针方向节点存储大量数据’大量负载会倾斜到该节点。这个缺点可以用虚拟节点解决**

##### 虚拟节点

虚拟节点并不是真实的物理服务器，虚拟节点是实际节点在哈希环中的副本。一个物理节点不再只对应哈希环上一个点，而是对应多个节点。

我们假设—个物理节点要映射到哈希环中的三个点，则hash图如下，并且显然，虚拟节点越多数据分布就越均匀。当节点发生异常被迫下线，数据会分摊给其余的节点，避免某个节点独自承担存储和处理数据的压力。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605153500519.png" style="zoom:90%">

**’在不额外存储数据的情况下,一致性哈希依然无法高效地进行范围查询·任何范围 查询都会发送到多个节点上。**

### 分区挑战

- 查询。在一个垂直分区的数据集中，将不同表的数据组合起来的查询（即join查询）会非常低效，因为这些请求可能需要访问多个节点的数据.

  > 水平分区可以避免上面的麻烦。因为每一 行的所有数据都位于同一个节点中。但是对于需要查询许多行的范围查询来说,可能这些行位于不同的节点。请求也会访问多个节点。

- 实现事务。数据存储在单台机器上时实现事务的难度尚可，但在分布 式系统中想要实现事务就比较困难

## 复制

分区将数据和负载分配到多个节点,提高了系统的可扩展性和 能。**为了提高可用性，除了分区还需要复制（Replication）**。**复制是指将同一份数据冗余存储在 多个节点上,节点间通过网络来同步数据，使之保持一致**。**一个存储了复制数据的节点称为副本(Replica)**，复制可以和分区一起使用

**复制的好处：**

- 增强数据的可用性和安全性。**通过复制技术，将数据冗余存储,即使系统部分节点发生故障。系统也能继续工作**。有时用户甚至没有发现系统部分节点出现过问题。
- 减少往返时间。数据从客户端发起请求，通过网络传输到服务端，服务端处理完之后，数据也需要重走一遍来路，返回到客户端**。这一段 时间被称为往返时间（Round-Trip Time,RTT）**。往返时间是无法避免的。**通过复制技术把数据 存储到各个数据中心,**可以将全国各地甚至全球不同用户的请求**重定向到离用户位置更近的副本，减少往返时间,提升响应速度**
- 增加吞吐量。—台服务器能够处理的请求数存在物理上限，这种情况下复制出同样的几台服务器，可以提供更多处理读写请求的机器，统一的处理性能能够成倍增长。

**缺点：**

给系统带来复杂性。复制意味着系统中的每份数据会有多个副本，这些副本在每次更新时必须—起更新或相互同步数据。由于网络延迟的存在，可能带来一些其他问题。比如数据不一致

### 单主复制

**单主复制也叫主从复制或主从同步**。即指定系统中的一个副本为主节点（有Leader、Master 或Primary等多种叫法）。**客户端的写请求必须发送到主节点**，其余的副本称为从节点（对应 Follower、Slave或Backup），**从节点只能处理读请求,并从主节点同步最新的数据。**

主节点收到写请求时，除了将数据写入本地存储，还要负责将这次数据变更同步给所有节点， 以确保所有的副本保持数据一致。**数据变更同步具体是同步操作日志还是转发请求，不同的系统有着不同的实现。**

根据系统以何种方式同步数据，又可以将单主复制分为三类，分别为同步复制、异步复制 和半同步复制。

**同步复制**：同步复制中的主节点执行完一个写请求（或一个事务）后，必须等待所有的从节点都执行完毕，并收到确认信息后，才可以回复客户端写入成功。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605160653414.png" style="zoom:90%">

> 这个图从上到下的箭头代表时间顺序
>
> 同步复制保证所有节点写完再返回client，这样client无论从哪个副本读，都能读到刚才写入数据。并且这样还可以提升数据可用性，**就算主节点写完后立即宕机，这次写入的数据也不会轻易丢失。**
>
> 缺点是因为主节点必须等等所有副本写入完成，写请求性能必然受到影响。

**异步复制**：主节点执行完写请求后，会立即将结果返回给客户端，无须等待其他副本是否写入完成

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605161146458.png" style="zoom:90%">

> 由于主节点不需要再等待从节点写入完成，异步复制不会影响写请求的性能。**但异步复制会潜在影响副本数据的一致性和持久性。**
>
> 例如，如果客户端收到写请求完成的响应后，立即去某个从节点读取数据，而此时写入操作还未同步到该副本。那么客户端会发现自己读不到刚才 明明写入成功的数据。
>
> 如果主节点 在本地写入完成后立即岩机，那么写操作可能并没有同步到从节点上，如果此时强行将从节点 提升为主节点（这是主节点宕机后的一种处理策略，就是再从里面节点里找一个新的节点当主节点），那么新的主节点上的数据并不完整,一个明明已经完成的写操作可能会丢失

**半同步复制（Semisynchronous Replication）**：是介于同步复制和异步复制之间的一种复制机制。主节点只需要等待至少一个从节点同步写操作并返回完成信息即可。这等价于,有一个从节点是同步复制，其余的从节点则是异步复制。**保证至少有两个节点拥有最新的数据副本，该节点能随时接替主节点的工作。**

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605162138326.png" style="zoom:90%">

#### 优缺点分析

缺点：

1. 面对大量写请求工作负载时系统很难进行扩展因为系统只有一个主节点，**写请求的性 能瓶颈由单个节点（主节点）决定**
2. 当主节点岩机时，从节点提升为主节点不是即时的,可能会造成一些停机时间，甚至产 生错误

对第二点可以展开分析。

分布式系统执行故障切换有两种方法:**手动切换和自动切换。**

- 对于手动切换的情况，一般由运维人员根据数据完整性来选择新的主节点，这是最安全的方法，但由于需要人工介入,可能导致**较长的停机时间**。
- 自动切换, 即从节点通过心跳超时检测到主节点已经岩机，然后尝试成为整个集群的主节点。这种方式更快，不需要人工介入，能够自动容错，但也相对危险

自动切换危险举例：倘若两个从节点同时检测到主节点失效, 或者网络分区导致从节点认为主节点失效，但其实主节点仍然正常工作，这两种情况都会导致集群产生两个主节点。这种情况称为（脑裂（Split Brain），**两个主节点都在处理写请求，可能造成数据损坏之类的灾难性后果**。

自动切换最重要的问题是如何使系统中只有一个主节点’同时在主节点出现故障时自动、 正确地选举出新主节点? **该问题被称为领导者选举问题**

从节点故障恢复：

**通过日志偏移量与主节点继续同步数据，**如果从节点故障不可恢复,则 可以换上新的从节点重新复制主节点的数据

> PostgreSQL和MySQL都支持单主复制，也都支持同步、异步或半同步复制。
>
> 主节点和从节点一般都会对一写关键信息，比如写操作等记录到日志，用于恢复数据。

### 多主复制

单 主复制只有一个主节点，在写性能和可扩展性方面有着一定的局限性。对于写请求负载要求严 格的系统，一个自然的想法是增加多个主节点来分担写请求的负载。**这种由多个节点充当主节 点的数据复制方式称为多主复制**

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605165157287.png" style="zoom:90%">

多主复制和单主复制的显著区别是, 由于多主复制不止一个节点处理写请求，**且网络存在延迟，这就意味着节点可能会对某些请求的正确顺序产生分歧**,导致多个节点上的数据不一致， **这种现象简称为数据冲突。**如上图中，由于写操作X=1同步延迟，导致最后主节点1和从节点的X值为3，而主节点2上X的值为1，**造成了数据不一致（数据冲突）。**

最好的解决办法就是避免数据冲突，例如，特定账号总是交给特定主节点来处理，可以通过-个哈希函数来将特定账 户的所有请求路由到相同的主节点上，这样可以避免同一份数据在多个节点上更新。

有时候冲突无法避免，此时可以

- **由客户端解决冲突**，这种方法的具体解决方案是：客户端下次读取系统中冲突数据 的时候将冲突的数据全部返回给客户端。**客户端选择合适的数据并返回给存储系统，存储系统以此数据作为最终确认的数据，覆盖有冲突的数据。**一个典型的例子是购物车应用购物 车应用，解决冲突的逻辑是保留购物车中所有冲突的商品,并全部返回给用户。**用户看到购物车 里出现了被删除的物品或重复的物品，会重新选择购物车里的商品数量然后将此数据重新写 入存储系统 ，以此解决冲突**。
- 因果关系跟踪。**系统使用一种算法来跟踪不同请求之间的因果关系,并以此判断请求 的先后顺序。**举个例子，当写请求A和写请求B之间发生冲突时，系统尝试确认一个请求是另 一个请求的原因。更具体的,假设写请求A是一个发帖操作, 写请求B是一个对应的回帖操作。由于先有发帖操作才会产生回帖操作，那么写请求B必然是在写请求A之后发生的。
- 最后写入胜利（LWW，Last Write Wins）。让系统中的每个节点为 每个写入请求标记上唯—时间戳或唯一自增ID，当冲突发生时，系统选择具有最新时间戳或最 新ID版本的数据，并丢弃其他写入的数据。但分布式系统中，很难有统一的时间概念，因为可能导致一些错误。

#### **优缺点分析**

优点:

- 增加主节点的容错性。
- 可以在多个节点上执行写请求，**分担写负载的压力**。
- 应用程序可以将写请求路由到不同的主节点，通常来说会路由到地理位置最近的节点, 以减少往返时间,**提升写请求的响应速度**

缺点：

它的复杂性，由于可以在多个节点上执行写操作，可能经常产生 数据冲突。**由于多主复制带来的复杂性远超它的好处,因此很少会在单个数据中心使用多主复制来构 建分布式系统。**

### 无主复制

> 完全没有主节点，称为无主复制’尽管无主复制技术，在几十年前就出现了， 但直到亚马逊发布了Dynamo架构的论文，并在其中使用了无主复制,才让该技术重新引起广 泛关注。鉴于Dynamo的大获成功，无主复制变得流行起来,成为大家的学习对象并启发了其他许多NoSQL数据库实现比如Apache Cassandra° ，Riak，无主复制有时也叫Dynamo架构（Dynamo-Style）

虽然但是，亚马逊云计算服务（AWS）提供一个名为Amazon DynamoDB的服务，但Dynamo 架构是基于无主复制的，而Amazon DynamoDB使用单主同步复制架构。

无主复制的**基本思想**是，客户端不仅向一个节点发送写请求，而是将请求发送到多个节点，在某些情况下甚至会发送给所有节点。

![image-20230605170751594](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605170751594.png)

客户端将写请求并发地发送给几个节点后，一旦得到其中一些节点的确认响应（即将讨论具体需要多少个节点的确认信息）,就认为这次写成功了’然后继续发送下一个请求

> 无主复制有着不同的协调请求方式,，一种是客户端直接将写操作发送到多个副本。
>
> 另一种是 在节点中选出一个协调节点，客户端将请求发送到协调节点（感觉还是有点像主从？），再由协调节点代表客户端将写操作转发到多个副本，经过多个副本确认后再由协调节点响应客户端。
>
> 与基于领导者的复制不同， **无主复制不强制写操作的顺序**

**无主复制最大的好处是可以轻松容忍节点障碍。**无主复制直接去掉了领导，**只要能够满足写入数量的节点可用，系统仍然被认为是正常运行的**

写入多个节点最容易出现的问题是: 冲突更多了。如果写请求在节点1和节点3上成功。但在节点2上失败了,那么此时分布式存储系统中 **有两个节点上存储了新的值,但有—个节点存储了旧的值。造成数据不一致**

![image-20230605171622174](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605171622174.png)

> 可以让客户端不止会从一个节点读取数据，读请求也会同时发送给多个节点，然后获取节点上的数据和数据的版本号，客户端可以根据所有响应中的版本 号决定应该使用哪个值’应该丢弃哪个值。

Dynamo架构中同时使用了以下两种数据修复方法:

读修复：读修复就是多主复制中提到让客户端负责更新数据，客户端可以检测旧数据，如果他发现节点数据旧的，会发送新的数据过去。

反熵过程：）·反墒过程会新建一个后台进程来修复数据,该进 程找出错误的数据，并从存储最新的数据的节点中将数据复制到错误的节点。**和基于领导者的 复制不同,反嫡过程不保证写操作的顺序，只保证最后结果一样**

#### 基于Quorum的数据冗余机制

Quorum（法定人数）机制是分布式系统中用来保证数据冗余和最终一致性的一种算法。

在无助复制中，Quorum机制用于多副本数据的一致性维护，即前面提到的客户端要想一些节点发送读写请求，**Quorum机制用于确定到底要多少节点才足够，以及如果我们增加或减少读写请求的节点数量，系统会发生怎样的变化。**

> 详细解释看这个https://zhuanlan.zhihu.com/p/61896391

### CAP定理

CAP定理就是—个分布式系统特性的高度抽象。总结了各个特性之间的冲突，分区和复制 等技术既会带来好处，也会带来问题, CAP定理对这类数据系统的特性做了一个重要的总结。

CAP定理指出在一个异步网络环境中,对于一个分布式读写存储（Read-Write Storege）系 统来说,，**能满足以下三项中的两项，而不可能满足全部三项:**

- 一致性
- 可用性
- 分区容错性

> 详细解释可以看这里：架构设计之「 CAP 定理 」 - 不止思考(奎哥)的文章 - 知乎 https://zhuanlan.zhihu.com/p/59327194

### PACELC 定理

PACELC定理的 主要论点是, CAP定理忽略分布式系统中的延迟影响是一个重大疏忽，**因为延迟在系统运行过 程中时刻存在，而网络分区不会一直存在。**

PACELC定理指出，在分布式系统存在网络分区（P）的情况下，必须在可用性（A）和一致性（C）之间做出选择；否则（Else ，E）系统在没有网络分区且正常运行的情况下，必须在延迟（L）和一致性（C）之间做出选择。

![image-20230605202236297](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605202236297.png)

### BASE

**BASE即基本可用、软状态和最终一致性的首字母缩写**。目的是抓住当时逐渐成型的一些针对高可用性的设计思路’其中的软状态和最终一致性。

主要指存在网络分区的情况’为了高可用性，舍弃强一致性，选择一致性更弱的最终一致性。

虽然网络分区听起来很严重，但其实大部分情况只会持续一小段时间，可能几秒或几分钟

## 一致性模型

什么是一致性？有人会说是CAP定理里面的一致性;有人会提到数据库事务ACID中的一致性；更有甚者会说Paxos或Raft算法是—种分布式—致性算法。通过阅读本书，笔者希望读者能清楚地知道三者是完全不一样的概念，这三 个“一致性”会在本书不同的章节讨论。

首先,需要指出一个错误观点，即把Paxos或Raft称作分布式一致性算法，笔者认为完全是中文翻译导致的错误，它们的英文单词并不一样，为了区分,本书统一把Paxos或Raft称为分布式共识算法。

ACID中的一致性（Consistency）和一致性模型（Consistency Model）中的一致性都是同一个英文单词，但AICD属于数据库领域概念，主要是指数据的一致性没有被破坏, 比如数据库完整性约束（例如主键、外键、触发器、check等约束）等。

而一致性模型指的是，在并发编程中,系统和开发者之间的一种约定，如果开发者遵循某些 规则，那么开发者执行读操作或写操作的结果是可预测的

> 一致性模型与复制有紧密的联系

著名的分布式—致性验证框架Jepsen对一致性模型的分类：

![image-20230605203335407](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605203335407.png)

一致性模型根据可用性可以分为三类’白底矩形中的模型的可用性为不可用（Unavailable），’灰底矩形中的模型的可用性为基本可用（Sticky Available），椭圆中的模型的可用性为高可用（Total Available）：

- 不可用指的是：满足这类—致性模型的系统发生网络分区时，为了保证数据一致性和 正确性，系统会不可用。用CAP定理来解释’就是典型的CP类系统，这类一致性模型包括线性一致性和顺序一致性。
- 基本可用指的是：满足这类一致性模型的系统可以容忍一部分节点发生故障，还未出现故障的节点仍然可用，但前提是客户端不能将请求发送到不可用的副本节点。这类 一致性模型包括因果—致性、PRAM一致性和读你所写一致性。
- 高可用性：满足这类—致性模型的系统可用性是最高的，即使网络发生严重 分区在没有发生故障的节点上，仍然保证可用。这类—致性模型包括读后写—致性、 单调读一致性和单调写一致性。

图中一致性模型中的一致性强度从上到下越来越弱，即最上方的线性一致性是最强的一致性模型

### 线性一致性

线性—致性的非严格定义很简单，即**线性一致性意味着分布式系统的所有操作看起来都是原子的，整个分布式系统看起来好像只有一个节点。**

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605204213336.png" style="zoom:90%">

上图中，客户端A和客户端B同时执行写操作，客户端A执行X=1，B执行X=2，但由于副本 之间同步数据存在延迟，最终导致两个副本的x值不相同。**是一个典型的不满足线性一致性模型。**

根据非严格定义，线性一致性的系统要像单一节点一样工作，并且所有操作是原子的。上述情况变成

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605204720183.png" style="zoom:90%">

如上，系统行为变有序了，系统也从一个不可预测的行为变成了可预测的行为。

线性一致性如何实现？首先介绍论文中相关概念

首先，发生在系统上的所有事件可以建模为一个并发程序的执行历史,简称为历史（History）, 常用H来表示。我们假设系统只有读操作或写操作一个操作可以分为调用（Invocation）和响应（Response）两个事件。**即调用表示读操作或写操作的开始**，响应可以理解为操作结束并返回如ON的状态值，调用一定发生在响应之前’每个调用之后紧跟着相应的响应。**执行历史就是由一系列的调用和响应事件组成的。**

举个最简单的例子,一个写操作如：

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605210634270.png" style="zoom:90%">

图中只有一个客户端A，只有一个Write（1）写操作并用—个线段来表示，即将X这个变量的值更新为1。线段最左端表示调用事件，线段最右端表示响应事件，线段的长度表示 Write（1）写操作实际持续的时间。处于调用事件和响应事件之间的这段时间，无法确认写操作到底发生在哪个具体的时间，**所以客户端读到X≡0或x≡l都认为是合法的。**

如果有多个客户端进行并发操作，其执行情况可以如下所示

![image-20230605211202891](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605211202891.png)

<center> 图两个客户端并发操作</center>

他们各自的执行状况就称为并发情况下的执行历史。

线性一致性的严格定义是：给定一个执行历史，执行历史根据并发操作可以扩展为多个执行历史，**只要从中找到一个合法的顺序历史，那么该执行历史就是线性一致性的**。

并发执行有三种情况如

![image-20230605212626367](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605212626367.png)

- 一个操作明显在另一个操作之前发送’这两个操作是顺序关系
- 两个操作之间有重叠，这两个操作是并发关系·
- 一个操作包含另一个操作’这两个操作也是并发关系

线性一致性有一个非常重要的约束，就是在将执行历史转变成顺序历史的过程中，如果两个操作是顺序关系，那么它们的先后关系必须保持相同；如果两个操作是并发关系，则它们可以按任何顺序排列。

将上面的两个客户端并发操作，可以转换为

![image-20230605213107975](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605213107975.png)

**不过，S1是不合法的，S2才是合法的顺序执行顺序**，因此图两个客户端并发操作满足线性一致性

**拓展**，下面那个执行顺序可以满足线性一致性？（H1满足，H2不满足（不能转成顺序历史））

![image-20230605213418716](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605213418716.png)

**总结**线性—致性主要有两个约束条件：

- 第—，顺序记录中的任何一次读必须读到最近一次写入的数据;
- 第二，顺序记录要跟全局时钟下的顺序一致。

#### 实现

假设有程序如下：

~~~c
int inc_counter(){
    int j = i++;
    return j;
}
~~~

当两个线程并发执行该函数时,i++会执行两次，但可能线程1先执行完，返回，结果是1，线程2再执行完，返回2，所以我们并不能预测返回结果。

为了实现并发编程的线性一致性实现（最常见的编程方法），可以加锁

~~~c
int inc_counter(){
    lock(&lock);
    i++;
    int j=i;
    unlock(&lock);
    return j;
}
~~~

分布式系统还可以通过共识算法实现线性一致性（注意，并不是说实现了共识算法就等于 实现了线性一致性）包括如何选择领导者，如何处理重复的请求，如何确保请求在每个副本上的顺序是一致的

#### 代价

代价最高，并发编程中的同步原语和原子变量都会增加系统开销。不仅如此,分布式系统中的线性一致性最困难的是需要一个全局时钟，而这是很困难的

> 默认情况下,现代CPU在访问内存时不保证线性—致性,这是因为同步指令开销大、速 度慢，并且涉及跨节点CPU缓存失效问题。

### 顺序一致性

顺序一致性同样允许对并发操作历史进行重新排列，**但它的约束比线性—致性要弱**，顺序 一致性只要求同一个客户端（或进程）的操作在排序后保持先后顺序不变，但不同客户端（或 进程）之间的先后顺序是可以任意改变的。

假设有下图的操作![image-20230605215123897](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605215123897.png)

显然无法满足线性一致性（最后的结果是1，但应该读3），**但是可以满足顺序一致性**，执行历史可以重排为

![image-20230605215212687](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605215212687.png)

顺序一致性和线性一致性的主要区别在于没有全局时间的限制，顺序一致性不要求不同客户端之间操作顺序顺序一致，只关注局部顺序。

> 现代CPU在默认情况下也不保证顺序一致性，因为顺序一致性严格限制程序的执行顺序，现**代编译器和CPU通常都会优化指令的执行顺序’以提升程序性能’实 际执行的指令顺序和程序写的指令顺序可能是不一致的。**

### 因果一致性

因果一致性（Causal Consistency）是—种**比顺序一致性更弱一些的一致性模型，他与顺序一致性一样不依赖于全局操作的顺序。**因果一致性要求，必须以相同的顺序看到因果相关的操作，而没有因果关系的并发操作可以被不同的进程以不同顺序观察到。

最典型的因果关系**就是社交网络中的发帖和评论关系**，根据因果关系：必须先有发帖才能有对于该帖子的评论，所以发帖操作必然在评论操作之前。

> 微信的朋友圈评论就用了因果一致性

### 最终一致性

还有一些应用，它们的操作没有因果关系。允许使用更宽松的一致性模型，例如只要系统最终能够达到一个稳定的状态，在某个阶段系统各节点处理客户端的操作顺序可以不同， 读操作也不需要返回最新的写操作的结果。在最终的状态下，只要不再执行写操作，读操作将 返回相同的、最新的结果。这就是最终一致性（Eventual Consistency）模型。

最终—致性是一个比较笼统的说法，所以并没有具体地归为某—类。

### 以客户端为中心的一致性模型

Tanenbaum等人将前面四种一致性模型归为一类，称为以数据为中心的一致性模型，以数据为中心的一致性模型旨在为数据存储系统提供一个系统级别的全局一致性视图。

还有另—类以客户端为中心的一致性模型，这类一致性模型从客户端的角度来观察分布式系统，不再从系统的角度考虑每个副本的数据是否一致，**是考虑客户端的读写请求的结果，从而推断出系统的—致性**。

用—句话来对比就是，以数据为中心的一致性模型常常考虑多个客户端时的系统状态，**而以客户端为中心的—致性模型聚焦于单个客户端观察到的系统状态**

> 1 Thnenbaum,Andrew;MaartenⅥnSteen（2007）.Distributed systems＂。

**单调读（Monotonic Read）一致性模型模型：**一种简单的以客户端为中心的一致性模型，单调读一致性必须满足: 如果客户端读到关键字x的值为v，那么该客户端对于x的任何后续的读操作必须返回v或比V更新的值，**即保证客户端不会读到旧的值**。

**单调写（Monotonic Write）一致性必须满足:** 同一个客户端（或进程）的写操作在所有副 本上都以同样的顺序执行，即保证客户端的写操作是串行的。例如，客户端先执行写操作×＝6 再执行写操作x＝1，如果另—个客户端不停地读x的值，那么会读到x的值先为0再为1，不会先读到l再读到0。

**读你所写（Read Your Write）**一致性也称为读己之写（Read My Write），**要求：**当写操作完成后，在同一副本或其他副本上的读操作必须能够读到写入的值，注意，读你所写一致性必须是单个客户端（进程）。下图是一个违反的例子

![image-20230605221759688](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605221759688.png)

> 客户端A执行写操作x＝1,并且副本返回了成功,但是当客户端A从另一个副本读取数据时，由于数据同步延迟读到旧的数据0，这就违反了读你所写一致性

**还有FIFO一致性，读后写一致性等。**

## 隔离级别

常见的有

- 串行化（Serializability）
- 可重复读（Repeatable Read）
- 快照隔离（Snapshot）
- 读已提交（Read Committed）
- 读未提交（Read Uncommitted）

其层次关系如

![image-20230605222321529](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230605222321529.png)

同样的，椭圆底的为高可用，矩形的为不可用，越强的隔离能防止越多的异常，但是性能也会越低

### 事务相关的异常

事务的基本用法，通常用BEGIN或者START TRANSACTION 开始一个事务，然后执行一系利操作，最后执行commit语句提交事务，所以操作提交。或者执行ROLLBACK操作事务，放弃变更。

**脏写（Dirty Write）指一个事务覆盖了另一个仍在运行中，尚未提交的事务写入的值**。例如，事务A包含两个写[x=1,y=1],事务B包含两个写[x=2,y=2],事务一致性约束是x必须等于y。如果两个事务串行，那么x和y值一直相同。但是并发执行时，执行顺序可能是[x=1,x=2,y=2,B提交,y=1,A提交],这样导致x=2,y=1,如下图**并且破坏了数据完整性约束，使得事务无法正确回滚。**

![image-20230606090149800](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230606090149800.png)

**脏读（Dirty Read）指一个是事务读到了另一个尚未提交的事务写入的值。**如下图，事务B读到了事务A写入的x值为1，可是之后事务A却回滚了该操作。还有就是银行转账，事务A从账户1转账到账户2，如果事务B能在事务运行的过程中读到账户1和账户2的余额，就会发现账户1扣掉了钱但账户2还没收到钱。

![image-20230606090212184](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230606090212184.png)

**不可重复读（Non-Repeatable Read）**也叫模糊读，指的是一个事务查询一个值两次，但两次返回查询值不一样。

与脏读区别：脏读是事务回滚导致的，而不可重复读读到的是其他事务已经提交的数据。如下图，在事务A提交之前，读到两个不同的值

> 不可重复读可能导致的问题是，如果第一次读取的值用于一些条件判断，而第二次读的值用来更新某个数据，那么会得到意料之外的结果。

![image-20230606091318444](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230606091318444.png)

**幻读（Phantom Read）：指当一个事务进行条件查询时，另一个事务在中间插入或删除匹配该条件的数据，此时再去读，就会发送幻读**。也就是说，读到的数据项变多或者变少了。

![image-20230606092005335](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230606092005335.png)

更新丢失（Lost Update）指的是两个事务同时读取一个值，然后都尝试更新这个值为不同的值，此时就会发送生更新丢失。结果是，两个更新最终只有一个更新生效，**但是另一个没有被执行的更新没有被告知更新没有生效。**

![image-20230606093138252](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230606093138252.png)

读偏斜（Read Skew）是指读到了数据一致性约束被破坏的数据。**这里的一致性约束通常是业务逻辑层面上的（注意:这里指ACID层面的一致性）**。比如有数据约束X+Y=100,并发事务B一开始读到X的值为50，同时事务A将X和Y的值分别修改为30和70，此时B再读到70，这样事务B看来和为120.

> 上面这个应该算用户自定义完整性约束

![image-20230606093742952](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230606093742952.png)

![image-20230606093751855](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230606093751855.png)

写偏斜（Writ Skew）是指两个并发事务读到了相同的数据集，**但随后各自修改了不相干的数据集，导致数据一致性约束被破坏。**

比如下图，事务A和B一开始都读到X=10且Y=20,满足约束，然后事务A的值修改为70，在事务A看来没有违反数据约束，70+20<100.事务B将Y的值修改为50，在事务B看来也没有违反约束，但最后X=+Y=70+50>100,违反了数据约束。

![image-20230606101610450](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230606101610450.png)

### 隔离级别下存在的问题

串行化是严格的隔离级别，给予锁实现，读操作加读锁，写操作加写锁，直到事务结束才释放。不过性能最差

![image-20230606101656225](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230606101656225.png)

### 一致性模型与隔离级别对比

一致性模型和隔离级别的相同点是，他们本质上都是用来描述系统能够容忍哪些行为，不能容忍哪些异常行为,更严格的—致性模型或隔离级别意味着更少的异常行为,但以降低系统 性能和可用性为代价。

一致性模型和隔离级别的一个主要区别**是一致性模型适用于单个操作对象**，比如单个数 据项或单个变量的读写,该数据可能存在多个副本;**而隔离级别通常涉及多个操作对象**，比如 在并发事务中修改多个数据。

对于最严格一致性模型和隔离级别，线性一致性和串行化，还有一个重要的区别是，线 性—致性提供了实时保证，而串行化则没有
