---
title: Raft算法
date: 2023-09-26
tags: 
  - 深入理解分布式系统
categories: 
  - 大数据
  - 深入理解分布式系统
---

raft算法也是paxos算法的一个变种，但是其被广泛应用，取得极大成功，因此有必要专门学习一下。

> [条分缕析 Raft 算法 (qq.com)](https://mp.weixin.qq.com/s?__biz=MzIwODA2NjIxOA==&mid=2247484140&idx=1&sn=37876b5dda5294ea7f6211f0a3300ea5&chksm=97098129a07e083fe65f8b87c2ec516b630a8f210961038f0091fbcd69468b41edbe193891ee&scene=21#wechat_redirect)
>
> 《深入理解分布式系统》

## 目标

Raft 的目标（或者说是分布式共识算法的目标）是：**保证 log 完全相同地复制到多台服务器上**。

> 当然，复制log是为了实现去实现状态机复制

![图片](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/640)

只要每台服务器的日志相同，那么，在不同服务器上的状态机以相同顺序从日志中执行相同的命令，将会产生相同的结果。

共识算法的工作就是管理这些日志。

## 系统模型

我们假设：

- 服务器可能会宕机、会停止运行过段时间再恢复，但是**非拜占庭的**（即它的行为是非恶意的，不会篡改数据等）；
- 网络通信会中断，消息可能会丢失、延迟或乱序；可能会网络分区；

Raft 是基于 Leader 的共识算法，故主要考虑：

- Leader 正常运行
- Leader 故障，必须选出新的 Leader

优点：只有一个 Leader，简单。

难点：**Leader 发生改变时，可能会使系统处于不一致的状态，因此，下一任 Leader 必须进行清理；**

我们将从 9个部分解释 Raft：

1. Leader 选举；multi-paxos直接用server_id来选，存在日志落后的问题，Raft如何实现leader选举？
2. 正常运行：日志复制（最简单的部分）；
3. Leader 变更时的安全性和一致性（最棘手、最关键的部分，领导者怎么做日志清理工作）；
4. 处理旧 Leader：旧的 Leader 并没有真的下线怎么办（脑裂？）？
5. 客户端交互：实现线性化语义(linearizable semantics)；
6. 配置变更：如何在集群中增加或删除节点；
7. 日志压缩。为例减少磁盘存储空间，同时快速让新节点跟上系统状态，**Raft还会压缩日志生成快照。**
8. 实现线性一致性。
9. 性能优化

## 基本概念

### 服务器状态

服务器在任意时间只能处于以下三种状态之一：

- Leader（领导者）：处理所有客户端请求、日志复制。同一时刻最多只能有一个可行的 Leader；
- Follower（跟随者）：完全被动的（不发送 RPC，只响应收到的 RPC）——大多数服务器在大多数情况下处于此状态；
- Candidate（候选者）：用来选举新的 Leader，处于 Leader 和 Follower 之间的暂时状态；

**系统正常运行时，只有一个 Leader，其余都是 Followers.**

状态转换图：

![image-20231029211132453](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231029211132453.png)

### 任期

时间被划分成一个个的**任期(Term)**，每个任期都由一个数字来表示任期号，任期号单调递增并且永远不会重复。

一个正常的任期至少有一个 Leader，通常分为两部分：

- 任期开始时的选举过程；
- 正常运行的部分；

![image-20231029211219617](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231029211219617.png)

有些任期可能没有选出 Leader（如图 Term 3），这时候会立即进入下一个任期，再次尝试选出一个 Leader。

每个节点维护一个 `currentTerm` 变量，表示系统中当前任期。`currentTerm` **必须持久化存储**，以便在服务器宕机重启时将其恢复。

**任期非常重要！任期能够帮助 Raft 识别过期的信息。**例如：如果 `currentTerm = 2` 的节点与 `currentTerm = 3` 的节点通信，我们可以知道第一个节点上的信息是过时的。

我们只使用最新任期的信息。后面我们会遇到各种情况，去检测和消除不是最新任期的信息。

### 两个 RPC

Raft 中服务器之间所有类型的通信通过两个 RPC 调用：

- `RequestVote`：用于选举；
- `AppendEntries`：用于复制 log 和发送心跳；

## 算法流程

### Leader 选举

**启动**

Raft算法中刚启动的第一步就是要选出领导者。节点间的转换图如下：

![image-20231029213207894](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231029213207894.png)

- 节点启动时，都是 Follower 状态；

- Follower 被动地接受 Leader 或 Candidate 的 RPC；

- 所以，如果 Leader 想要保持权威，必须向集群中的其它节点发送心跳包（空的 `AppendEntries RPC`）；

- 等待选举超时(`electionTimeout`，一般在 100~500ms)后，Follower 没有收到任何 RPC：

- - Follower 认为集群中没有 Leader
  - 开始新的一轮选举

**选举**

当一个节点开始竞选：

- 增加自己的 `currentTerm`
- 转为 Candidate 状态，**其目标是获取超过半数节点的选票，让自己成为 Leader**
- **先给自己投一票**
- 并行地向集群中其它节点发送 `RequestVote RPC` 索要选票，如果没有收到指定节点的响应，它会反复尝试，直到发生以下三种情况之一：

1. 获得超过半数的选票：成为 Leader，并向其它节点发送 `AppendEntries` 心跳；
2. 收到来自 Leader 的 RPC：转为 Follower；
3. 其它两种情况都没发生，没人能够获胜(`electionTimeout` 已过)：增加 `currentTerm`，开始新一轮选举；

流程图如下：

![image-20231029214231789](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231029214231789.png)



**选举安全性**

选举过程需要保证两个特性：**安全性(safety)**和**活性(liveness)**。

安全性(safety)：一个任期内只会有一个 Leader 被选举出来。需要保证：

- 每个节点在同一任期内只能投一次票，它将投给第一个满足条件的投票请求，然后拒绝其它 Candidate 的请求。这需要持久化存储投票信息 `votedFor`，以便宕机重启后恢复，否则重启后 `votedFor` 丢失会导致投给别的节点；
- 只有获得超过半数节点的选票才能成为 Leader，也就是说，两个不同的 Candidate 无法在同一任期内都获得超过半数的票；

活性(liveness)：确保最终能选出一个 Leader。

问题是：原则上我们可以无限重复分割选票，假如选举同一时间开始，同一时间超时，同一时间再次选举，如此循环。

解决办法很简单：

- 节点随机选择超时时间，通常在 [T, 2T] 之间（T = `electionTimeout`）
- 这样，节点不太可能再同时开始竞选，先竞选的节点有足够的时间来索要其他节点的选票
- T >> broadcast time(T 远大于广播时间)时效果更佳

### 日志复制

首先我们看一下Raft算法的日志格式。每个节点存储自己的日志副本（用变量log[]表示），日志中的每个日志条目(Log Entry)包含内容：

- 索引（Index）。索引表示该日志条目在整个日志中的位置
- 任期号。日志条目首次被领导者创建时的任期
- 命令。应用于状态机的命令

**Raft通过索引和任期号唯一的标识一条日志条目。**

> 之后讨论日志也只关心索引和日期号，不用关心具体命令是什么

**日志必须持久化存储。**一个节点必须先将记录安全写到磁盘，才能向系统中其他节点返回响应。

**如果一条日志记录被存储在超过半数的节点上，我们认为该记录已提交(`committed`)——这是 Raft 非常重要的特性！**如果一条记录已提交，意味着状态机可以安全地执行该记录。

在下图中，第 1-7 条记录被提交，第 8 条尚未提交。

![image-20231029215808807](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231029215808807.png)

**正常运行**

- 客户端向 Leader 发送命令，希望该命令被所有状态机执行；

- Leader 先将该命令追加到自己的日志中；

- Leader 并行地向其它节点发送 `AppendEntries RPC`，等待响应；

- 收到超过半数节点的响应，则认为新的日志记录是被提交的：

- - Leader 将命令传给自己的状态机，然后向客户端返回响应
  - 此外，一旦 Leader 知道一条记录被提交了，将在后续的 `AppendEntries RPC` 中通知已经提交记录的 Followers
  - Follower 将已提交的命令传给自己的状态机

- 如果 Follower 宕机/超时：Leader 将反复尝试发送 RPC；

- 性能优化：Leader 不必等待每个 Follower 做出响应，只需要超过半数的成功响应（确保日志记录已经存储在超过半数的节点上）——一个很慢的节点不会使系统变慢，因为 Leader 不必等他；

**日志一致性**

Raft 尝试在集群中保持日志较高的一致性。

**Raft 日志的 index 和 term 唯一标示一条日志记录。**（这非常重要！！！）

1. 如果两个节点的日志在相同的索引位置上的任期号相同，则认为他们具有一样的命令；**从头到这个索引位置之间的日志完全相同**；
2. **如果给定的记录已提交，那么所有前面的记录也已提交**。

**`AppendEntries` 一致性检查**

**Raft 通过 `AppendEntries RPC` 来检测这两个属性(term和index)。**

- 对于每个 `AppendEntries RPC` 包含新日志记录**之前那条记录的**索引(`prevLogIndex`)和任期(`prevLogTerm`)；
- Follower 检查自己的 index 和 term 是否与 `prevLogIndex` 和 `prevLogTerm` 匹配，匹配则接收该记录；否则拒绝；如下图所示

![image-20231029220009096](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20231029220009096.png)

> 一致性检查的原理可以用数学归纳法证明：简单说就是，初始状态日志都是空的；其次，每追加一条日志都要通过一次性检查保证前一条日志是相同的，那么最后可得，这一条日志前面的所有日志一定也是相同的

