---
title: VAE
date: 2023-07-13
tags: 
  - 
categories: 
  - 深度学习
  - 论文阅读
---

> 参考https://www.yuque.com/lirt1231/na5606/pntoly

## 一些概念：

**隐变量**（latent variables）是在统计模型或概率图模型中存在但未直接观测到的变量。

**观测变量**（observed variables）是我们可以直接测量或观察到的变量。

>在潜在狄利克雷分配（Latent Dirichlet Allocation，LDA）中，隐变量表示文档的主题分布，而观测变量表示文档中的单词。通过对观测变量（单词）的观测，我们可以推断出隐变量（主题）的分布，从而了解文档的主题结构

## 变分推断

变分推断（variational inference）是贝叶斯学习中常用的、含有隐变量模型学习和推理方法。

##  变分推断的核心思想

###  视角一 近似分布（最重要）

贝叶斯学习的本质是学习隐变量或者模型参数的后验分布![img](https://cdn.nlark.com/yuque/__latex/0ddbaa85f55eb156e861b9ab54cc27d9.svg)。而一般情况下![img](https://cdn.nlark.com/yuque/__latex/4e57d6ce6d261528245cbaeb3d04332b.svg)是一个复杂的分布，直接估计分布的参数很困难。所以变分的**核心思想**就是，**用一个简单的分布**![img](https://cdn.nlark.com/yuque/__latex/0eaa0f59f74c2e7a454981adb98e7812.svg)**来近似条件概率分布**![img](https://cdn.nlark.com/yuque/__latex/4e57d6ce6d261528245cbaeb3d04332b.svg)。KL  散度常用来度量两个分布之间“距离”的标准，所以变分推断其实就是以 KL 散度![img](https://cdn.nlark.com/yuque/__latex/05030c9e2953a942cc941b984e5b4380.svg)为目标函数，希望找到在 KL 散度意义下与![img](https://cdn.nlark.com/yuque/__latex/4e57d6ce6d261528245cbaeb3d04332b.svg)最接近的分布![img](https://cdn.nlark.com/yuque/__latex/8ec7431c12f3d8a0e807d67f62d3fd2e.svg)：

![img](https://cdn.nlark.com/yuque/__latex/602fe521295c05492f00420ff0b9eba8.svg)

经过一系列推导，KL散度也可以表示为



![img](https://cdn.nlark.com/yuque/__latex/15de7d612355a8140c20910d419e8548.svg)

我们的目标函数是通过调节![img](https://cdn.nlark.com/yuque/__latex/0eaa0f59f74c2e7a454981adb98e7812.svg)来最小化 KL 散度![img](https://cdn.nlark.com/yuque/__latex/05030c9e2953a942cc941b984e5b4380.svg)

（1）式 KL 散度等式右边可以看做两部分，其一![img](https://cdn.nlark.com/yuque/__latex/9c6bb8c7d3b7944bbd0f26a1a9e6a50b.svg)被称为证据（evidence），而后面一部分![img](https://cdn.nlark.com/yuque/__latex/2ad569efec842c43006119bab33aee3f.svg)被称为证据下界（evidence lower bound, **ELBO**）。具体原因是这样的，首先对（1)式变形：

![img](https://cdn.nlark.com/yuque/__latex/9864ff5162cc88383a87de4872e98f12.svg)



**Evidence 可以写成 ELBO + 一个 KL 散度**。因为 KL 散度大于等于 0，所以 ELBO 的最大值就是左边的![img](https://cdn.nlark.com/yuque/__latex/6a376202edcf4b314021c6dbd791e850.svg)。

回归头来再看（1）式，我们的目标是通过调节![img](https://cdn.nlark.com/yuque/__latex/0eaa0f59f74c2e7a454981adb98e7812.svg)最小化（1）式。可以看到![img](https://cdn.nlark.com/yuque/__latex/9c6bb8c7d3b7944bbd0f26a1a9e6a50b.svg)中不包含![img](https://cdn.nlark.com/yuque/__latex/0eaa0f59f74c2e7a454981adb98e7812.svg)，所以在优化过程中对![img](https://cdn.nlark.com/yuque/__latex/0eaa0f59f74c2e7a454981adb98e7812.svg)不起作用。最终，这个**最小化 KL 散度的问题变成了最大化 ELBO 的问题**：



![img](https://cdn.nlark.com/yuque/__latex/4e94f32d57e161df0652fa80d4f85b22.svg)



（3）式就是变分推断中最重要的公式，**可以说所有变分问题都是围绕这个 ELBO 来展开的**。

> 一句话就是要最大化ELBO，然后就可以最小化散度，也就是两个分布之间的”距离“的标准



### 视角二 最大化证据 evidence

**除了从最小化 KL 散度的视角理解 ELBO 的作用，其实还有另一种视角。首先将（2）式再拿来：**



![img](https://cdn.nlark.com/yuque/__latex/e2071d9370de91169ceeda0da2b8ef98.svg)



该式可以简化成 **evidence = ELBO + KL**。不管是在 EM 算法，还是在许多机器学习算法中，目标都可以转化为一个极大似然估计的问题。如果在上式中加入参数![img](https://cdn.nlark.com/yuque/__latex/ed5a4aa5e092e303a69c608582c70db9.svg)，则有



![img](data:image/svg+xml;utf8,%3Csvg%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20width%3D%2266.167ex%22%20height%3D%223.009ex%22%20style%3D%22vertical-align%3A%20-1.005ex%3B%22%20viewBox%3D%220%20-863.1%2028488.4%201295.7%22%20role%3D%22img%22%20focusable%3D%22false%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20aria-labelledby%3D%22MathJax-SVG-1-Title%22%3E%0A%3Ctitle%20id%3D%22MathJax-SVG-1-Title%22%3EEquation%3C%2Ftitle%3E%0A%3Cdefs%20aria-hidden%3D%22true%22%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-6C%22%20d%3D%22M42%2046H56Q95%2046%20103%2060V68Q103%2077%20103%2091T103%20124T104%20167T104%20217T104%20272T104%20329Q104%20366%20104%20407T104%20482T104%20542T103%20586T103%20603Q100%20622%2089%20628T44%20637H26V660Q26%20683%2028%20683L38%20684Q48%20685%2067%20686T104%20688Q121%20689%20141%20690T171%20693T182%20694H185V379Q185%2062%20186%2060Q190%2052%20198%2049Q219%2046%20247%2046H263V0H255L232%201Q209%202%20183%202T145%203T107%203T57%201L34%200H26V46H42Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-6F%22%20d%3D%22M28%20214Q28%20309%2093%20378T250%20448Q340%20448%20405%20380T471%20215Q471%20120%20407%2055T250%20-10Q153%20-10%2091%2057T28%20214ZM250%2030Q372%2030%20372%20193V225V250Q372%20272%20371%20288T364%20326T348%20362T317%20390T268%20410Q263%20411%20252%20411Q222%20411%20195%20399Q152%20377%20139%20338T126%20246V226Q126%20130%20145%2091Q177%2030%20250%2030Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-67%22%20d%3D%22M329%20409Q373%20453%20429%20453Q459%20453%20472%20434T485%20396Q485%20382%20476%20371T449%20360Q416%20360%20412%20390Q410%20404%20415%20411Q415%20412%20416%20414V415Q388%20412%20363%20393Q355%20388%20355%20386Q355%20385%20359%20381T368%20369T379%20351T388%20325T392%20292Q392%20230%20343%20187T222%20143Q172%20143%20123%20171Q112%20153%20112%20133Q112%2098%20138%2081Q147%2075%20155%2075T227%2073Q311%2072%20335%2067Q396%2058%20431%2026Q470%20-13%20470%20-72Q470%20-139%20392%20-175Q332%20-206%20250%20-206Q167%20-206%20107%20-175Q29%20-140%2029%20-75Q29%20-39%2050%20-15T92%2018L103%2024Q67%2055%2067%20108Q67%20155%2096%20193Q52%20237%2052%20292Q52%20355%20102%20398T223%20442Q274%20442%20318%20416L329%20409ZM299%20343Q294%20371%20273%20387T221%20404Q192%20404%20171%20388T145%20343Q142%20326%20142%20292Q142%20248%20149%20227T179%20192Q196%20182%20222%20182Q244%20182%20260%20189T283%20207T294%20227T299%20242Q302%20258%20302%20292T299%20343ZM403%20-75Q403%20-50%20389%20-34T348%20-11T299%20-2T245%200H218Q151%200%20138%20-6Q118%20-15%20107%20-34T95%20-74Q95%20-84%20101%20-97T122%20-127T170%20-155T250%20-167Q319%20-167%20361%20-139T403%20-75Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-70%22%20d%3D%22M23%20287Q24%20290%2025%20295T30%20317T40%20348T55%20381T75%20411T101%20433T134%20442Q209%20442%20230%20378L240%20387Q302%20442%20358%20442Q423%20442%20460%20395T497%20281Q497%20173%20421%2082T249%20-10Q227%20-10%20210%20-4Q199%201%20187%2011T168%2028L161%2036Q160%2035%20139%20-51T118%20-138Q118%20-144%20126%20-145T163%20-148H188Q194%20-155%20194%20-157T191%20-175Q188%20-187%20185%20-190T172%20-194Q170%20-194%20161%20-194T127%20-193T65%20-192Q-5%20-192%20-24%20-194H-32Q-39%20-187%20-39%20-183Q-37%20-156%20-26%20-148H-6Q28%20-147%2033%20-136Q36%20-130%2094%20103T155%20350Q156%20355%20156%20364Q156%20405%20131%20405Q109%20405%2094%20377T71%20316T59%20280Q57%20278%2043%20278H29Q23%20284%2023%20287ZM178%20102Q200%2026%20252%2026Q282%2026%20310%2049T356%20107Q374%20141%20392%20215T411%20325V331Q411%20405%20350%20405Q339%20405%20328%20402T306%20393T286%20380T269%20365T254%20350T243%20336T235%20326L232%20322Q232%20321%20229%20308T218%20264T204%20212Q178%20106%20178%20102Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-28%22%20d%3D%22M94%20250Q94%20319%20104%20381T127%20488T164%20576T202%20643T244%20695T277%20729T302%20750H315H319Q333%20750%20333%20741Q333%20738%20316%20720T275%20667T226%20581T184%20443T167%20250T184%2058T225%20-81T274%20-167T316%20-220T333%20-241Q333%20-250%20318%20-250H315H302L274%20-226Q180%20-141%20137%20-14T94%20250Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-78%22%20d%3D%22M52%20289Q59%20331%20106%20386T222%20442Q257%20442%20286%20424T329%20379Q371%20442%20430%20442Q467%20442%20494%20420T522%20361Q522%20332%20508%20314T481%20292T458%20288Q439%20288%20427%20299T415%20328Q415%20374%20465%20391Q454%20404%20425%20404Q412%20404%20406%20402Q368%20386%20350%20336Q290%20115%20290%2078Q290%2050%20306%2038T341%2026Q378%2026%20414%2059T463%20140Q466%20150%20469%20151T485%20153H489Q504%20153%20504%20145Q504%20144%20502%20134Q486%2077%20440%2033T333%20-11Q263%20-11%20227%2052Q186%20-10%20133%20-10H127Q78%20-10%2057%2016T35%2071Q35%20103%2054%20123T99%20143Q142%20143%20142%20101Q142%2081%20130%2066T107%2046T94%2041L91%2040Q91%2039%2097%2036T113%2029T132%2026Q168%2026%20194%2071Q203%2087%20217%20139T245%20247T261%20313Q266%20340%20266%20352Q266%20380%20251%20392T217%20404Q177%20404%20142%20372T93%20290Q91%20281%2088%20280T72%20278H58Q52%20284%2052%20289Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-2223%22%20d%3D%22M139%20-249H137Q125%20-249%20119%20-235V251L120%20737Q130%20750%20139%20750Q152%20750%20159%20735V-235Q151%20-249%20141%20-249H139Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-3B8%22%20d%3D%22M35%20200Q35%20302%2074%20415T180%20610T319%20704Q320%20704%20327%20704T339%20705Q393%20701%20423%20656Q462%20596%20462%20495Q462%20380%20417%20261T302%2066T168%20-10H161Q125%20-10%2099%2010T60%2063T41%20130T35%20200ZM383%20566Q383%20668%20330%20668Q294%20668%20260%20623T204%20521T170%20421T157%20371Q206%20370%20254%20370L351%20371Q352%20372%20359%20404T375%20484T383%20566ZM113%20132Q113%2026%20166%2026Q181%2026%20198%2036T239%2074T287%20161T335%20307L340%20324H145Q145%20321%20136%20286T120%20208T113%20132Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-29%22%20d%3D%22M60%20749L64%20750Q69%20750%2074%20750H86L114%20726Q208%20641%20251%20514T294%20250Q294%20182%20284%20119T261%2012T224%20-76T186%20-143T145%20-194T113%20-227T90%20-246Q87%20-249%2086%20-250H74Q66%20-250%2063%20-250T58%20-247T55%20-238Q56%20-237%2066%20-225Q221%20-64%20221%20250T66%20725Q56%20737%2055%20738Q55%20746%2060%20749Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-3D%22%20d%3D%22M56%20347Q56%20360%2070%20367H707Q722%20359%20722%20347Q722%20336%20708%20328L390%20327H72Q56%20332%2056%20347ZM56%20153Q56%20168%2072%20173H708Q722%20163%20722%20153Q722%20140%20707%20133H70Q56%20140%2056%20153Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-45%22%20d%3D%22M492%20213Q472%20213%20472%20226Q472%20230%20477%20250T482%20285Q482%20316%20461%20323T364%20330H312Q311%20328%20277%20192T243%2052Q243%2048%20254%2048T334%2046Q428%2046%20458%2048T518%2061Q567%2077%20599%20117T670%20248Q680%20270%20683%20272Q690%20274%20698%20274Q718%20274%20718%20261Q613%207%20608%202Q605%200%20322%200H133Q31%200%2031%2011Q31%2013%2034%2025Q38%2041%2042%2043T65%2046Q92%2046%20125%2049Q139%2052%20144%2061Q146%2066%20215%20342T285%20622Q285%20629%20281%20629Q273%20632%20228%20634H197Q191%20640%20191%20642T193%20659Q197%20676%20203%20680H757Q764%20676%20764%20669Q764%20664%20751%20557T737%20447Q735%20440%20717%20440H705Q698%20445%20698%20453L701%20476Q704%20500%20704%20528Q704%20558%20697%20578T678%20609T643%20625T596%20632T532%20634H485Q397%20633%20392%20631Q388%20629%20386%20622Q385%20619%20355%20499T324%20377Q347%20376%20372%20376H398Q464%20376%20489%20391T534%20472Q538%20488%20540%20490T557%20493Q562%20493%20565%20493T570%20492T572%20491T574%20487T577%20483L544%20351Q511%20218%20508%20216Q505%20213%20492%20213Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-71%22%20d%3D%22M33%20157Q33%20258%20109%20349T280%20441Q340%20441%20372%20389Q373%20390%20377%20395T388%20406T404%20418Q438%20442%20450%20442Q454%20442%20457%20439T460%20434Q460%20425%20391%20149Q320%20-135%20320%20-139Q320%20-147%20365%20-148H390Q396%20-156%20396%20-157T393%20-175Q389%20-188%20383%20-194H370Q339%20-192%20262%20-192Q234%20-192%20211%20-192T174%20-192T157%20-193Q143%20-193%20143%20-185Q143%20-182%20145%20-170Q149%20-154%20152%20-151T172%20-148Q220%20-148%20230%20-141Q238%20-136%20258%20-53T279%2032Q279%2033%20272%2029Q224%20-10%20172%20-10Q117%20-10%2075%2030T33%20157ZM352%20326Q329%20405%20277%20405Q242%20405%20210%20374T160%20293Q131%20214%20119%20129Q119%20126%20119%20118T118%20106Q118%2061%20136%2044T179%2026Q233%2026%20290%2098L298%20109L352%20326Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-5B%22%20d%3D%22M118%20-250V750H255V710H158V-210H255V-250H118Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-2C%22%20d%3D%22M78%2035T78%2060T94%20103T137%20121Q165%20121%20187%2096T210%208Q210%20-27%20201%20-60T180%20-117T154%20-158T130%20-185T117%20-194Q113%20-194%20104%20-185T95%20-172Q95%20-168%20106%20-156T131%20-126T157%20-76T173%20-3V9L172%208Q170%207%20167%206T161%203T152%201T140%200Q113%200%2096%2017Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-7A%22%20d%3D%22M347%20338Q337%20338%20294%20349T231%20360Q211%20360%20197%20356T174%20346T162%20335T155%20324L153%20320Q150%20317%20138%20317Q117%20317%20117%20325Q117%20330%20120%20339Q133%20378%20163%20406T229%20440Q241%20442%20246%20442Q271%20442%20291%20425T329%20392T367%20375Q389%20375%20411%20408T434%20441Q435%20442%20449%20442H462Q468%20436%20468%20434Q468%20430%20463%20420T449%20399T432%20377T418%20358L411%20349Q368%20298%20275%20214T160%20106L148%2094L163%2093Q185%2093%20227%2082T290%2071Q328%2071%20360%2090T402%20140Q406%20149%20409%20151T424%20153Q443%20153%20443%20143Q443%20138%20442%20134Q425%2072%20376%2031T278%20-11Q252%20-11%20232%206T193%2040T155%2057Q111%2057%2076%20-3Q70%20-11%2059%20-11H54H41Q35%20-5%2035%20-2Q35%2013%2093%2084Q132%20129%20225%20214T340%20322Q352%20338%20347%20338Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-5D%22%20d%3D%22M22%20710V750H159V-250H22V-210H119V710H22Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-2212%22%20d%3D%22M84%20237T84%20250T98%20270H679Q694%20262%20694%20250T679%20230H98Q84%20237%2084%20250Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-2B%22%20d%3D%22M56%20237T56%20250T70%20270H369V420L370%20570Q380%20583%20389%20583Q402%20583%20409%20568V270H707Q722%20262%20722%20250T707%20230H409V-68Q401%20-82%20391%20-82H389H387Q375%20-82%20369%20-68V230H70Q56%20237%2056%20250Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-44%22%20d%3D%22M287%20628Q287%20635%20230%20637Q207%20637%20200%20638T193%20647Q193%20655%20197%20667T204%20682Q206%20683%20403%20683Q570%20682%20590%20682T630%20676Q702%20659%20752%20597T803%20431Q803%20275%20696%20151T444%203L430%201L236%200H125H72Q48%200%2041%202T33%2011Q33%2013%2036%2025Q40%2041%2044%2043T67%2046Q94%2046%20127%2049Q141%2052%20146%2061Q149%2065%20218%20339T287%20628ZM703%20469Q703%20507%20692%20537T666%20584T629%20613T590%20629T555%20636Q553%20636%20541%20636T512%20636T479%20637H436Q392%20637%20386%20627Q384%20623%20313%20339T242%2052Q242%2048%20253%2048T330%2047Q335%2047%20349%2047T373%2046Q499%2046%20581%20128Q617%20164%20640%20212T683%20339T703%20469Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-4B%22%20d%3D%22M285%20628Q285%20635%20228%20637Q205%20637%20198%20638T191%20647Q191%20649%20193%20661Q199%20681%20203%20682Q205%20683%20214%20683H219Q260%20681%20355%20681Q389%20681%20418%20681T463%20682T483%20682Q500%20682%20500%20674Q500%20669%20497%20660Q496%20658%20496%20654T495%20648T493%20644T490%20641T486%20639T479%20638T470%20637T456%20637Q416%20636%20405%20634T387%20623L306%20305Q307%20305%20490%20449T678%20597Q692%20611%20692%20620Q692%20635%20667%20637Q651%20637%20651%20648Q651%20650%20654%20662T659%20677Q662%20682%20676%20682Q680%20682%20711%20681T791%20680Q814%20680%20839%20681T869%20682Q889%20682%20889%20672Q889%20650%20881%20642Q878%20637%20862%20637Q787%20632%20726%20586Q710%20576%20656%20534T556%20455L509%20418L518%20396Q527%20374%20546%20329T581%20244Q656%2067%20661%2061Q663%2059%20666%2057Q680%2047%20717%2046H738Q744%2038%20744%2037T741%2019Q737%206%20731%200H720Q680%203%20625%203Q503%203%20488%200H478Q472%206%20472%209T474%2027Q478%2040%20480%2043T491%2046H494Q544%2046%20544%2071Q544%2075%20517%20141T485%20216L427%20354L359%20301L291%20248L268%20155Q245%2063%20245%2058Q245%2051%20253%2049T303%2046H334Q340%2037%20340%2035Q340%2019%20333%205Q328%200%20317%200Q314%200%20280%201T180%202Q118%202%2085%202T49%201Q31%201%2031%2011Q31%2013%2034%2025Q38%2041%2042%2043T65%2046Q92%2046%20125%2049Q139%2052%20144%2061Q147%2065%20216%20339T285%20628Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-4C%22%20d%3D%22M228%20637Q194%20637%20192%20641Q191%20643%20191%20649Q191%20673%20202%20682Q204%20683%20217%20683Q271%20680%20344%20680Q485%20680%20506%20683H518Q524%20677%20524%20674T522%20656Q517%20641%20513%20637H475Q406%20636%20394%20628Q387%20624%20380%20600T313%20336Q297%20271%20279%20198T252%2088L243%2052Q243%2048%20252%2048T311%2046H328Q360%2046%20379%2047T428%2054T478%2072T522%20106T564%20161Q580%20191%20594%20228T611%20270Q616%20273%20628%20273H641Q647%20264%20647%20262T627%20203T583%2083T557%209Q555%204%20553%203T537%200T494%20-1Q483%20-1%20418%20-1T294%200H116Q32%200%2032%2010Q32%2017%2034%2024Q39%2043%2044%2045Q48%2046%2059%2046H65Q92%2046%20125%2049Q139%2052%20144%2061Q147%2065%20216%20339T285%20628Q285%20635%20228%20637Z%22%3E%3C%2Fpath%3E%0A%3C%2Fdefs%3E%0A%3Cg%20stroke%3D%22currentColor%22%20fill%3D%22currentColor%22%20stroke-width%3D%220%22%20transform%3D%22matrix(1%200%200%20-1%200%200)%22%20aria-hidden%3D%22true%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-6C%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-6F%22%20x%3D%22278%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-67%22%20x%3D%22779%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-70%22%20x%3D%221446%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-28%22%20x%3D%221949%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-78%22%20x%3D%222339%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2223%22%20x%3D%222911%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-3B8%22%20x%3D%223190%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-29%22%20x%3D%223659%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-3D%22%20x%3D%224326%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3Cg%20transform%3D%22translate(5383%2C0)%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-45%22%20x%3D%220%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20transform%3D%22scale(0.707)%22%20xlink%3Ahref%3D%22%23E1-MJMATHI-71%22%20x%3D%221044%22%20y%3D%22-213%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%3Cg%20transform%3D%22translate(6714%2C0)%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-5B%22%20x%3D%220%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3Cg%20transform%3D%22translate(278%2C0)%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-6C%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-6F%22%20x%3D%22278%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-67%22%20x%3D%22779%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-70%22%20x%3D%221724%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-28%22%20x%3D%222228%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-78%22%20x%3D%222617%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2C%22%20x%3D%223190%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-7A%22%20x%3D%223635%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2223%22%20x%3D%224103%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-3B8%22%20x%3D%224382%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-29%22%20x%3D%224851%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-5D%22%20x%3D%225241%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2212%22%20x%3D%2212456%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3Cg%20transform%3D%22translate(13456%2C0)%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-45%22%20x%3D%220%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20transform%3D%22scale(0.707)%22%20xlink%3Ahref%3D%22%23E1-MJMATHI-71%22%20x%3D%221044%22%20y%3D%22-213%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%3Cg%20transform%3D%22translate(14787%2C0)%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-5B%22%20x%3D%220%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3Cg%20transform%3D%22translate(278%2C0)%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-6C%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-6F%22%20x%3D%22278%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-67%22%20x%3D%22779%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-71%22%20x%3D%221724%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-28%22%20x%3D%222185%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-7A%22%20x%3D%222574%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-29%22%20x%3D%223043%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-5D%22%20x%3D%223432%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2B%22%20x%3D%2218720%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3Cg%20transform%3D%22translate(19721%2C0)%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-44%22%20x%3D%220%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3Cg%20transform%3D%22translate(828%2C-150)%22%3E%0A%20%3Cuse%20transform%3D%22scale(0.707)%22%20xlink%3Ahref%3D%22%23E1-MJMATHI-4B%22%20x%3D%220%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20transform%3D%22scale(0.707)%22%20xlink%3Ahref%3D%22%23E1-MJMATHI-4C%22%20x%3D%22889%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%3C%2Fg%3E%0A%3Cg%20transform%3D%22translate(21927%2C0)%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-28%22%20x%3D%220%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-71%22%20x%3D%22389%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-28%22%20x%3D%22850%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-7A%22%20x%3D%221239%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-29%22%20x%3D%221708%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2223%22%20x%3D%222097%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2223%22%20x%3D%222376%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-70%22%20x%3D%222654%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-28%22%20x%3D%223158%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-7A%22%20x%3D%223547%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2223%22%20x%3D%224016%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-78%22%20x%3D%224294%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2C%22%20x%3D%224867%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-3B8%22%20x%3D%225312%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-29%22%20x%3D%225781%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-29%22%20x%3D%226171%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%3C%2Fg%3E%0A%3C%2Fsvg%3E)



而我们的目标是最大化对数似然![img](https://cdn.nlark.com/yuque/__latex/2970f060aaa94469d27cf0114eb516d1.svg)，由于上面分析过 **ELBO 是 evidence 的下界，所以不断提升 优化 ELBO 的值就可以迭代地最大化对数似然 evidence**。



到这，变分推断的内容基本就完事儿 了，剩下的都是应用了。

## VAE

**变分自编码器（Variational Auto-Encoder, VAE）**作为贝叶斯统计学习系列，传统贝叶斯与深度学习结合的第一个也是最重要的案例

### Auto-Encoder 自编码器网络

自编码器的结构很简单，思想也很朴素：

![img](https://cdn.nlark.com/yuque/0/2022/png/805730/1663757882247-959b74e0-194f-4b01-b0a5-15b08537c9e3.png)



AE 一共有两个网络：编码器 encoder 以及解码器 decoder，可以是由 CNN、RNN、Transformer 等组成，因为 **AE 只是描述了一种框架**。

AE 训练的思路是，把原始数据（图像、音频等）放到 encoder 中进行编码，得到数据![img](https://cdn.nlark.com/yuque/__latex/7db4cee9e74865ab082228d786b31d61.svg)的编码表示向量![img](https://cdn.nlark.com/yuque/__latex/b891664b42113aee13f0bac25eb998e5.svg)（一般比原始数据维度低很多），然后用一个解码器网络将编码![img](https://cdn.nlark.com/yuque/__latex/b891664b42113aee13f0bac25eb998e5.svg)还原成与原始数据同尺寸的![img](https://cdn.nlark.com/yuque/__latex/c3250d8e3ddfbbb53294f4de57c62c6b.svg)，认为它就是经解码得到的原始数据。**损失当然就是**![img](https://cdn.nlark.com/yuque/__latex/712ecf7894348e92d8779c3ee87eeeb0.svg)**与**![img](https://cdn.nlark.com/yuque/__latex/c3250d8e3ddfbbb53294f4de57c62c6b.svg)**之间的距离**，一般采用 MSE 均方误差损失。这个损失经常被称为**重建损失（reconstruction loss）**。



得到编码表示![img](https://cdn.nlark.com/yuque/__latex/b891664b42113aee13f0bac25eb998e5.svg)的意义在于，可以对**原始数据降维，提取有效特征**（比如图像中有大量冗余的信息）。一方面能提高运算效率，另一方面能提升模型性能。当然光编码解码是没有意义的，一般会将训练好的 Auto-Encoder 的编码器 encoder 部分应用到下游任务中，即使用 encoder 对下游数据进行编码，然后用该编码作为下游模型的输入完成任务。

比如先在一个非常大的数据集（比如 ImageNet）上训练 AE，然后留下 encoder 部分，认为该 encoder 部分能对（所有的）图像进行有效编码。随后在比如物体检测、物体识别等具体的应用场景中，会使用到不同的数据集，可以将图片输入训练好的 encoder 提取特征得到编码表示![img](https://cdn.nlark.com/yuque/__latex/b891664b42113aee13f0bac25eb998e5.svg)，然后将![img](https://cdn.nlark.com/yuque/__latex/b891664b42113aee13f0bac25eb998e5.svg)再经过几个线性层得到分类结果，最后只需训练这几层线性层即可，而 encoder 是 frozen 的（也可以将 encoder 在下游模型上微调 fine-tune）。

### VAE 变分自编码器

不谈别的，先放一张 VAE 的图。

![img](https://cdn.nlark.com/yuque/0/2022/png/805730/1663758673584-588dc041-5c08-43df-a779-93f793f49f28.png)

可以说 VAE 区别普通 AE 的地方在于，**它将原始数据输入到 encoder 网络后，encoder 输出的是两个向量（而不是之前的一个），并且分别代表了高斯分布的均值和标准差**，记为![img](https://cdn.nlark.com/yuque/__latex/c35918a94a2680762fc5960bbc43e549.svg)（这里是[多元高斯分布](https://www.yuque.com/herormlihaotian/pugkgw/ckrrh2)），然后从![img](https://cdn.nlark.com/yuque/__latex/c35918a94a2680762fc5960bbc43e549.svg)所代表的高斯分布中**采样得到**![img](https://cdn.nlark.com/yuque/__latex/02bab26178a0cd05dae15ad487830237.svg)向量（图中 sampled latent vector)作为原始图像的压缩编码表示，随后输入 decoder 网络还原图像。

看起来 VAE 是 Auto-Encoder 的框架，但其理论内核远比 AE 要深很多。设想以下几个问题：

1. VAE 是 Variational AE，跟 Variational Inference 有什么关系？
2. 为什么 encoder 输出的是高斯分布的两个参数，而不是直接一个向量![img](https://cdn.nlark.com/yuque/__latex/02bab26178a0cd05dae15ad487830237.svg)？
3. 为什么 encoder 输出的是高斯分布，**不是别的分布**？
4. 说![img](https://cdn.nlark.com/yuque/__latex/02bab26178a0cd05dae15ad487830237.svg)是从![img](https://cdn.nlark.com/yuque/__latex/3aec12fbf626fa7c8588cea35442bb0f.svg)两个 encoder 输出向量所代表的高斯分布中采样得到的，而**采样过程不可导**，如何进行反向传播训练整个网络？

### VAE 与变分推断

1.VAE 是 Variational AE，跟 Variational Inference 有什么关系？

变分推断中提到，最小化KL散度需要最大化ELBO，设L是ELBO，经过一系列推导，有：

![image-20230714113349927](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230714113349927.png)

 这个就是**VAE 的损失函数：**可以看到，该损失有两部分组成：

![image-20230714113438598](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230714113438598.png)



2.为什么 encoder 输出的是高斯分布的两个参数，而不是直接一个向量![img](https://cdn.nlark.com/yuque/__latex/02bab26178a0cd05dae15ad487830237.svg)

**主要是方便计算KL散度，**

![image-20230716222710535](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230716222710535.png)

具体计算过程

![image-20230716222848027](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230716222848027.png)

总结：

- 两个高斯分布的 KL 散度有确定的表达式，当然这并不是主要的
- 主要在于，**为了构造 ELBO 的第一项 KL 损失**。设想如果 encoder 直接输出![img](https://cdn.nlark.com/yuque/__latex/02bab26178a0cd05dae15ad487830237.svg)，那 KL 损失该如何计算呢？毕竟这是两个分布函数之间的函数，是个泛函。

3.为什么输出高斯分布，4 说![img](https://cdn.nlark.com/yuque/__latex/02bab26178a0cd05dae15ad487830237.svg)是从![img](https://cdn.nlark.com/yuque/__latex/3aec12fbf626fa7c8588cea35442bb0f.svg)两个 encoder 输出向量所代表的高斯分布中采样得到的，而**采样过程不可导**，如何进行反向传播训练整个网络？

#### Reparameterization trick 重参数化技巧

上面提到，隐变量![img](https://cdn.nlark.com/yuque/__latex/02bab26178a0cd05dae15ad487830237.svg)是从 encoder 输出的两个变量![img](https://cdn.nlark.com/yuque/__latex/c35918a94a2680762fc5960bbc43e549.svg)定义的高斯分布中**采样得到**的。而**采样这项计算是不可导的**，也就不能通过反向传播训练整个网络。所以 VAE 的作者们就想到了一个 Reparameterization trick 让整个过程可导。

![image-20230716221904088](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230716221904088.png)

**作者们给出了这种 trick 的适用范围，总之这种 trick 只能应用于很有限的几种分布，而高斯是其中一种**，且高斯分布被称为“宇宙第一分布”

>当然，经过后人的不断努力，越来越多的分布的 reparameterization trick 被开发出来并应用于 VAE 框架。

1. VAE 把变分的核心 ELBO 拆成了![img](https://cdn.nlark.com/yuque/__latex/dc5930388fe727d529564160682a7335.svg)和![img](https://cdn.nlark.com/yuque/__latex/47be2e49daecf8eba2aeb56f5bd6f22e.svg)两项，**并用两个神经网络encoder 和 decoder 分别进行拟合，这也是 VAE 贡献最大的地方之一**；
2. 为了 KL 散度好算，因为两个高斯分布，乃至两个已知概率密度函数表达式的分布的 KL 散度是完全可算的，所以用 encoder 拟合高斯分布的参数；
3. 因为高斯分布的 reparameterization trick 好做
4. 通过 reparameterization trick 完成可导

#### Reconstruction loss 重构损失的由来（VAE损失的第二项）

5.为什么损失中的第二项，也就是下面的期望，最后变成了重构损失 MSE？

![image-20230716223641156](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230716223641156.png)



解释：

> 首先引用深度学习花树《Deep Learning》(by Ian Goodfellow, Yoshua Bengio and Aaron Courville) 中的一段话：
>
> Any loss consisting of a negative log-likelihood is a cross-entropy between the empirical distribution defined by the training set and the probability distribution defined by model. For example, mean squared error is the cross-entropy between the empirical distribution and a Gaussian model.
>
> 翻译：任何一个**负对数似然的损失**，都是一个计算经验分布（先验分布）与模型在训练集上推理得到的概率分布之间的**交叉熵损失**。比如**均方误差 MSE** 就是**模型推理得到分布与一个高斯分布之间的交叉熵**。

![image-20230716223828059](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230716223828059.png)

![image-20230716223802302](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230716223802302.png)

![image-20230716223849178](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230716223849178.png)

### VAE训练框架

![image-20230716224036021](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230716224036021.png)

