---
title: 生成网络GAN
date: 2023-07-05
categories: 
  - 深度学习
  - 深度学习-李宏毅2022
tags: 
  - null
---

## 引入

之前学习的Network都是给定一些输入，然后经由网络处理后得到输出，但是现在需要把他当成一个Generator来使用

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705152241248.png" style="zoom:70%">

> 解释一下就是每次输入x时，就从z中随机去一个simple distribution，然后经由网络，生成一个复杂的complex distribution，所以每次可以得到不一样的输出

## 介绍

### Distribution

翻译过来时分布，再上面那个例子中的作用是让机器对于同一个input可以有不同的输出，当我们需要网络看起来有创造力时，就需要这样么做

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705154102796.png" style="zoom:70%">

### Generative Adversarial Network (GAN)

#### Unconditional generation 

>Unconditional 就是输入的时候2没有X，同样的，有conditional 就是输入有x

![image-20230705154447289](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705154447289.png)

#### Discriminator

Discriminator（辨识器）是自己选的一个neural network，他用来辨别GAN的输出与真实的要的图片的不同。 比如输入是图像可以选择CNN来当discriminator

![image-20230705154659470](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705154659470.png)

假设现在要生成图片，第一代网络生成的是Generator V1只有黑白的轮廓,于是Discriminator V1那输出去对比真实图像，觉得不行，要有眼睛；于是Generator V1演化成Generator V2，但是Discriminator V1也变成V2(也是网络，也能进化)，这次呢他说要有嘴巴，而Generator V2生成的没有嘴巴；于是三代生成的有了嘴巴....就这样Discriminator让Generator的输出越来越逼近真实需要的输出

> 这也是**adversarial**（对抗）这个意思的由来

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705155012733.png" style="zoom:70%">

#### Algorithm

1   固定G，训练D

> 固定的意思就是参数不变

D代表discriminator，G代表Generator，我们输入D，让他去学习真实的图片和G输出的区别，而给G输入一个随机的vector。

> 具体来说，D可以当成分类的任务来做，比如让他把真实的图片标1，G生成的标0

![image-20230705160139028](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705160139028.png)

2 固定D，训练G

![image-20230705172241553](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705172241553.png)

> 训练方法当然还是和训练普通网络一样，减小损失函数

3.反复执行1,2，效果会越来越好

![image-20230705172526715](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705172526715.png)

下面是训练5w次时的成果（用GAN生成动画人脸）

![image-20230705172616981](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705172616981.png)

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705172616981.png"/>

## Theory behind GAN

概览一下GAN，其训练就是先输入一个Normal Distrbution，然后通过G生成$P_G$,$P_{data}$指的是真实结果（就是想生成结果）的分布，$P_G$和$P_{data}$越接近，说明两者越想象。

**衡量两者相似度的参数叫Divergence**

可以通过减小损失函数让Divergence更小，这样两者也就更接近

$G^*$最小就是GAN的训练目标

![image-20230705213020598](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705213020598.png)

### 怎么算Divergence

GAN采用了一种方法，在只知道Sampling的情况下，就估算出了Divergence

![image-20230705213601567](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705213601567.png)

具体方法是通过Discriminator

> Discriminator实际的作用就像一个Classifier

假设$D^*$是Discriminator训练时的损失，他是跟Divergence有关的

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230705214001763.png" style="zoom:70%">

