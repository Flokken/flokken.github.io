---
title: 神经网络的学习技巧
date: 2023-03-30 00:00:00
categories: 
  - 深度学习
  - 鱼书-深度学习入门
tags: 
  - null
permalink: /pages/803669/
---

## 参数更新

神经网络的学习的目的是找到使损失函数的值尽可能小的参数。这是寻找最优参数的问题，解决这个问题的过程称为最优化（optimization）。不过这个问题很困难，因为参数空间很复杂，无法轻易找到最优解（无法使用那种通过解数学式一下子就求得最小值的方法）。深度神经网络中，参数的数量非常庞大，导致最优化问题更加复杂。

我们之前使用梯度来寻找最优的参数，也即是使用参数的梯度，沿梯度方向更新参数，并重复这个步骤多次，从而逐渐靠

近最优参数，这个过程称为随机梯度下降法（stochastic gradient descent），简称**SGD**

> 注意这里的随机是每次随机选取一批数据

### SGD

在复习一下SGD的公式：

$W \leftarrow W - \eta \frac {\partial L}{\partial W}$

SGD是朝着梯度方向只前,进一定距离的简单方法。将其实现为一个类：

~~~python
class SGD:
    def __init__(self,lr=0.01):
        self.lr = lr
    
    def update(self,params,grads):
        for key in params.keys():
            params[key] -= self.lr * grads[key]
~~~

这里默认lr为0.01，注意参数params和grads（与之前的神经网络的实现一样）是字典型变量，按params['W1']、grads['W1']的形式，分别保存了权重参数和它们的梯度。

> 一个key就是一层

这里可以用探险家的故事来理解寻找最优参数的困难

> 有一个性情古怪的探险家。他在广袤的干旱地带旅行，坚持寻找幽深的山谷。他的目标是要到达最深的谷底（他称之为“至深之地”）。这也是他旅行的目的。并且，他给自己制定了两个严格的“规定”：一个是不看地图；另一个是把眼睛蒙上。因此，他并不知道最深的谷底在这个广袤的大地的何处，而且什么也看不见。在这么严苛的条件下，这位探险家如何前往“至深之地”呢？他要如何迈步，才能迅速找到“至深之地”呢？
>
> 
>
> 寻找最优参数时，我们所处的状况和这位探险家一样，是一个漆黑的世界。我们必须在没有地图、不能睁眼的情况下，在广袤、复杂的地形中寻找“至深之地”



### Momentum

#### SGD的缺点

思考下面这个函数最小值:

$f(x,y) = \frac {1}{20}x^2+y^2$

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330165020788.png" style="zoom:70%">

这个梯度的特征是，y轴方向上大，x轴方向上小。换句话说， 就是y轴方向的坡度大，而x轴方向的坡度小。这里需要注意的是，虽然式 （6.2）的最小值在(x, y) = (0, 0)处，但是图6-2中的**梯度在很多地方并没有指 向(0, 0)**

其梯度图如下：

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330165210917.png" style="zoom:70%">

我们来尝试对图6-1这种形状的函数应用SGD。

从(x, y) = (−7.0, 2.0)处 （初始值）开始搜索，结果如图6-3所示。 在图6-3中，SGD呈“之”字形移动。这是一个相当低效的路径。也就是说， SGD的缺点是，如果函数的形状非均向（anisotropic），比如呈延伸状，搜索 的路径就会非常低效。因此，我们需要比单纯朝梯度方向前进的SGD更聪 明的方法。SGD低效的根本原因是，**梯度的方向并没有指向最小值的方向**。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330165330078.png" style="zoom:70%">



#### Momentum是啥

Momentum是“动量”的意思，和物理有关。用数学式表示Momentum方法，如下所示。

$v \leftarrow \alpha v-\eta\frac{\partial L}{\partial W} $

$W\leftarrow W+v$

和前面的SGD一样，W表示要更新的权重参数， 表示损失函数关 于W的梯度，η表示学习率。**这里新出现了一个变量v，对应物理上的速度**。 表示了物体在梯度方向上受力，在这个力的作用下，物体的速度增 加这一物理法则。

Momentum方法给人的感觉就像是**小球在地面上滚动**

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330165921342.png" style="zoom:70%">

αv这一项是用来表示，**在物体不受任何力时，该项承担使物体逐渐减速的任务**（α设定为0.9之类的值），**对应物理上的地面摩擦或空气阻力**

> $\alpha 称为动量参数$

为什么要这干呢？我们假设$\alpha=0.9$，迭代过程如下

![image-20230330202247666](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330202247666.png)

>我们可以看到之前的梯度会一直存在后面的迭代过程中，只是越靠前的梯度其权重越小。（说的数学一点，我们取的是这些梯度步长的指数平均）。

下图是实际情况下，只使用‘SGD的行进过程

![image-20230330202502064](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330202502064.png)
>注意到大部分的梯度更新呈锯齿状。我们也注意到，**每一步的梯度更新方向可以被进一步分解为 w1 和 w2 分量**。如果我们单独的将这些向量求和，沿 w1 方向的的分量将抵消，沿 w2 方向的分量将得到加强。

更新路径就像小球在碗中滚动一样。和SGD相比，我们发现“之”字形的“程度”减轻了。这是因为虽然x轴方向上受到的力非常小，但是一直在同一方向上受力，所以朝同一个方向会有一定的加速。反过来，虽然y轴方向上受到的力很大，**但是因为交互地受到正方向和反方向的力，它们会互相抵消**，所以y轴方向上的速度不稳定。因此，和SGD时的情形相比，可以更快地朝x轴方向靠近，减弱“之”字形的变动程度。





<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330192817009.png" style="zoom:70%">

#### 代码实现：

~~~python
class Momentum:
    def __init__(self,lr=0.01,momentum=0.9):
        self.lr = lr
        self.momentum = momentum
        self.v = None
    def updtae(self,params,grads):
        if self.v is None:
            self.v = {}
            for key,val in params.items():
                self.v[key] = np.zeros_like(val)
                
        for key in params.key():
            slef.v[key] = self.momentum*self.v[key] - self.lr*grads[key]
            params[key] += self.v[key]
            
~~~

> 其实就是多了一个累积量，让以前的也会影响到下一步梯度的更新

### AdaGrad

在关于学习率的有效技巧中，有一种被称为学习率衰减（learning rate decay）的方法，即随着学习的进行，使学习率逐渐减小。实际上，一开始“多” 学，然后逐渐“少”学的方法，在神经网络的学习中经常被使用。

逐渐减小学习率的想法，相当于将“全体”参数的学习率值一起降低。 而AdaGrad 进一步发展了这个想法，针对“一个一个”的参数，赋予其“定 制”的值。 **AdaGrad会为参数的每个元素适当地调整学习率**，与此同时进行学习 （AdaGrad的Ada来自英文单词Adaptive，即“适当的”的意思）。下面，用数学式表示AdaGrad的更新方法。

$h \leftarrow h+\frac{\partial L}{\partial W}*\frac{\partial L}{\partial W}$

$W \leftarrow - \eta\frac{1}{\sqrt h}\frac{\partial L}{\partial W}$

>W表示要更新的权重参数， 表示损失函数关 于W的梯度，η表示学习率。这里新出现了变量h,**它保 存了以前的所有梯度值的平方和**

在更新参数时，通过乘以 $\frac{1}{\sqrt h}$，就可以调整学习的尺度。这意味着， 参数的元素中变动较大（被大幅更新）的元素的学习率将变小。也就是说， 可以按参数的元素进行学习率衰减，使变动大的参数的学习率逐渐减小。

>AdaGrad会记录过去所有梯度的平方和。因此，学习越深入，更新 的幅度就越小。实际上，如果无止境地学习，更新量就会变为 0， 完全不再更新。为了改善这个问题，可以使用 RMSProp 方法。 RMSProp方法并不是将过去所有的梯度一视同仁地相加，而是逐渐 地遗忘过去的梯度，在做加法运算时将新梯度的信息更多地反映出来。 这种操作从专业上讲，称为“指数移动平均”，呈指数函数式地减小 过去的梯度的尺度

~~~python
class AdaGrad:
    def __init__(self,lr=0.01):
        self.lr =lr
        self.h =None
        
    def update(self,params,grads):
        if self.h is None:
            self.h = {}
            for key,val in params.items():
                self.h[key] = np.zeros_like(val)
    for key in params.key():
        self.h[key] += grad[key] * grads[key]
        params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7 )
~~~



这里需要注意的是，最后一行加上了微小值1e-7。这是为了防止当。self.h[key]中有0时，将0用作除数的情况。

### Adam

Momentum参照小球在碗中滚动的物理规则进行移动，AdaGrad为参 数的每个元素适当地调整更新步伐。如果将这两个方法融合在一起,,这就是Adam方法的基本思路.其证明过程很复杂，可以看论文。

>Adam会设置 3个超参数。一个是学习率（论文中以α出现），另外两 个是一次momentum系数β1和二次momentum系数β2。根据论文， 标准的设定值是β1为 0.9，β2 为 0.999。设置了这些值后，大多数情 况下都能顺利运行。

根据使用的方法不同，参数更新的路径也不同。只看这个图的话，AdaGrad似乎是最好的，不过也要注意，结果会根据要解决的问

题而变。并且，很显然，超参数（学习率等）的设定值不同，结果也会发生变化

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330205735504.png" style="zoom:70%">



## 权重的初始值

设定什么样的权重初始值，经常关系到神经网络的学习能否成功。

### 能不能将初始权重全部设置为0？

不能。因为在误差反向传播法中，所有的权重值都会进行相同的更新。比如，在2层神经网络中，假设第1层和第2层的权重为0。这样一来，正向传播时，因为输入层的权重为0，所以第2层的神经元全部会被传递相同的值。第2层的神经元中全部输入相同的值，这意味着反向传播时第2层的权重全部都会进行**相同的更新**(（回忆一下“乘法节点的反向传播”)。因此，权重被更新为相同的值，并拥有了对称的值（重复的值）。这使得神经网络拥有许多不同的权重的意义丧失了。为了防止“权重均一化”（严格地讲，是为了瓦解权重的对称结构），**必须随机生成初始值**

>如果想减小权重的值，一开始就将初始值设为较小的值才是正途。实际上， 在这之前的权重初始值都是像0.01 * np.random.randn(10, 100)这样，使用 由高斯分布生成的值乘以0.01后得到的值

### 隐藏层激活值分布

做一个简单的实验，观察权重初始值是如何影响隐藏层的激活值的分布的。这里要做的实验是，**向一个5层神经网络（激活函数使用sigmoid函数）传入随机生成的输入数据，用直方图绘制各层激活值的数据分布。**

~~~python
# coding: utf-8
import numpy as np
import matplotlib.pyplot as plt


def sigmoid(x):
    return 1 / (1 + np.exp(-x))


def ReLU(x):
    return np.maximum(0, x)


def tanh(x):
    return np.tanh(x)
    
input_data = np.random.randn(1000, 100)  # 1000个数据
node_num = 100  # 各隐藏层的节点（神经元）数
hidden_layer_size = 5  # 隐藏层有5层
activations = {}  # 激活值的结果保存在这里

x = input_data

for i in range(hidden_layer_size):
    if i != 0:
        x = activations[i-1]

    # 改变初始值进行实验！
    w = np.random.randn(node_num, node_num) * 1
    # w = np.random.randn(node_num, node_num) * 0.01
    # w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)
    # w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)


    a = np.dot(x, w)


    # 将激活函数的种类也改变，来进行实验！
    z = sigmoid(a)
    # z = ReLU(a)
    # z = tanh(a)

    activations[i] = z

# 绘制直方图
for i, a in activations.items():
    plt.subplot(1, len(activations), i+1)
    plt.title(str(i+1) + "-layer")
    if i != 0: plt.yticks([], [])
    # plt.xlim(0.1, 1)
    # plt.ylim(0, 7000)
    plt.hist(a.flatten(), 30, range=(0,1))
plt.show()

~~~



这里假设神经网络有5层，每层有100个神经元。然后，用高斯分布随机生成1000个数据作为输入数据，并把它们传给5层神经网络。激活函数使用sigmoid函数，各层的激活值的结果保存在activations变量中。这个代码段中需要注意的是**权重的尺度**。虽然这次我们使用的是标准差为1的高斯分布，但实验的目的是通过改变这个尺度（标准差），观察激活值的分布如何变化。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330215107111.png" style="zoom:70%">

### 梯度消失

各层的激活值呈偏向0和1的分布。这里使用的sigmoid 函数是S型函数，随着输出不断地靠近0（或者靠近1），它的导数的值逐渐接 近0。因此，偏向0和1的数据分布会造成反向传播中梯度的值不断变小，最 后消失。这个问题称为**梯度消失**（gradient vanishing）。层次加深的深度学习 中，梯度消失的问题可能会更加严重

### 表现力受限

如果仅仅把标准差改成0.01，也就是只改动这个

`w = np.random.randn(node_num, node_num) * 0.01`

结果如下图

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330215237651.png" style="zoom:70%">

这次呈集中在0.5附近的分布。**因为不像刚才的例子那样偏向0和1，所以不会发生梯度消失的问题**。但是，激活值的分布有所偏向，说明在表现力上会有很大问题。为什么这么说呢？因为**如果有多个神经元都输出几乎相同的值，那它们就没有存在的意义了**。比如，如果100个神经元都输出几乎相同的值，那么也可以由1个神经元来表达基本相同的事情。因此，**激活值在分布上有所偏向会出现“表现力受限”的问题。**

>各层的激活值的分布都要求有适当的广度。为什么呢？因为通过在各层间传递多样性的数据，神经网络可以进行高效的学习。反过来，如果传递的是有所偏向的数据，就会出现梯度消失或者“表现力受限”的问题，导致学习可能无法顺利进行。

### Xavier初始值

Xavier Glorot等人的论文中推荐的权重初始值（俗称“Xavier初始值”)

Xavier的论文中，为了使各层的激活值呈现出具有相同广度的分布，推 导了合适的权重尺度。推导出的结论是，如果前一层的节点数为n，则初始 值使用标准差为 的分布A 。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330215843327.png" style="zoom:70%">

使用Xavier初始值后，**前一层的节点数越多，要设定为目标节点的初始值的权重尺度就越小**。现在，我们使用Xavier初始值进行实验。进行实验的代码只需要将设定权重初始值的地方换成如下内容即可（因为此处所有层的节点数都是100，所以简化了实现）

`w = np.random.randn(node_num, node_num) / np.sqrt(node_num)`

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330220010465.png" style="zoom:70%">

从这个结果可知，越是后面的层，图像变得越歪斜，但是呈现了比之前更有广度的分布。因为各层间传递的数据有适当的广度，所以sigmoid函数的表现力不受限制，有望进行高效的学习

>图 6-13的分布中，后面的层的分布呈稍微歪斜的形状。如果用tanh 函数（双曲线函数）代替sigmoid函数，这个稍微歪斜的问题就能得 到改善。实际上，使用tanh函数后，会呈漂亮的吊钟型分布。tanh 函数和sigmoid函数同是 S型曲线函数，但tanh函数是关于原点(0, 0) 对称的 S型曲线，而sigmoid函数是关于(x, y)=(0, 0.5)对称的S型曲 线。众所周知，**用作激活函数的函数最好具有关于原点对称的性质。**

### ReLU的权重初始值

Xavier初始值是以激活函数是线性函数为前提而推导出来的。因为 sigmoid函数和tanh函数左右对称，且中央附近可以视作线性函数，所以适 合使用Xavier初始值。但**当激活函数使用ReLU时，一般推荐使用ReLU专 用的初始值**，也就是Kaiming He等人推荐的初始值，也称为**“He初始值”**

当前一层的节点数为*n*时，He初始值使用标准差为$\sqrt {\frac {2}{n}}$的高斯分布。当Xavier的出啥子会是$\sqrt {\frac {1}{n}}$时，可以解释为，因为ReLU的负值区域的值为0，为了使它更有广度，所以需要2倍的系数

下面进行一下对比：

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330220723909.png" style="zoom:70%">

观察实验结果可知，当“std = 0.01”时，各层的激活值非常小 A。神经网 络上传递的是非常小的值，说明逆向传播时权重的梯度也同样很小。这是很 严重的问题，**实际上学习基本上没有进展。**

接下来是初始值为Xavier初始值时的结果。在这种情况下，随着层的加深， 偏向一点点变大。**实际上，层加深后，激活值的偏向变大，学习时会出现梯 度消失的问题。**

而当初始值为He初始值时，各层中分布的广度相同。由于 即便层加深，数据的广度也能保持不变，因此逆向传播时，也会传递合适的值。 

### 总结

当激活函数使用ReLU时，权重初始值使用He初始值，当 激活函数为sigmoid或tanh等S型曲线函数时，初始值使用Xavier初始值。 这是目前的最佳实践。

## Batch Normalization

上面可以知道，如果设定了合适的权重初始值，则各层的激活值分布会有适当的广度，从而可以顺利地进行学习。

那么，为了使各层拥有适当的广度，“强制性”地调整激活值的分布 会怎样呢？实际上，Batch Normalization方法就是基于这个想法而产生的。

Batch Norm有以下优点。

- 可以使学习快速进行（可以增大学习率）。
- 不那么依赖初始值（对于初始值不用那么神经质）。
- 抑制过拟合（降低Dropout等的必要性）。

Batch Norm的思路是调整各层的激活值分布使其拥有适当 的广度。为此，**要向神经网络中插入对数据分布进行正规化的层，即Batch Normalization层**（下文简称Batch Norm层）

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230330221110976.png" style="zoom:70%">

Batch Norm，**顾名思义，以进行学习时的mini-batch为单位，按minibatch进行正规化**。具体而言，就是进行使数据分布的均值为0、方差为1的 正规化。用数学式表示的话，如下所示                                      

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331095658139.png" style="zoom:70%">

这里对mini-batch的*m*个输入数据的集合*B* ={x1,x2...xm}求均值$u_b和方差\sigma^2_B$​,**然后对输入数据进行均值为0，方差为1（标准正态分布）的正规化**，式（6*.*7）中的*ε*是一个微小值（比如，10e-7等），**它是为了防止出现除以0的情况**。

> 若随机变量X服从一个数学期望为μ、方差为σ2的正态分布，记为N(μ，σ2)。其概率密度函数为正态分布的期望值μ决定了其位置，其标准差σ决定了分布的幅度。当μ = 0,σ = 1时的正态分布是标准正态分布。

经过这个处理，输入数据变成了，{$\hat x_1,\hat x_2,\hat x_3,\hat x_m$},这个处理插入到激活函数的前面（或者后面)，**可以减小数据分布的偏向**



接着，Batch Norm层会**对正规化后的数据进行缩放和平移的变换**，用数学式可以如下表示

$y_i \leftarrow \gamma \hat x_i +\beta$

一开始*γ* = 1，*β* = 0，然后再通过学习调整到合适的值

**这个算法是神经网络上的正向传播，用计算图可以表示如下**

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331100835339.png" style="zoom:70%">

> 当然也有反向传播，不过有点复杂，不介绍

### 结论

几乎所有的情况下都是使用Batch Norm时**学习进行得更快**。同时也可以发现，实际上，在不使用Batch Norm的情况下，如果不赋予一

个尺度好的初始值，学习将完全无法进行。通过使用Batch Norm，可以推动学习的进行。并且，**对权重初始值变得健壮**（“对初始值健壮”表示不那么依赖初始值）

## 正则化

机器学习的问题中，过拟合是一个很常见的问题。过拟合指的是只能拟合训练数据，但不能很好地拟合不包含在训练数据中的其他数据的状态。

> 直观表现就是训练集正确率很高，测试集却低

**过拟合原因：**

- 模型拥有大量参数、表现力强。
- 训练数据少。

**案例**

我们故意满足这两个条件，制造过拟合现象。为此，要从

MNIST数据集原本的60000个训练数据中**只选定300个**，并且，为了增加网

络的复杂度，**使用7层网络**（每层有100个神经元，激活函数为ReLU）。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331101337890.png" style="zoom:70%">

过了 100 个 epoch 左右后，用训练数据测量到的识别精度几乎都为100%。但是，对于测试数据，离100%的识别精度还有较大的差距。如此大的识别精度差距，**这样就是过拟合了。**

### 权值衰减

权值衰减是一直以来经常被使用的**一种抑制过拟合的方法**。该方法通过在学习的过程中对大的权重进行惩罚，来抑制过拟合。**很多过拟合原本就是因为权重参数取值过大才发生的**

复习一下，**神经网络的学习目的是减小损失函数的值**。这里介绍L2正则化，其实就是为损失函数加上**权重的平方范数**（L2范数）。这样一来，就可以抑制权重变大。

如果把权重记为$W$，L2范数的权重衰减就是$\frac 1 2 \lambda W^2$,然后将这个东西加到损失函数上，就是L2正则化了。这里，*λ*是控制正则化强度的超参数。*λ*越大，**对大的权重施加惩罚越重。**。此外，$\frac 1 2 \lambda W^2$ 开头的$\frac 1 2$ 是用于将$\frac 1 2 \lambda W^2$的求导结**果变成λW的调整用常量**。

对于所有权重，权值衰减方法都会为损失函数加上 $\frac 1 2 \lambda W^2$。因此，在求权重梯度的计算中，**要为之前的误差反向传播法的结果加上正则化项的导数λW**。

> 这里详细摘抄一下L2范数是什么

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331102844658.png" style="zoom:70%">

加入L2范数后的变化

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331103112772.png" style="zoom:70%">

虽然训练数据的识别精度和测试数据的识别精度之间有差距，但是与没有使用权值衰减的图6-20的结果相比，**差距变小了**。这说明

过拟合受到了抑制。此外**，还要注意，训练数据的识别精度没有达到100%**

## Dropout

正则化可以简单地实现，在某种程度上能够抑制过拟合。但是，如果网络的模型变得很复杂，只用权值衰减就难以应对了。

在这种情况下，我们经常会使用Dropout 方法

Dropout是一种在学习的过程中随机删除神经元的方法。**训练时，随机选出隐藏层的神经元，然后将其删除。被删除的神经元不再进行信号的传递**。

训练时，每传递一次数据，就会随机选择要删除的神经元。然后，测试时，虽然会传递所有的神经元信号，但是对于各个神经元的输出，

要乘上训练时的删除比例后再输出。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331103332755.png" style="zoom:70%">

~~~python
#Dropout
class Dropout:
    def __init__(self,dropout_ratio = 0.5):
        self.dropout_ratio = dropout_ratio
        self.mask = None
        
    def forward(self,x,train_flag=True):
        if train_flg:
            self.mask = np.random.rand(&x.shape) > self.dropout_ratio
            return x * self.mask
        else:
            return x * (1.0 - self.dropout_ratio)
    def backward(self,dout):
        return dout * self.mask
~~~



每次正向传播时，self.mask中都会以False的形式保存要删除的神经元。**self.mask会随机生成和x形状相同的数组，并将值比**

**dropout_ratio大的元素设为True**。反向传播时的行为和ReLU相同。也就是说，正向传播时传递了信号的神经元，反向传播时按原样传递信号；正向传播时没有传递信号的神经元，反向传播时信号将停在那里。

依然是对minist数据集进行实验

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331104704128.png" style="zoom:70%">

>通过使用Dropout，训练数据和测试数据的识别精度的**差距变小了**。并且，**训练数据也没有到达100%的识别精度**。像这样，通过使用Dropout，**即便是表现力强的网络，也可以抑制过拟合**

## 超参数的验证

神经网络中，除了权重和偏置等参数，超参数（hyper-parameter）也经常出现。这里所说的超参数是指，比如各层的神经元数量、batch大小、参数更新时的学习率或权值衰减等。如果这些超参数没有设置合适的值，模型的性能就会很差。

> 人工设置的值就叫超参数

### 验证集

之前我们使用的数据集分成了训练数据和测试数据，训练数据用于学习，测试数据用于评估泛化能力。由此，就可以评估是否只过度拟合了训练数据（是否发生了过拟合），以及泛化能力如何等。

那能不能用测试数据评测超参数的性能呢？**不能**

**因为如果使用测试数据调整超参数，超参数的值会对测试数据发生过拟合**。换句话说，用测试数据确认超参数的值的“好坏”，就会导致超参数的值被调整为只拟合测试数据。这样的话，可能就会得到不能拟合其他数据、泛化能力低的模型。

调整超参数时，必须使用超参数专用的确认数据。**用于调整超参数的数据，一般称为验证数据（validation data）**。我们使用这个验证数据来评估超参数的好坏

>训练数据用于参数（权重和偏置）的学习，验证数据用于超参数的性能评估。为了确认泛化能力，要在最后使用（**比较理想的是只用一次）测试数据**。

**怎么分割验证集**

根据不同的数据集，有的会事先分成训练数据、验证数据、测试数据三部分，有的只分成训练数据和测试数据两部分，有的则不进行分割。在这种情况下，用户需要自行进行分割。如果是MNIST数据集，获得验证数据的最简单的方法就是从训练数据中事先分割20%作为验证数据，代码如下

~~~python
(x_train, t_train), (x_test, t_test) = load_mnist()
# 打乱训练数据
x_train, t_train = shuffle_dataset(x_train, t_train)
# 分割验证数据
validation_rate = 0.20
validation_num = int(x_train.shape[0] * validation_rate)
x_val = x_train[:validation_num]
t_val = t_train[:validation_num]
x_train = x_train[validation_num:]
t_train = t_train[validation_num:]
~~~

**这里，分割训练数据前，先打乱了输入数据和教师标签。这是因为数据集的数据可能存在偏向**（比如，数据从“0”到“10”按顺序排列等）。这里使用的shuffle_dataset函数利用了np.random.shuffle

### 超参数最优化

进行超参数的最优化时，逐渐缩小超参数的“好值”的存在范围非常重要。

所谓逐渐缩小范围，**是指一开始先大致设定一个范围，从这个范围中随机选出一个超参数（采样），用这个采样到的值进行识别精度的评估**；然后，多次重复该操作，观察识别精度的结果，根据这个结果缩小超参数的“好值”的范围。通过重复这一操作，就可以逐渐确定超参数的合适范围。

> 可以说就是暴力求最优的解
>
> 在进行神经网络的超参数的最优化时，与网格搜索等有规律的搜索相比，**随机采样的搜索方式效果更好**。这是因为在多个超参数中，各个超参数对最终的识别精度的影响程度不同

超参数的范围只要“大致地指定”就可以了。所谓“大致地指定”，是指像0*.*001（10^(-3) ）到1000（10^3 ）这样，以“10的阶乘”的尺度指定范围（也表述为“用对数尺度（log scale）指定”）。

**总结步骤如下**：

步骤**0**

​	设定超参数的范围。

步骤**1**

​	从设定的超参数范围中随机采样。

步骤**2**

​	使用步骤1中采样到的超参数的值进行学习，通过验证数据评估识别精度（但是要将epoch设置得很小）。

步骤**3**

​	重复步骤1和步骤2（100次等），根据它们的识别精度的结果，缩小超参数的范围。



**更精炼的优化方法**

>如果需要更精炼的方法，可以使用贝叶斯最优化（Bayesian optimization）。贝叶斯最优化运用以贝叶斯定理为中心的数学理论，能够更加严密、高效地进行最优化。详细内容请参 考 论 文“Practical Bayesian Optimization of Machine LearningAlgorithms”[16]等。

### 还是以minist为例

我们使用MNIST数据集进行超参数的最优化。这里我们将**学习率和控制权值衰减强度的系数**（下文称为“权值衰减系数”）这两个超参数的搜索问题作为对象

如前所述，通过从 0*.*001（10^*−*3 ）到 1000（10^3 ）**这样的对数尺度的范围中随机采样进行超参数的验证**。这在Python中可以写成10  np.random.uniform(-3, 3)。在该实验中，权值衰减系数的初始范围为10^−8 到10^−4 ，学习率的初始范围为10^-6 到10^−2 。此时，超参数的随机采样的代码如下所示。

~~~python
weight_decay = 10 ** np.random.uniform(-8, -4)
lr = 10 ** np.random.uniform(-6, -2)
~~~

实验结果举例:

<img src ="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331111137074.png" style="zoom:70%">

> 显然，这里由高到低排列了结果

从上面可以发现，Best6之后效果不怎么好。**直到“Best-5”左右，学习进行得都很顺利**。因此，我们来观察一下“Best-5”之前的超参数的值（学习率和权值衰减系数），结果如下所示

~~~shell
Best-1 (val acc:0.83) | lr:0.0092, weight decay:3.86e-07
Best-2 (val acc:0.78) | lr:0.00956, weight decay:6.04e-07
Best-3 (val acc:0.77) | lr:0.00571, weight decay:1.27e-06
Best-4 (val acc:0.74) | lr:0.00626, weight decay:1.43e-05
Best-5 (val acc:0.73) | lr:0.0052, weight decay:8.97e-06
~~~

从这个结果可以看出，学习率在0*.*001到0*.*01、权值衰减系数在10*−*8 到10*−*6 之间时，学习可以顺利进行**。像这样，观察可以使学习顺利进行的超参数的范围，从而缩小值的范围。然后，在这个缩小的范围中重复相同的操作。**这样就能缩小到合适的超参数的存在范围，然后在某个阶段，选择一个最终的超参数的值。
