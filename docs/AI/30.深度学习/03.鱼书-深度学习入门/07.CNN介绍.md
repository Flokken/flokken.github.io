---
title: CNN介绍
date: 2023-03-31 
categories: 
  - 深度学习
  - 鱼书-深度学习入门
tags: 
  - null
---

# CNN

## 整体结构

回忆一下Affine层，神经网络中，相邻层的所有神经元之间都有连接，这称为全连接（fully-connected）。而**我们用Affine层实现了全连接层。**

<img src ="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331205906827.png" style="zoom:70%">



再观察CNN结构

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331210042062.png" style="zoom:70%">

需要注意的是，在图7-2的CNN中，**靠近输出的层中使用了之前的“Affi ne - ReLU”组合。此外，最后的输出层中使用了之前的“Affi ne -** 

**Softmax”组合**。这些都是一般的CNN中比较常见的结构。

## 卷积层

### 全连接层存在问题

在全连接层中，相邻层的神经元全部连接在一起，输出的数量可以任意决定

全连接层存在什么问题呢？**那就是数据的形状被“忽视”了**。比如，输入数据是图像时，图像通常是高、长、通道方向上的3维形状。但是，向全连接层输入时，**需要将3维数据拉平为1维数据**。实际上，前面提到的使用了MNIST数据集的例子中，输入图像就是1通道、高28像素、长28像素的（1*,* 28*,* 28）形状，但却被排成1列，以784个数据的形式输入到最开始的Affine层

>图像是3维形状，这个形状中应该含有重要的空间信息。比如，空间上邻近的像素为相似的值、RBG的各个通道之间分别有密切的关联性、相距较远的像素之间没有什么关联等，3维形状中可能隐藏有值得提取的本质模式。但是，因为全连接层会忽视形状，将全部的输入数据作为相同的神经元（同一维度的神经元）处理，所以无法利用与形状相关的信息。

CNN 中，有时将卷积层的输入输出数据称为特征图（feature map）。其中，卷积层的输入数据称为输入特征图（input feature map），输出数据称为输出特征图（output feature map）

### 卷积运算

卷积层进行的处理就是卷积运算。卷积运算相当于**图像处理中的“滤波器运算”**。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331211148093.png" style="zoom:70%">

假设用（height, width）表示数据和滤波器的形状，则在本例中，输入大小是(4*,* 4)，滤波器大小是(3*,* 3)，输出大小是(2*,* 2)。另外，有的文献中也会用**“核”**这个词来表示这里所说的“滤波器”。
**详细的计算过程**

对于输入数据，卷积运算**以一定间隔滑动滤波器的窗口并应用**。这里所说的窗口是指图7-4中灰色的3 *×* 3的部分。如图7-4所示，将各个位置上滤波器的元素和输入的对应元素相乘，然后再求和（**有时将这个计算称为乘积累加运算**）



<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331211432319.png" style="zoom:70%">

CNN中，滤波器的参数就对应之前的权重。**并且，CNN中也存在偏置**

加上偏置，**这个值会被加到应用了滤波器的所有元素**



<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331211731442.png" style="zoom:70%">

### 填充

在进行卷积层的处理之前，**有时要向输入数据的周围填入固定的数据**（比如0等），这称为**填充**（padding），是卷积运算中经常会用到的处理

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331212022307.png" style="zoom:70%">

>对大小为(4*,* 4)的输入数据应用了幅度为1的填充。“幅度为1的填充”是指**用幅度为1像素的0填充周围**。

如图7-6所示，通过填充，大小为(4*,* 4)的输入数据变成了(6*,* 6)的形状。然后，应用大小为(3*,* 3)的滤波器，生成了大小为(4*,* 4)的输出数据。这个例子中将填充设成了1，不过填充的值也可以设置成2、3等任意的整数

### 步幅

**应用滤波器的位置间隔称为步幅**（stride）。之前的例子中步幅都是1，如果将步幅设为2，则如图7-7所示，应用滤波器的窗口的间隔变为2个元素。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331212433436.png" style="zoom:70%">

### 步幅和填充对输出大小计算关系

**增大步幅后，输出大小会变小。而增大填充后，输出大小会变大。**

他们与输出大小间的计算关系是什么？

这里，假设输入大小为(*H, W*)，滤波器大小为(*FH, FW*)，输出大小为

(*OH, OW*)，填充为*P*，步幅为*S*。此时，输出大小

$OH = \frac {H+2P-FH} {S}+1$

$OW = \frac {H+2P-FW} {S}+1$

举例如下

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331212907547.png" style="zoom:70%">

> 注意，显然有时候，会发生除不尽的情况，这种时候根据深度学习的框架的不同，当值无法除尽时，有时会向最接近的整数四舍五入，不进行报错而继续运行。

### 3维数据的卷积运算

之前的卷积运算的例子都是以有高、长方向的2维形状为对象的。但是，

**图像是3维数据，除了高、长方向之外，还需要处理通道方向**。(想想RGB模式图像，就是三个通道)

例如：

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331213322729.png" style="zoom:70%">

详细计算过程

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331213357136.png" style="zoom:70%">

> 这里注意，滤波器的通道数必须要与输入数据一样，大小可以不一样，比如这里也可以为(1,1),(5,5)等等，但是每个通道的滤波器大小要都一样。

### 结合方块思考运算

**将数据和滤波器结合长方体的方块来考虑**，3维数据的卷积运算会很 容易理解。方块是如图7-10所示的3维长方体。把3维数据表示为多维数组 时，书写顺序为（channel, height, width）。比如，**通道数为C、高度为H、 长度为W的数据的形状可以写成（C, H, W）**。滤波器也一样，要按（channel, height, width）的顺序书写。比如，通道数为C、滤波器高度为FH（Filter Height）、长度为FW（Filter Width）时，可以写成（C, FH, FW）。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331213818184.png" style="zoom:70%">

这个例子中，数据输出是1张特征图。所谓1张特征图，换句话说， **就是通道数为1的特征图**。那么，**如果要在通道方向上也拥有多个卷积运算的输出，该怎么做呢**？**可以使用多个滤波器**（权重）

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331214027213.png" style="zoom:70%">

通过应用*FN*个滤波器，输出特征图也生成了*FN*个。如果将这*FN*个特征图汇集在一起，就得到了形状为(*FN, OH, OW*)的方块。将

这个方块传给下一层，就是CNN的处理流。

**关于卷积运算的滤波器，也必须考虑滤波器的数 量**。因此，**作为4维数据**，滤波器的权重数据要按(output_channel, input_ channel, height, width)的顺序书写。比如，通道数为3、大小为5 × 5的滤 波器有20个时，可以写成(20, 3, 5, 5)。

注意卷积运算中（和全连接层）一样有偏置运算。下面加上偏置。

每个通道只有一个偏置。这里，**偏置的形状是(FN, 1, 1)**， **滤波器的输出结果的形状是(FN, OH, OW)**。这两个方块相加时，**要对滤波 器的输出结果(FN, OH, OW)按通道加上相同的偏置值**。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331214804287.png" style="zoom:100%">

>不同形状的方块相加时，可以基于NumPy的广播功能轻松实现

### 批处理

类比全连接神经网络批处理，我们希望卷积运算也同样对应批处理。为此，**需要将在各层间传递的数 据保存为4维数据**。具体地讲，**就是按(batch_num, channel, height, width) 的顺序保存数据**。

图7-13的批处理版的数据流中，在各个数据的开头添加了批用的维度。像这样，数据作为4维的形状在各层间传递。这里需要注意的是，网络间传递的是4维数据，对这N个数据进行了卷积运算。**也就是说，批处理将N次的处理汇总成了1次进行**

![image-20230331215335682](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331215335682.png)

## 池化层

**池化是缩小高、长方向上的空间的运算**。比如，如图7-14所示，进行将 2 × 2的区域集约成1个元素的处理，缩小空间大小。

![image-20230331215604425](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331215604425.png)

> 除了Max池化之外，还有Average池化等。相对于Max池化是从目标区域中取出最大值，Average池化则是计算目标区域的平均值。在图像识别领域，主要使用Max池化。

### **池化层的特征**

- 没有要学习的参数
  - 池化层和卷积层不同，没有要学习的参数。池化只是从目标区域中取最大值（或者平均值），所以不存在要学习的参数。

- 通道数不发生变化

  - 经过池化运算，输入数据和输出数据的通道数不会发生变化。如图7-15所示，计算是按通道独立进行的。

  ![image-20230331220724122](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230331220724122.png)

  

- 对微小的位置变化具有鲁棒性（健壮）

  **输入数据发生微小偏差时，池化仍会返回相同的结果**。因此，池化对输入数据的微小偏差具有鲁棒性。比如最大池化，只要最大的那个数没变，那个池子里的数稍微改变，输出值也一样

## 卷积层和池化层实现

和前面一样，这里对卷积层和池化层也给进行实现的类赋予forward和backward方法，并使其可以作为模块使用

###  4维数组

这里解析一下numpy的多维数组，

~~~python
import numpy as np
z = np.random.rand(1,2,3)
z
#
array([[[0.5103475 , 0.36586482, 0.16843464],
        [0.02858124, 0.73298163, 0.87232873]]])
~~~

这个例子就可以看成一个数组包了两个数组，两个数组有各自包了三个小数组

~~~python
z[0]
array([[0.5103475 , 0.36586482, 0.16843464],
       [0.02858124, 0.73298163, 0.87232873]])
z[0].shape
(2, 3)
~~~

下标可以看成选择第几维的数据

~~~python
z[0,0]
#
array([0.5103475 , 0.36586482, 0.16843464])
z[0,0].shape
(3,)#省略行，只有列
~~~

因此，选择单个数据

~~~python
z[0,0,0]
0.5103474959617181
~~~

### img2col实现卷积操作

因为卷积运算就是乘法再求和，肯定写几个for循环就可以，但是NumPy中存在使用for语句后处理变慢的缺点（NumPy

中，访问元素时最好不要用for语句）,因此采用img2col来辅助实现。

i**m2col会把输入数据展开以适合滤波器（权重）**。具体地说，如图7-18所示，对于输入数据，将应用滤波器的区域（3维方块）横向展开为1列。im2col会在所有应用滤波器的地方进行这个展开处理。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230403200258354.png" style="zoom:70%">

为了便于观察，将步幅设置得很大，以使滤波器的应用区域不重叠。而在实际的卷积运算中，滤波器的应用区域几乎都是重叠的。在滤波器的应用区域重叠的情况下，**使用im2col展开后，展开后的元素个数会多于原方块的元素个数**

>使用im2col的实现存在比普通的实现消耗更多内存的缺点。但是，汇总成一个大的矩阵进行计算，对计算机的计算颇有益处。比如，在矩阵计算的库（线性代数库）等中，矩阵计算的实现已被高度最优化，可以高速地进行大矩阵的乘法运算
>
>im2col这个名称是“image to column”的缩写，翻译过来就是“从图像到矩阵”的意思。Caffe、Chainer 等深度学习框架中有名为im2col的函数，并且在卷积层的实现中，都使用了im2col

使用im2col展开输入数据后，之后就只需将卷积层的滤波器（权重）纵向展开为1列，**并计算2个矩阵的乘积**

基于im2col方式的输出结果是2维矩阵。因为CNN中数据会保存为4维数组，所以要将2维输出数据转换为合适的形状

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230403201023870.png" style="zoom:70%">

### 卷积层实现

im2col会考虑滤波器大小、步幅、填充，将输入数据展开为**2维数组**(感觉实现挺复杂的，当成黑盒就可以)

~~~python
def im2col(input_data, filter_h, filter_w, stride=1, pad=0):
    """

    Parameters
    ----------
    input_data : 由(数据量, 通道, 高, 长)的4维数组构成的输入数据
    filter_h : 滤波器的高
    filter_w : 滤波器的长
    stride : 步幅
    pad : 填充

    Returns
    -------
    col : 2维数组
    """
    N, C, H, W = input_data.shape
    out_h = (H + 2*pad - filter_h)//stride + 1
    out_w = (W + 2*pad - filter_w)//stride + 1

    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')
    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))

    for y in range(filter_h):
        y_max = y + stride*out_h
        for x in range(filter_w):
            x_max = x + stride*out_w
            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]

    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)
    return col
~~~

**img2col**使用（输出是二维数据，第一维是个数，第二维是滤波器乘积）

~~~python
import sys, os
sys.path.append(os.pardir)
from common.util import im2col
x1 = np.random.rand(1, 3, 7, 7)
col1 = im2col(x1, 5, 5, stride=1, pad=0)
print(col1.shape) # (9, 75)
x2 = np.random.rand(10, 3, 7, 7) # 10个数据
col2 = im2col(x2, 5, 5, stride=1, pad=0)
print(col2.shape) # (90, 75)
~~~

这里举了两个例子。第一个是批大小为1、通道为3的7 *×* 7的数据，第二个的批大小为10，数据形状和第一个相同。分别对其应用im2col函数，在这两种情形下，第2维的元素个数均为75。这是**滤波器（通道为3、大小为5 *×* 5）的元素个数的总和**。批大小为1时，im2col的结果是(9, 75)。而第2个例子中批大小为10，所以保存了10倍的数据，即(90, 75)。

**实现前向传播**

~~~python
class Convolution:
    def __init__(self,W,b,stride=1,pad=0):
        self.W = W
        self.b = b
        self.stride = stride
        self.pad =pad
    def forward(self, x):
        FN, C, FH, FW = self.W.shape
        N, C, H, W = x.shape
        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)
        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)
        col = im2col(x, FH, FW, self.stride, self.pad)
        col_W = self.W.reshape(FN, -1).T # 滤波器的展开
        out = np.dot(col, col_W) + self.b#这里就是和全连接层一样的计算
        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)
        return out
~~~

卷积层的初始化方法将滤波器（权重）、偏置、步幅、填充作为参数接收。滤波器是 (FN, C, FH, FW)的 4 维形状。另外，FN、C、FH、FW分别是 Filter Number（滤波器数量）、Channel、Filter Height、Filter Width的缩写。

​	这里用粗体字表示Convolution层的实现中的重要部分。在这些粗体字部分，用im2col展开输入数据，并用reshape将滤波器展开为2维数组。然后，计算展开后的矩阵的乘积。

这里通过reshape(FN,-1)将参数指定为-1，这是reshape的一个便利的功能。通过在reshape时指定为-1，reshape函数会自动计算-1维度上的元素个数，以使多维数组的元素个数前后一致。比如，(10*,* 3*,* 5*,* 5)形状的数组的元素个数共有750个，指定reshape(10,-1)后，就会转换成(10*,* 75)形状的数组。

forward的实现中，最后会将输出大小转换为合适的形状。转换时使用了NumPy的transpose函数。**transpose会更改多维数组的轴的顺序**

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230403211835689.png" style="zoom:70%">

#### reshape

numpy.reshape(x,y...)就是将目前的数据换一个形状，当然内容不变（**注意元素个数相同**）

主要说一下，reshape(x，-1)中**-1的用法**

在官方文档中，-1被理解为unspecified value，**未指定为给定的行数(列数)**,如果把某行指定为-1，**会自动计算-1的维度上的元素个数**

比如

~~~python
x=np.random.rand(3,2)

array([[0.86852744, 0.78710504],
       [0.8175077 , 0.28540559],
       [0.15449493, 0.51839175]])

x.reshape(1,-1)
array([[0.86852744, 0.78710504, 0.8175077 , 0.28540559, 0.15449493,
        0.51839175]])

x.reshape(2,-1)
array([[0.86852744, 0.78710504, 0.8175077 ],
       [0.28540559, 0.15449493, 0.51839175]])

x.reshape(4,-1)#当然，这里6/4除不尽，所以自动转换不了
ValueError: cannot reshape array of size 6 into shape (4,newaxis)
~~~

#### transpose	

介绍一下轴与维度，以numpy（2,3）为例，

维度：就是指有多少维，每个维有多少元素，(2,3)就是两个维度，两个维长度分别是2和3

轴：维度的方向，比如(2,3)，就有两个轴，第0轴（长度为2，第一个维度的方向），第一轴，长度为（3，第二个维度的方向）

在numpy中，**可以认为轴就是维度的体现**，需要注意的是轴的方向

二维数组，0轴是行方向，1轴是列方向

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230403221434548.png" style="zoom:70%">

例如维度为（2,3）的数组

![image-20230403220425869](https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230403220425869.png)

这个东西可以交换**多维数组维度的轴的顺序**，需要注意的是，**他们的含义交换后，是不变的，只是改变的顺序**

~~~python
a = np.array([[1, 2], [3, 4]])
a
array([[1, 2],
       [3, 4]])


np.tranpose(a)       #对于二维矩阵，什么参数都不填，默认转置操作，等同于a.tranpose(1,0)
array([[1, 3],
       [2, 4]])

a[0][0]=1
a[0][1]=2
a[1][0]=3
a[1][1]=4
 1轴
 ^
 |
 |
13     4 
 |     |
 |     |
 1-----2---->0轴
 0     1
transpose后
a[0][0]=1
a[0][1]=3
a[1][0]=2
a[1][1]=4
 0轴
 ^
 |
 |
13     4 
 |     |
 |     |
 1-----2---->1轴
 0     1
       
~~~

对于更高维的数据，也是一样的道理，只不过超过三维后，我们想象不到他的形状了，但是轴，只是一种输出该数组的形式



#### 反向传播

待实现，在进行卷积层的反向传播时，必须进行im2col的逆处理

### 池化层实现

池化层的实现和卷积层相同，都使用im2col展开输入数据。不过，池化的情况下，在通道方向上是独立的，这一点和卷积层不同。具体地讲，如图7-21所示，池化的应用区域按通道单独展开

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230403215114110.png" style="zoom:70%">

展开之后，只需对展开的矩阵求各行的最大值，**并转换为合适的形状即可**

三步走：展开，求最大值，转换为合适的形状

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230403215243085.png" style="zoom:70%">

`

~~~python
#pool
class Pooling:
    def __init__(self, pool_h, pool_w, stride=1, pad=0):
        self.pool_h = pool_h
        self.pool_w = pool_w
        self.stride = stride
        self.pad = pad
    def forward(self, x):
        N, C, H, W = x.shape
        out_h = int(1 + (H - self.pool_h) / self.stride)
        out_w = int(1 + (W - self.pool_w) / self.stride)
        # 展开(1)
        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)
        col = col.reshape(-1, self.pool_h*self.pool_w)
        # 最大值(2)
        out = np.max(col, axis=1)
        # 转换(3)
        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)
        return out
~~~

>最大值的计算可以使用 NumPy 的 np.max方法。np.max可以指定axis参数，并在这个参数指定的那个轴方向上求最大值。比如，如果写成np.max(x, axis=1)，就可以在输入x的第1轴（也是第一维）方向上的最大值

## 一个简单的CNN

以手写数字识别为例，实现如图CNN

![image-20230405093230898]()

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230405093230898.png" style="zoom:90%">

将上面的例子实现为simpleNet的类

**参数**

*•*  input_dim―输入数据的维度：（通道，高，长）

*•* conv_param―卷积层的超参数（字典）。字典的关键字如下：

​	filter_num―滤波器的数量

​	filter_size―滤波器的大小

​	stride―步幅

​	pad―填充

*•* hidden_size―隐藏层（全连接）的神经元数量

*•* output_size―输出层（全连接）的神经元数量

*•* weitght_int_std―初始化时权重的标准差

**卷积层的超参数通过名为conv_param的字典传入**，设想它会像{'filter_num':30,'filter_size':5, 'pad':0, 'stride':1}这样

细节都在都进行了注释，参照代码

~~~python
#simpleNet
import sys, os
sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定
import pickle
import numpy as np
from collections import OrderedDict
from common.layers import *
class SimpleConvNet:
    def __init__(self,input_dim=(1,28,28),
                conv_param={'filter_num':30,'filter_size':5,'pad':0,'stride':1},
                hidden_size=100,output_size=10,weight_init_std=0.01):
        filter_num = conv_param['filter_num']
        filter_size = conv_param['filter_size']
        filter_pad = conv_param['pad']
        filter_stride = conv_param['stride']
        input_size = input_dim[1]
        #这里，因为输入图像长宽一样的，所以只算一次就行
        conv_output_size = (input_size - filter_size + 2*filter_pad)/ filter_stride+1
        #池化层的输出大小就是把长宽都除以2，再注意还要乘上数量
        pool_output_size = int(filter_num *(conv_output_size/2)*(conv_output_size/2))
        
        
        self.params = {}
        #np.random.randn(dn0,dn1,......)
    #     randn函数返回一个或一组样本，具有标准正态分布。
    #     dn表格每个维度
    #     返回值为指定维度的array
        self.params['W1'] = weight_init_std * np.random.randn(filter_num,input_dim[0],filter_size,filter_size)
        self.params['b1'] = np.zeros(filter_num)

        self.params['W2'] = np.random.randn(pool_output_size,hidden_size)
        self.params['b2'] = np.zeros(hidden_size)

        self.params['W3']= weight_init_std * np.random.randn(hidden_size,output_size)
        self.params['b3'] = np.zeros(output_size)
        
        self.layers = OrderedDict()#有序字典对象
        self.layers['Conv1'] = Convolution(self.params['W1'],
                                           self.params['b1'],
                                          conv_param['stride'],
                                          conv_param['pad'])
        self.layers['Relu1'] =Relu()
        self.layers['Pool1'] = Pooling(pool_h=2,pool_w=2,stride=2)
        self.layers['Affine1'] = Affine(self.params['W2'],self.params['b2'])
        
        self.layers['Relu2']=Relu()
        self.layers['Affine2'] = Affine(self.params['W3'],self.params['b3'])
        
        self.last_layer = SoftmaxWithLoss()
        #注意这些层都是之前实现了的，都有参数，前向传播和反向传播
        
    def predict(self,x):
        for layer in self.layers.values():#调用每一层的前向传播
            x = layer.forward(x)
        return x
    def loss(self,x,t):
        y = self.predict(x)
        return self.last_layer.forward(y,t)
    
    
    def accuracy(self, x, t, batch_size=100):
        if t.ndim != 1 : t = np.argmax(t, axis=1)
        
        acc = 0.0
        
        for i in range(int(x.shape[0] / batch_size)):
            tx = x[i*batch_size:(i+1)*batch_size]
            tt = t[i*batch_size:(i+1)*batch_size]
            y = self.predict(tx)
            y = np.argmax(y, axis=1)
            acc += np.sum(y == tt) 
        
        return acc / x.shape[0]
    
    def gradient(self,x,t):
        self.loss(x,t)
        #传入一个参数，让层里的参数初始化，因为这些层里面也有random这种函数
        dout = 1
        dout = self.last_layer.backward(dout)
        
        layers = list(self.layers.values())
        layers.reverse()#因为反向传播的顺序就是正向传播的逆序，所以这里要reverse
        for layer in layers:
            dout = layer.backward(dout)
        
        grads ={}
        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db
        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db
        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db
        
        return grads
    
            
    def save_params(self, file_name="params.pkl"):
        params = {}
        for key, val in self.params.items():
            params[key] = val
        with open(file_name, 'wb') as f:
            pickle.dump(params, f)

    def load_params(self, file_name="params.pkl"):
        with open(file_name, 'rb') as f:
            params = pickle.load(f)
        for key, val in params.items():
            self.params[key] = val

        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):
            self.layers[key].W = self.params['W' + str(i+1)]
            self.layers[key].b = self.params['b'`b`b + str(i+1)]
        
~~~

**对该网络进行训，基本和Affine网络一样**

~~~python
# coding: utf-8
import sys, os
sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定
import numpy as np
import matplotlib.pyplot as plt
from dataset.mnist import load_mnist
from simple_convnet import SimpleConvNet
from common.trainer import Trainer

# 读入数据
(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)

# 处理花费时间较长的情况下减少数据 
#x_train, t_train = x_train[:5000], t_train[:5000]
#x_test, t_test = x_test[:1000], t_test[:1000]

max_epochs = 20

network = SimpleConvNet(input_dim=(1,28,28), 
                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},
                        hidden_size=100, output_size=10, weight_init_std=0.01)
                        
trainer = Trainer(network, x_train, t_train, x_test, t_test,
                  epochs=max_epochs, mini_batch_size=100,
                  optimizer='Adam', optimizer_param={'lr': 0.001},
                  evaluate_sample_num_per_epoch=1000)
trainer.train()

# 保存参数
network.save_params("params.pkl")
print("Saved Network Parameters!")

# 绘制图形
markers = {'train': 'o', 'test': 's'}
x = np.arange(max_epochs)
plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)
plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)
plt.xlabel("epochs")
plt.ylabel("accuracy")
plt.ylim(0, 1.0)
plt.legend(loc='lower right')
plt.show()

~~~





## CNN可视化

以上面的网络来查看，到底每一层干了什么

### 第一层权重可视化

第1层的

卷积层的权重的形状是(30*,* 1*,* 5*,* 5)，即30个大小为5 *×* 5、通道为1的滤波器。滤波器大小是5 *×* 5、通道数是1，**意味着滤波器可以可视化为1通道的灰度图像**

~~~python
# coding: utf-8
import numpy as np
import matplotlib.pyplot as plt
from simple_convnet import SimpleConvNet

def filter_show(filters, nx=8, margin=3, scale=10):
    """
    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py
    """
    FN, C, FH, FW = filters.shape
    ny = int(np.ceil(FN / nx))

    fig = plt.figure()
    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)

    for i in range(FN):
        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])
        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')
    plt.show()


network = SimpleConvNet()
# 随机进行初始化后的权重
filter_show(network.params['W1'])

# 学习后的权重
network.load_params("params.pkl")
filter_show(network.params['W1'])
~~~

学习前的滤波器是随机进行初始化的，所以在黑白的浓淡上没有规律可循，但学习后的滤波器变成了有规律的图像。我们发现，通**过学**

**习，滤波器被更新成了有规律的滤波器，比如从白到黑渐变的滤波器、含有块状区域（称为blob）的滤波器等。**

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230405110728215.png" style="zoom:70%">

右边的有规律的滤波器在“观察”什么？答案就是它**在观察边缘（颜色变化的分界线）和斑块（局部的块状区域）等**。比如，左半

部分为白色、右半部分为黑色的滤波器的情况下，如图7-25所示，会对垂直方向上的边缘有响应。

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230405110753098.png" style="zoom:70%">

图7-25中显示了选择两个学习完的滤波器对输入图像进行卷积处理时的结果。**我们发现“滤波器1”对垂直方向上的边缘有响应，“滤波2”对水平方向上的边缘有响应。**

由此可知，卷积层的滤波器会提取边缘或斑块等原始信息。而刚才实现的CNN会将这些原始信息传递给后面的层。

### 基于分层结构的信息提取

上面的结果是针对第1层的卷积层得出的。第1层的卷积层中提取了边缘或斑块等“低级”信息，那么在堆叠了多层的CNN中，各层中又会提取什么样的信息呢？**根据深度学习的可视化相关的研究，随着层次加深，提取的信息（正确地讲，是反映强烈的神经元）也越来越抽象**

<img src="https://typora-1309665611.cos.ap-nanjing.myqcloud.com/typora/image-20230405111325378.png" style="zoom:70%">

如图7-26所示，如果堆叠了多层卷积层，则随着层次加深，提取的信息也愈加复杂、抽象，这是深度学习中很有意思的一个地方。最开始的层对简单的边缘有响应，接下来的层对纹理有响应，再后面的层对更加复杂的物体部件有响应。也就是说，**随着层次加深，神经元从简单的形状向“高级”信息变化。**换句话说，就像我们理解东西的“含义”一样，响应的对象在逐渐变化。

